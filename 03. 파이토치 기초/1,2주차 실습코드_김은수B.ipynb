{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e7b55b9-c521-4420-9245-b72aa762812f",
   "metadata": {},
   "source": [
    "# 텐서 생성부터 최적화까지 (~87p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1749b87-5681-41e6-8619-90fc522ece5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "tensor([1, 2, 3])\n",
      "tensor([1., 2., 3.])\n"
     ]
    }
   ],
   "source": [
    "# 03장 파이토치 기초/예제 3.01 텐서 생성\n",
    "\n",
    "import torch\n",
    "\n",
    "print(torch.tensor([1, 2, 3])) # 입력의 자료형을 그대로 복사\n",
    "print(torch.Tensor([[1, 2, 3], [4, 5, 6]])) # 기본형 텐서 (32비트 부동소수점 float)\n",
    "print(torch.LongTensor([1, 2, 3])) # 정수 Long 형의 텐서 \n",
    "print(torch.FloatTensor([1, 2, 3])) # 64비트 부동소수점 float 형의 텐서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adc02f4a-0b34-46b6-b92f-28f6c07c61ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3821, 0.3377]])\n",
      "torch.Size([1, 2])\n",
      "torch.float32\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# 03장 파이토치 기초/예제 3.02 텐서 속성\n",
    "\n",
    "import torch\n",
    "\n",
    "tensor = torch.rand(1, 2) # 1보다 작은 숫자를 랜덤으로 뽑아서, 1x2 형태의 텐서에 할당\n",
    "print(tensor) # 랜덤으로 할당된 텐서를 출력\n",
    "print(tensor.shape) # 텐서의 차원을 출력 (shape)\n",
    "print(tensor.dtype) # 텐서의 데이터타입=자료형을 출력 (dtype)\n",
    "print(tensor.device) # 텐서의 디바이스를 출력 (device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "812e7575-de52-45ef-a566-77c13561acc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4203, 0.1743]])\n",
      "torch.Size([1, 2])\n",
      "tensor([[0.4203],\n",
      "        [0.1743]])\n",
      "torch.Size([2, 1])\n"
     ]
    }
   ],
   "source": [
    "# 03장 파이토치 기초/예제 3.03 텐서 차원 변환\n",
    "\n",
    "import torch\n",
    "\n",
    "tensor = torch.rand(1, 2)\n",
    "print(tensor)\n",
    "print(tensor.shape)\n",
    "\n",
    "tensor = tensor.reshape(2, 1) # reshape 메소드로 텐서를 2행 1열의 수직 구조로 차원 변환\n",
    "print(tensor)\n",
    "print(tensor.shape) # 변환된 차원을 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9186e9c5-ea78-4c3c-8d4d-cea8f3573424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7711, 0.3723, 0.6124],\n",
      "        [0.1127, 0.6084, 0.7319],\n",
      "        [0.0574, 0.6367, 0.4691]])\n"
     ]
    }
   ],
   "source": [
    "# 03장 파이토치 기초/예제 3.04 텐서 자료형 설정\n",
    "\n",
    "import torch\n",
    "\n",
    "tensor = torch.rand((3, 3), dtype=torch.float) # 1보다 작은 숫자를 랜덤으로 뽑아서, 3x3 형태의 텐서에 할당\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83b0ae73-1119-48d7-ab18-789d5a87805c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "type torch.cuda.FloatTensor not available. Torch not compiled with CUDA enabled.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      6\u001b[0m cpu \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m])\n\u001b[1;32m----> 7\u001b[0m gpu \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mFloatTensor([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m])\n\u001b[0;32m      8\u001b[0m tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m), device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(device)\n",
      "\u001b[1;31mTypeError\u001b[0m: type torch.cuda.FloatTensor not available. Torch not compiled with CUDA enabled."
     ]
    }
   ],
   "source": [
    "# 03장 파이토치 기초/예제 3.05 텐서 GPU 장치 설정\n",
    "\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # gpu 가 없어서 에러 발생\n",
    "cpu = torch.FloatTensor([1, 2, 3]) # cpu 변수에 텐서 생성 \n",
    "gpu = torch.cuda.FloatTensor([1, 2, 3]) # gpu 변수에 cuda 속성을 이용한 텐서 생성\n",
    "tensor = torch.rand((1, 1), device=device) # 1x1의 1 이하 무작위 텐서, device 에 대한 정보\n",
    "print(device)\n",
    "print(cpu)\n",
    "print(gpu)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "914431fa-d23f-4501-8dc0-083fdb2b2a9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      5\u001b[0m cpu \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m])\n\u001b[1;32m----> 6\u001b[0m gpu \u001b[38;5;241m=\u001b[39m cpu\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m      7\u001b[0m gpu2cpu \u001b[38;5;241m=\u001b[39m gpu\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[0;32m      8\u001b[0m cpu2gpu \u001b[38;5;241m=\u001b[39m cpu\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\cuda\\__init__.py:305\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    300\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    301\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    303\u001b[0m     )\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    307\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    309\u001b[0m     )\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "# 03장 파이토치 기초/예제 3.06 텐서 장치 변환\n",
    "\n",
    "import torch\n",
    "\n",
    "cpu = torch.FloatTensor([1, 2, 3])\n",
    "gpu = cpu.cuda() # gpu 가 없어서 에러 발생\n",
    "gpu2cpu = gpu.cpu() # gpu 를 cpu 로 변환\n",
    "cpu2gpu = cpu.to(\"cuda\") # cuda 를 이용해서 cpu 로\n",
    "print(cpu)\n",
    "print(gpu)\n",
    "print(gpu2cpu)\n",
    "print(cpu2gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bb9d073-2eb8-41db-af40-cb9eb2951075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3], dtype=torch.uint8)\n",
      "tensor([1., 2., 3.])\n",
      "tensor([1, 2, 3], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "# 03장 파이토치 기초/예제 3.07 넘파이 배열의 텐서 변환\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "ndarray = np.array([1, 2, 3], dtype=np.uint8) # [1,2,3] 의 넘파이 배열 선언\n",
    "print(torch.tensor(ndarray)) # 넘파이 배열을 복사형 텐서로 변환 (똑같이 출력한다)\n",
    "print(torch.Tensor(ndarray)) # 넘파이 배열을 기본형 텐서로 변환\n",
    "print(torch.from_numpy(ndarray)) # 넘파이 배열을 텐서로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc8e6110-4ec6-460f-9720-b6380a00a0a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "type torch.cuda.FloatTensor not available. Torch not compiled with CUDA enabled.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 03장 파이토치 기초/예제 3.08 텐서의 넘파이 배열 변환.ipynb\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mFloatTensor([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m])\n\u001b[0;32m      6\u001b[0m ndarray \u001b[38;5;241m=\u001b[39m tensor\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(ndarray)\n",
      "\u001b[1;31mTypeError\u001b[0m: type torch.cuda.FloatTensor not available. Torch not compiled with CUDA enabled."
     ]
    }
   ],
   "source": [
    "# 03장 파이토치 기초/예제 3.08 텐서의 넘파이 배열 변환\n",
    "\n",
    "import torch\n",
    "\n",
    "tensor = torch.cuda.FloatTensor([1, 2, 3]) # 기본형 텐서를 생성\n",
    "ndarray = tensor.detach().cpu().numpy() # numpy 로 변환하고, cpu 로 장치 변환하고, datach 까지\n",
    "print(ndarray)\n",
    "print(type(ndarray)) # ndarray 의 타입을 출력 (class numpy.ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d1c174b-1637-47ee-b0a7-93e6cd17cf21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600.75x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 03장 파이토치 기초/예제 3.09~3.10 비쌍체 t-검정\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "man_height = stats.norm.rvs(loc=170, scale=10, size=500, random_state=1) # 남자 키 값 (평균 170, 표준편차 10 을 따르는 500개의 값)\n",
    "woman_height = stats.norm.rvs(loc=150, scale=10, size=500, random_state=1) # 여자 키 값 (평균 150, 표준편차 10 을 따르는 500개의 값)\n",
    "\n",
    "X = np.concatenate([man_height, woman_height]) # 독립 변수 X에 할당 \n",
    "Y = [\"man\"] * len(man_height) + [\"woman\"] * len(woman_height) # 종속 변수 Y에 할당\n",
    "\n",
    "df = pd.DataFrame(list(zip(X, Y)), columns=[\"X\", \"Y\"]) \n",
    "fig = sns.displot(data=df, x=\"X\", hue=\"Y\", kind=\"kde\")\n",
    "fig.set_axis_labels(\"cm\", \"count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36f2dc39-0bb6-43c5-b0ce-9d6ee9c7bd8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistic: 31.96162891312776\n",
      "pvalue : 6.2285854381989205e-155\n",
      "*: True\n",
      "**: True\n"
     ]
    }
   ],
   "source": [
    "# 03장 파이토치 기초/예제 3.09~3.10 비쌍체 t-검정\n",
    "\n",
    "# 서로 독립된 두 집단 man과 woman 에 대해 비쌍체 t-검정\n",
    "# 이를 통해 두 모집단 데이터 간의 통계적 유의성을 확인하고자 함\n",
    "statistic, pvalue = stats.ttest_ind(man_height, woman_height, equal_var=True)\n",
    "\n",
    "print(\"statistic:\", statistic) # static 이 크고, pvalue 가 작으면 대립가설이 유력\n",
    "print(\"pvalue :\", pvalue)\n",
    "print(\"*:\", pvalue < 0.05) # pvalue 가 0.5 보다 작으면 * 로 표기 (통계적 유의성이 있다고 봄)\n",
    "print(\"**:\", pvalue < 0.001) # pvalue 가 0.05 보다 작으면 * 로 표기 (통계적 유의성이 크다고 봄)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b66ea128-f2ff-4c21-baa1-5c9e9597ba52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1000, Weight : 0.872, Bias : -0.290, Cost : 1.377\n",
      "Epoch : 2000, Weight : 0.877, Bias : -0.391, Cost : 1.373\n",
      "Epoch : 3000, Weight : 0.878, Bias : -0.422, Cost : 1.372\n",
      "Epoch : 4000, Weight : 0.879, Bias : -0.432, Cost : 1.372\n",
      "Epoch : 5000, Weight : 0.879, Bias : -0.435, Cost : 1.372\n",
      "Epoch : 6000, Weight : 0.879, Bias : -0.436, Cost : 1.372\n",
      "Epoch : 7000, Weight : 0.879, Bias : -0.436, Cost : 1.372\n",
      "Epoch : 8000, Weight : 0.879, Bias : -0.436, Cost : 1.372\n",
      "Epoch : 9000, Weight : 0.879, Bias : -0.436, Cost : 1.372\n",
      "Epoch : 10000, Weight : 0.879, Bias : -0.436, Cost : 1.372\n"
     ]
    }
   ],
   "source": [
    "# 03장 파이토치 기초/예제 3.11~3.17 단순 선형 회귀(넘파이)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 넘파이 형태의 두 데이터 생성\n",
    "x = np.array(\n",
    "    [[1], [2], [3], [4], [5], [6], [7], [8], [9], [10],\n",
    "    [11], [12], [13], [14], [15], [16], [17], [18], [19], [20],\n",
    "    [21], [22], [23], [24], [25], [26], [27], [28], [29], [30]]\n",
    ")\n",
    "y = np.array(\n",
    "    [[0.94], [1.98], [2.88], [3.92], [3.96], [4.55], [5.64], [6.3], [7.44], [9.1],\n",
    "    [8.46], [9.5], [10.67], [11.16], [14], [11.83], [14.4], [14.25], [16.2], [16.32],\n",
    "    [17.46], [19.8], [18], [21.34], [22], [22.5], [24.57], [26.04], [21.6], [28.8]]\n",
    ")\n",
    "\n",
    "# 하이퍼파라미터 초기화\n",
    "weight = 0.0\n",
    "bias = 0.0\n",
    "learning_rate = 0.005\n",
    "\n",
    "for epoch in range(10000): #10,000 에폭 \n",
    "    y_hat = weight * x + bias # 가설 선언\n",
    "    cost = ((y - y_hat) ** 2).mean() # 손실 함수 선언\n",
    "\n",
    "    weight = weight - learning_rate * ((y_hat - y) * x).mean() # 최적화를 가중치에 적용\n",
    "    bias = bias - learning_rate * (y_hat - y).mean() # 최적화를 편향에 적용\n",
    "\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f\"Epoch : {epoch+1:4d}, Weight : {weight:.3f}, Bias : {bias:.3f}, Cost : {cost:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bb2824f-3dea-4844-bbf9-093bd7dab152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1000, Weight : 0.864, Bias : -0.138, Cost : 1.393\n",
      "Epoch : 2000, Weight : 0.870, Bias : -0.251, Cost : 1.380\n",
      "Epoch : 3000, Weight : 0.873, Bias : -0.321, Cost : 1.375\n",
      "Epoch : 4000, Weight : 0.875, Bias : -0.364, Cost : 1.373\n",
      "Epoch : 5000, Weight : 0.877, Bias : -0.391, Cost : 1.373\n",
      "Epoch : 6000, Weight : 0.878, Bias : -0.408, Cost : 1.372\n",
      "Epoch : 7000, Weight : 0.878, Bias : -0.419, Cost : 1.372\n",
      "Epoch : 8000, Weight : 0.878, Bias : -0.425, Cost : 1.372\n",
      "Epoch : 9000, Weight : 0.879, Bias : -0.429, Cost : 1.372\n",
      "Epoch : 10000, Weight : 0.879, Bias : -0.432, Cost : 1.372\n"
     ]
    }
   ],
   "source": [
    "# 03장 파이토치 기초/예제 3.18~3.24 단순 선형 회귀(파이토치)\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "\n",
    "# 텐서 형태의 두 데이터 선언 \n",
    "x = torch.FloatTensor([ \n",
    "    [1], [2], [3], [4], [5], [6], [7], [8], [9], [10],\n",
    "    [11], [12], [13], [14], [15], [16], [17], [18], [19], [20],\n",
    "    [21], [22], [23], [24], [25], [26], [27], [28], [29], [30]\n",
    "])\n",
    "y = torch.FloatTensor([\n",
    "    [0.94], [1.98], [2.88], [3.92], [3.96], [4.55], [5.64], [6.3], [7.44], [9.1],\n",
    "    [8.46], [9.5], [10.67], [11.16], [14], [11.83], [14.4], [14.25], [16.2], [16.32],\n",
    "    [17.46], [19.8], [18], [21.34], [22], [22.5], [24.57], [26.04], [21.6], [28.8]\n",
    "])\n",
    " \n",
    "weight = torch.zeros(1, requires_grad=True) # weight 을 0값의 텐서로 초기화\n",
    "bias = torch.zeros(1, requires_grad=True) # bias 을 0값의 텐서로 초기화\n",
    "learning_rate = 0.001\n",
    "\n",
    "optimizer = optim.SGD([weight, bias], lr=learning_rate) # 최적화 함수는 SGD 로 역전파 수행\n",
    "\n",
    "\n",
    "for epoch in range(10000):\n",
    "    hypothesis = weight * x + bias # 가설 선언\n",
    "    cost = torch.mean((hypothesis - y) ** 2) # 손실 함수 선언\n",
    "\n",
    "    # 가중치와 편향 갱신의 3단계\n",
    "    optimizer.zero_grad() # 기울기 초기화\n",
    "    cost.backward() # 역전파 연산\n",
    "    optimizer.step() # 계산된 변수를 적용\n",
    "\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f\"Epoch : {epoch+1:4d}, Weight : {weight.item():.3f}, Bias : {bias.item():.3f}, Cost : {cost:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75216a46-8c09-453e-a52d-8115ad1da79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :    1\n",
      "Step [1] : Gradient : None, Weight : 0.00000\n",
      "Step [2] : Gradient : None, Weight : 0.00000\n",
      "Step [3] : Gradient : tensor([-540.4854]), Weight : 0.00000\n",
      "Step [4] : Gradient : tensor([-540.4854]), Weight : 0.54049\n",
      "Epoch :    2\n",
      "Step [1] : Gradient : tensor([-540.4854]), Weight : 0.54049\n",
      "Step [2] : Gradient : None, Weight : 0.54049\n",
      "Step [3] : Gradient : tensor([-198.9818]), Weight : 0.54049\n",
      "Step [4] : Gradient : tensor([-198.9818]), Weight : 0.73947\n",
      "Epoch :    3\n",
      "Step [1] : Gradient : tensor([-198.9818]), Weight : 0.73947\n",
      "Step [2] : Gradient : None, Weight : 0.73947\n",
      "Step [3] : Gradient : tensor([-73.2604]), Weight : 0.73947\n",
      "Step [4] : Gradient : tensor([-73.2604]), Weight : 0.81273\n",
      "Epoch :    4\n",
      "Step [1] : Gradient : tensor([-73.2604]), Weight : 0.81273\n",
      "Step [2] : Gradient : None, Weight : 0.81273\n",
      "Step [3] : Gradient : tensor([-26.9772]), Weight : 0.81273\n",
      "Step [4] : Gradient : tensor([-26.9772]), Weight : 0.83970\n"
     ]
    }
   ],
   "source": [
    "# 03장 파이토치 기초/예제 3.25 zero_grad(), cost.backward(), optimizer.step()\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "\n",
    "\n",
    "x = torch.FloatTensor([\n",
    "    [1], [2], [3], [4], [5], [6], [7], [8], [9], [10],\n",
    "    [11], [12], [13], [14], [15], [16], [17], [18], [19], [20],\n",
    "    [21], [22], [23], [24], [25], [26], [27], [28], [29], [30]\n",
    "])\n",
    "y = torch.FloatTensor([\n",
    "    [0.94], [1.98], [2.88], [3.92], [3.96], [4.55], [5.64], [6.3], [7.44], [9.1],\n",
    "    [8.46], [9.5], [10.67], [11.16], [14], [11.83], [14.4], [14.25], [16.2], [16.32],\n",
    "    [17.46], [19.8], [18], [21.34], [22], [22.5], [24.57], [26.04], [21.6], [28.8]\n",
    "])\n",
    "\n",
    "weight = torch.zeros(1, requires_grad=True) # weight 을 0값의 텐서로 생성\n",
    "bias = torch.zeros(1, requires_grad=True) # bias 을 0값의 텐서로 생성\n",
    "learning_rate = 0.001\n",
    "\n",
    "optimizer = optim.SGD([weight, bias], lr=learning_rate) # 최적화 함수는 SGD 로 역전파 수행\n",
    "\n",
    "for epoch in range(10000):\n",
    "    hypothesis = weight * x + bias # 가설 선언\n",
    "    cost = torch.mean((hypothesis - y) ** 2) # 손실 함수 선언\n",
    "    \n",
    "    print(f\"Epoch : {epoch+1:4d}\")\n",
    "    print(f\"Step [1] : Gradient : {weight.grad}, Weight : {weight.item():.5f}\")\n",
    "\n",
    "    # 가중치와 편향 갱신의 3단계\n",
    "    optimizer.zero_grad()\n",
    "    print(f\"Step [2] : Gradient : {weight.grad}, Weight : {weight.item():.5f}\")\n",
    "\n",
    "    cost.backward()\n",
    "    print(f\"Step [3] : Gradient : {weight.grad}, Weight : {weight.item():.5f}\")\n",
    "\n",
    "    optimizer.step()\n",
    "    print(f\"Step [4] : Gradient : {weight.grad}, Weight : {weight.item():.5f}\")\n",
    "    \n",
    "    if epoch == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23afdff8-ff78-4886-9cf6-c852185e2938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1000, Model : [Parameter containing:\n",
      "tensor([[0.8756]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.3697], requires_grad=True)], Cost : 1.373\n",
      "Epoch : 2000, Model : [Parameter containing:\n",
      "tensor([[0.8769]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.3947], requires_grad=True)], Cost : 1.373\n",
      "Epoch : 3000, Model : [Parameter containing:\n",
      "tensor([[0.8776]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.4103], requires_grad=True)], Cost : 1.372\n",
      "Epoch : 4000, Model : [Parameter containing:\n",
      "tensor([[0.8781]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.4200], requires_grad=True)], Cost : 1.372\n",
      "Epoch : 5000, Model : [Parameter containing:\n",
      "tensor([[0.8784]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.4260], requires_grad=True)], Cost : 1.372\n",
      "Epoch : 6000, Model : [Parameter containing:\n",
      "tensor([[0.8786]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.4298], requires_grad=True)], Cost : 1.372\n",
      "Epoch : 7000, Model : [Parameter containing:\n",
      "tensor([[0.8787]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.4321], requires_grad=True)], Cost : 1.372\n",
      "Epoch : 8000, Model : [Parameter containing:\n",
      "tensor([[0.8788]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.4335], requires_grad=True)], Cost : 1.372\n",
      "Epoch : 9000, Model : [Parameter containing:\n",
      "tensor([[0.8788]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.4344], requires_grad=True)], Cost : 1.372\n",
      "Epoch : 10000, Model : [Parameter containing:\n",
      "tensor([[0.8789]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.4350], requires_grad=True)], Cost : 1.372\n"
     ]
    }
   ],
   "source": [
    "# 03장 파이토치 기초/예제 3.26~3.28 신경망 패키지 적용\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "x = torch.FloatTensor([\n",
    "    [1], [2], [3], [4], [5], [6], [7], [8], [9], [10],\n",
    "    [11], [12], [13], [14], [15], [16], [17], [18], [19], [20],\n",
    "    [21], [22], [23], [24], [25], [26], [27], [28], [29], [30]\n",
    "])\n",
    "y = torch.FloatTensor([\n",
    "    [0.94], [1.98], [2.88], [3.92], [3.96], [4.55], [5.64], [6.3], [7.44], [9.1],\n",
    "    [8.46], [9.5], [10.67], [11.16], [14], [11.83], [14.4], [14.25], [16.2], [16.32],\n",
    "    [17.46], [19.8], [18], [21.34], [22], [22.5], [24.57], [26.04], [21.6], [28.8]\n",
    "])\n",
    "\n",
    "model = nn.Linear(1, 1) # 선형 변환 클래스의 매개변수를 사용해서 weight 과 bias 생성\n",
    "criterion = nn.MSELoss() # MSE 로 손실을 계산 -> 매개변수 필요 X\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001) # 모델의 파라미터로 역전파 연산을 수행\n",
    "\n",
    "for epoch in range(10000): \n",
    "    output = model(x) # 가설은 선언한 모델을 이용해 선언\n",
    "    cost = criterion(output, y) # 손실 함수는 criterion 에 할당한 MSE \n",
    "\n",
    "    optimizer.zero_grad() # 가중치와 편향 갱신을 위한 3단게\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f\"Epoch : {epoch+1:4d}, Model : {list(model.parameters())}, Cost : {cost:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d24c78c-e719-4434-a10d-18980b004572",
   "metadata": {},
   "source": [
    "# 데이터세트와 데이터로더부터 퍼셉트론까지 (~159p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d8245e4-8fb6-414f-9d4e-c099aad4312a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1000, Model : [Parameter containing:\n",
      "tensor([[0.5571, 0.2085],\n",
      "        [0.7898, 0.4539]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.4419, -0.0167], requires_grad=True)], Cost : 0.037\n",
      "Epoch : 2000, Model : [Parameter containing:\n",
      "tensor([[0.6936, 0.1378],\n",
      "        [0.8470, 0.4243]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.6492, -0.1035], requires_grad=True)], Cost : 0.010\n",
      "Epoch : 3000, Model : [Parameter containing:\n",
      "tensor([[0.7633, 0.1018],\n",
      "        [0.8761, 0.4093]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.7548, -0.1477], requires_grad=True)], Cost : 0.003\n",
      "Epoch : 4000, Model : [Parameter containing:\n",
      "tensor([[0.7987, 0.0835],\n",
      "        [0.8910, 0.4016]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.8086, -0.1702], requires_grad=True)], Cost : 0.001\n",
      "Epoch : 5000, Model : [Parameter containing:\n",
      "tensor([[0.8168, 0.0741],\n",
      "        [0.8985, 0.3977]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.8360, -0.1817], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 6000, Model : [Parameter containing:\n",
      "tensor([[0.8260, 0.0694],\n",
      "        [0.9024, 0.3957]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.8499, -0.1875], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 7000, Model : [Parameter containing:\n",
      "tensor([[0.8307, 0.0670],\n",
      "        [0.9044, 0.3947]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.8571, -0.1905], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 8000, Model : [Parameter containing:\n",
      "tensor([[0.8331, 0.0657],\n",
      "        [0.9054, 0.3941]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.8607, -0.1920], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 9000, Model : [Parameter containing:\n",
      "tensor([[0.8343, 0.0651],\n",
      "        [0.9059, 0.3939]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.8625, -0.1928], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 10000, Model : [Parameter containing:\n",
      "tensor([[0.8349, 0.0648],\n",
      "        [0.9061, 0.3937]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.8635, -0.1932], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 11000, Model : [Parameter containing:\n",
      "tensor([[0.8352, 0.0646],\n",
      "        [0.9063, 0.3937]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.8640, -0.1934], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 12000, Model : [Parameter containing:\n",
      "tensor([[0.8354, 0.0645],\n",
      "        [0.9063, 0.3936]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.8642, -0.1935], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 13000, Model : [Parameter containing:\n",
      "tensor([[0.8355, 0.0645],\n",
      "        [0.9064, 0.3936]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.8643, -0.1935], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 14000, Model : [Parameter containing:\n",
      "tensor([[0.8355, 0.0645],\n",
      "        [0.9064, 0.3936]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.8644, -0.1936], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 15000, Model : [Parameter containing:\n",
      "tensor([[0.8355, 0.0645],\n",
      "        [0.9064, 0.3936]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.8644, -0.1936], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 16000, Model : [Parameter containing:\n",
      "tensor([[0.8355, 0.0645],\n",
      "        [0.9064, 0.3936]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.8644, -0.1936], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 17000, Model : [Parameter containing:\n",
      "tensor([[0.8356, 0.0644],\n",
      "        [0.9064, 0.3936]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.8644, -0.1936], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 18000, Model : [Parameter containing:\n",
      "tensor([[0.8356, 0.0644],\n",
      "        [0.9064, 0.3936]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.8644, -0.1936], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 19000, Model : [Parameter containing:\n",
      "tensor([[0.8356, 0.0644],\n",
      "        [0.9064, 0.3936]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.8644, -0.1936], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 20000, Model : [Parameter containing:\n",
      "tensor([[0.8356, 0.0644],\n",
      "        [0.9064, 0.3936]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.8644, -0.1936], requires_grad=True)], Cost : 0.000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "# 데이터세트와 데이터로더를 import\n",
    "from torch.utils.data import TensorDataset, DataLoader \n",
    "\n",
    "# 다중 선형 회귀 -> X 와 Y 데이터를 (n,2) 차원 형태로 선언한다\n",
    "train_x = torch.FloatTensor([\n",
    "    [1, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7]\n",
    "])\n",
    "train_y = torch.FloatTensor([ # 정답값\n",
    "    [0.1, 1.5], [1, 2.8], [1.9, 4.1], [2.8, 5.4], [3.7, 6.7], [4.6, 8]\n",
    "])\n",
    "\n",
    "train_dataset = TensorDataset(train_x, train_y)\n",
    "# 데이터로더에서 배치 사이즈를 2로 설정, shuffle=True 로 데이터 순서를 변경, \n",
    "# drop_last=True 로 나머지 데이터는 사용하지 않음\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True, drop_last=True)\n",
    "\n",
    "# 모델 구조는 선형 변환 클래스를 사용하고, 입력/출력 데이터 차원은 2\n",
    "model = nn.Linear(2, 2, bias=True) \n",
    "criterion = nn.MSELoss() # 손실은 평균오차제곱으로 계산\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001) # 경사하강법으로 역전파 연산을 통해 최적화\n",
    "\n",
    "for epoch in range(20000):\n",
    "    cost = 0.0 # 에폭마다 오차를 계산하기 위해서 포기화\n",
    "    \n",
    "    for batch in train_dataloader:\n",
    "        x, y = batch # batch 변수에는 데이터세트에 입력한 순서대로 입력/출력값 x,y 가 저장되어 있음.\n",
    "        output = model(x)\n",
    "        \n",
    "        loss = criterion(output, y) # 결과값과 정답값을 비교해서 손실 계산\n",
    "        \n",
    "        # SGD 의 3단계\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "         \n",
    "        cost += loss #배치마다 오차에 손실값을 누적해서 더함\n",
    "\n",
    "\n",
    "\t\t# 오차의 평균값 계산하기 위해 len 메소드 사용하여 데이터로더의 길이를 구해서 나눔\n",
    "    cost = cost / len(train_dataloader)\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f\"Epoch : {epoch+1:4d}, Model : {list(model.parameters())}, Cost : {cost:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56f3ff97-799a-43c5-9c2c-36732a6eb1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1000, Model : [Parameter containing:\n",
      "tensor([[0.2151, 0.4008],\n",
      "        [0.5421, 0.6511]], requires_grad=True)], Cost : 0.060\n",
      "Epoch : 2000, Model : [Parameter containing:\n",
      "tensor([[0.5198, 0.1542],\n",
      "        [0.6566, 0.5585]], requires_grad=True)], Cost : 0.037\n",
      "Epoch : 3000, Model : [Parameter containing:\n",
      "tensor([[ 0.7620, -0.0416],\n",
      "        [ 0.7476,  0.4849]], requires_grad=True)], Cost : 0.048\n",
      "Epoch : 4000, Model : [Parameter containing:\n",
      "tensor([[ 0.9547, -0.1970],\n",
      "        [ 0.8200,  0.4265]], requires_grad=True)], Cost : 0.011\n",
      "Epoch : 5000, Model : [Parameter containing:\n",
      "tensor([[ 1.1076, -0.3209],\n",
      "        [ 0.8774,  0.3800]], requires_grad=True)], Cost : 0.019\n",
      "Epoch : 6000, Model : [Parameter containing:\n",
      "tensor([[ 1.2293, -0.4192],\n",
      "        [ 0.9232,  0.3431]], requires_grad=True)], Cost : 0.007\n",
      "Epoch : 7000, Model : [Parameter containing:\n",
      "tensor([[ 1.3258, -0.4974],\n",
      "        [ 0.9594,  0.3137]], requires_grad=True)], Cost : 0.008\n",
      "Epoch : 8000, Model : [Parameter containing:\n",
      "tensor([[ 1.4026, -0.5595],\n",
      "        [ 0.9883,  0.2904]], requires_grad=True)], Cost : 0.004\n",
      "Epoch : 9000, Model : [Parameter containing:\n",
      "tensor([[ 1.4636, -0.6089],\n",
      "        [ 1.0112,  0.2718]], requires_grad=True)], Cost : 0.002\n",
      "Epoch : 10000, Model : [Parameter containing:\n",
      "tensor([[ 1.5121, -0.6481],\n",
      "        [ 1.0294,  0.2571]], requires_grad=True)], Cost : 0.001\n",
      "Epoch : 11000, Model : [Parameter containing:\n",
      "tensor([[ 1.5507, -0.6793],\n",
      "        [ 1.0439,  0.2454]], requires_grad=True)], Cost : 0.001\n",
      "Epoch : 12000, Model : [Parameter containing:\n",
      "tensor([[ 1.5813, -0.7041],\n",
      "        [ 1.0554,  0.2360]], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 13000, Model : [Parameter containing:\n",
      "tensor([[ 1.6057, -0.7237],\n",
      "        [ 1.0646,  0.2287]], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 14000, Model : [Parameter containing:\n",
      "tensor([[ 1.6251, -0.7394],\n",
      "        [ 1.0718,  0.2228]], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 15000, Model : [Parameter containing:\n",
      "tensor([[ 1.6404, -0.7518],\n",
      "        [ 1.0776,  0.2181]], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 16000, Model : [Parameter containing:\n",
      "tensor([[ 1.6527, -0.7617],\n",
      "        [ 1.0822,  0.2144]], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 17000, Model : [Parameter containing:\n",
      "tensor([[ 1.6624, -0.7696],\n",
      "        [ 1.0859,  0.2114]], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 18000, Model : [Parameter containing:\n",
      "tensor([[ 1.6701, -0.7758],\n",
      "        [ 1.0888,  0.2091]], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 19000, Model : [Parameter containing:\n",
      "tensor([[ 1.6762, -0.7808],\n",
      "        [ 1.0911,  0.2072]], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 20000, Model : [Parameter containing:\n",
      "tensor([[ 1.6811, -0.7847],\n",
      "        [ 1.0929,  0.2057]], requires_grad=True)], Cost : 0.000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "# 데이터세트와 데이터로더를 import\n",
    "from torch.utils.data import TensorDataset, DataLoader \n",
    "\n",
    "# 다중 선형 회귀 -> X 와 Y 데이터를 (n,2) 차원 형태로 선언한다\n",
    "train_x = torch.FloatTensor([\n",
    "    [1, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7]\n",
    "])\n",
    "train_y = torch.FloatTensor([ # 정답값\n",
    "    [0.1, 1.5], [1, 2.8], [1.9, 4.1], [2.8, 5.4], [3.7, 6.7], [4.6, 8]\n",
    "])\n",
    "\n",
    "train_dataset = TensorDataset(train_x, train_y)\n",
    "# 데이터로더에서 배치 사이즈를 2로 설정, shuffle=True 로 데이터 순서를 변경, \n",
    "# drop_last=True 로 나머지 데이터는 사용하지 않음\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True, drop_last=True)\n",
    "\n",
    "# 모델 구조는 선형 변환 클래스를 사용하고, 입력/출력 데이터 차원은 2\n",
    "model = nn.Linear(2, 2, bias=False) \n",
    "criterion = nn.MSELoss() # 손실은 평균오차제곱으로 계산\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001) # 경사하강법으로 역전파 연산을 통해 최적화\n",
    "\n",
    "for epoch in range(20000):\n",
    "    cost = 0.0 # 에폭마다 오차를 계산하기 위해서 포기화\n",
    "    \n",
    "    for batch in train_dataloader:\n",
    "        x, y = batch # batch 변수에는 데이터세트에 입력한 순서대로 입력/출력값 x,y 가 저장되어 있음.\n",
    "        output = model(x)\n",
    "        \n",
    "        loss = criterion(output, y) # 결과값과 정답값을 비교해서 손실 계산\n",
    "        \n",
    "        # SGD 의 3단계\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "         \n",
    "        cost += loss #배치마다 오차에 손실값을 누적해서 더함\n",
    "\n",
    "\n",
    "\t\t# 오차의 평균값 계산하기 위해 len 메소드 사용하여 데이터로더의 길이를 구해서 나눔\n",
    "        cost = cost / len(train_dataloader)\n",
    "        \n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f\"Epoch : {epoch+1:4d}, Model : {list(model.parameters())}, Cost : {cost:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2291dcf-12d2-46b6-8bdc-31c3a4b31657",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../datasets/non_linear.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 31\u001b[0m\n\u001b[0;32m     28\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer(x)\n\u001b[0;32m     29\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m---> 31\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m CustomDataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../datasets/non_linear.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# 데이터 로더 설정\u001b[39;00m\n\u001b[0;32m     33\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, drop_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[10], line 9\u001b[0m, in \u001b[0;36mCustomDataset.__init__\u001b[1;34m(self, file_path)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, file_path): \u001b[38;5;66;03m# 초기화 메서드\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_path) \u001b[38;5;66;03m# 파일 경로로 데이터 불러와서 df 에 넣음 \u001b[39;00m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;66;03m# :,0 은 모든 행의 0열을 가져오라는 뜻 -> 입력값\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;66;03m# :,1 은 모든 행의 1열을 가져오라는 뜻 -> 정답값\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1706\u001b[0m     f,\n\u001b[0;32m   1707\u001b[0m     mode,\n\u001b[0;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1714\u001b[0m )\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../datasets/non_linear.csv'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, file_path): # 초기화 메서드\n",
    "        df = pd.read_csv(file_path) # 파일 경로로 데이터 불러와서 df 에 넣음 \n",
    "        self.x = df.iloc[:, 0].values # :,0 은 모든 행의 0열을 가져오라는 뜻 -> 입력값\n",
    "        self.y = df.iloc[:, 1].values # :,1 은 모든 행의 1열을 가져오라는 뜻 -> 정답값\n",
    "        self.length = len(df)\n",
    "\n",
    "    def __getitem__(self, index): # 호출 메서드\n",
    "        x = torch.FloatTensor([self.x[index] ** 2, self.x[index]]) # [x^2, x] 의 구조로 반환\n",
    "        y = torch.FloatTensor([self.y[index]]) # [y] 의 구조로 반환\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() # super() 로 부모클래스 초기화\n",
    "        self.layer = nn.Linear(2, 1) # 2차 이상의 함수이므로 (2,1)의 구조\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.layer(x)\n",
    "        return x\n",
    "\n",
    "train_dataset = CustomDataset(\"../datasets/non_linear.csv\")\n",
    "# 데이터 로더 설정\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True, drop_last=True)\n",
    "\n",
    "# GPU 연산 적용\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# 모델, 손실함수, 최적화함수 선언\n",
    "model = CustomModel().to(device)\n",
    "criterion = nn.MSELoss().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0001)\n",
    "\n",
    "for epoch in range(10000):\n",
    "    cost = 0.0 # 오차 초기화\n",
    "\n",
    "    for x, y in train_dataloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y) # 손실 계산\n",
    "        \n",
    "\t\t# SGD 의 3단계\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        cost += loss # 오차에 손실을 누적해서 계산\n",
    "\n",
    "    cost = cost / len(train_dataloader) # 전체 데이터길이를 이용해 손실의 평균을 계산, 갱신\n",
    "\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f\"Epoch : {epoch+1:4d}, Model : {list(model.parameters())}, Cost : {cost:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "321d30cd-8eaf-413a-ab34-6ef57d9dbbc3",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../datasets/non_linear.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer(x)\n\u001b[0;32m     31\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m---> 33\u001b[0m dataset \u001b[38;5;241m=\u001b[39m CustomDataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../datasets/non_linear.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     34\u001b[0m dataset_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataset)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# 데이터 분리를 위한 코드\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[11], line 10\u001b[0m, in \u001b[0;36mCustomDataset.__init__\u001b[1;34m(self, file_path)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, file_path):\n\u001b[1;32m---> 10\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_path)\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1706\u001b[0m     f,\n\u001b[0;32m   1707\u001b[0m     mode,\n\u001b[0;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1714\u001b[0m )\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../datasets/non_linear.csv'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "# split 을 위한 패키지 import \n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "        self.x = df.iloc[:, 0].values\n",
    "        self.y = df.iloc[:, 1].values\n",
    "        self.length = len(df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = torch.FloatTensor([self.x[index] ** 2, self.x[index]])\n",
    "        y = torch.FloatTensor([self.y[index]])\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Linear(2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer(x)\n",
    "        return x\n",
    "\n",
    "dataset = CustomDataset(\"../datasets/non_linear.csv\")\n",
    "dataset_size = len(dataset)\n",
    "\n",
    "# 데이터 분리를 위한 코드\n",
    "train_size = int(dataset_size * 0.8) # 데이터 세트의 합과 전체데이터세트의 개수가 일치할 수 있도록 정수형으로 변환\n",
    "validation_size = int(dataset_size * 0.1)\n",
    "test_size = dataset_size - train_size - validation_size\n",
    "\n",
    "train_dataset, validation_dataset, test_dataset = random_split(dataset, [train_size, validation_size, test_size])\n",
    "print(f\"Training Data Size : {len(train_dataset)}\")\n",
    "print(f\"Validation Data Size : {len(validation_dataset)}\")\n",
    "print(f\"Testing Data Size : {len(test_dataset)}\")\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, drop_last=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=4, shuffle=True, drop_last=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=True, drop_last=True)\n",
    "\n",
    "for epoch in range(10000):\n",
    "    cost = 0.0\n",
    "\n",
    "    for x, y in train_dataloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        cost += loss\n",
    "\n",
    "    cost = cost / len(train_dataloader)\n",
    "\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f\"Epoch : {epoch+1:4d}, Model : {list(model.parameters())}, Cost : {cost:.3f}\")\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for x, y in validation_dataloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        outputs = model(x)\n",
    "        print(f\"X : {x}\")\n",
    "        print(f\"Y : {y}\")\n",
    "        print(f\"Outputs : {outputs}\")\n",
    "        print(\"--------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "501d562a-1088-4b11-99a7-9b08b1e63ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_24036\\701116082.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_state_dict = torch.load(\"../models/model_state_dict.pt\", map_location=device)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../models/model_state_dict.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m model \u001b[38;5;241m=\u001b[39m CustomModel()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# \"../models/model_state_dict.pt\" 에는 추론에 필요한 가중치와 편향이 저장되어 있음\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m model_state_dict \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../models/model_state_dict.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m, map_location\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m     20\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(model_state_dict)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\serialization.py:1065\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   1063\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m-> 1065\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_like(f, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m   1066\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m   1067\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1068\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1069\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1070\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\serialization.py:468\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 468\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[0;32m    469\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    470\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\serialization.py:449\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mopen\u001b[39m(name, mode))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../models/model_state_dict.pt'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class CustomModel(nn.Module): # 불러오기 위해 CustomModel 클래스 선언\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Linear(2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer(x)\n",
    "        return x\n",
    "        \n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = CustomModel().to(device)\n",
    "\n",
    "# \"../models/model_state_dict.pt\" 에는 추론에 필요한 가중치와 편향이 저장되어 있음\n",
    "model_state_dict = torch.load(\"../models/model_state_dict.pt\", map_location=device)\n",
    "model.load_state_dict(model_state_dict)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval() # 평가 모드로 전환 후,\n",
    "    inputs = torch.FloatTensor(\n",
    "        [ # 임의의 데이터를 입력하여 추론을 진행\n",
    "            [1 ** 2, 1],\n",
    "            [5 ** 2, 5],\n",
    "            [11 ** 2, 11]\n",
    "        ]\n",
    "    ).to(device)\n",
    "    outputs = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f02723d-81ab-485e-9cee-651a93e2e4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:538: UserWarning: Using a target size (torch.Size([2, 2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Parent directory ../models does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m cost \u001b[38;5;241m=\u001b[39m cost \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_dataloader)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 21\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(\n\u001b[0;32m     22\u001b[0m         {\n\u001b[0;32m     23\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCustomModel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;66;03m# 모델의 이름 저장\u001b[39;00m\n\u001b[0;32m     24\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m: epoch, \u001b[38;5;66;03m# 에폭 저장\u001b[39;00m\n\u001b[0;32m     25\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_state_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m: model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;66;03m# 모델 상태 저장\u001b[39;00m\n\u001b[0;32m     26\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer_state_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m: optimizer\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;66;03m# 최적화 상태 저장\u001b[39;00m\n\u001b[0;32m     27\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcost\u001b[39m\u001b[38;5;124m\"\u001b[39m: cost, \u001b[38;5;66;03m# 손실 저장\u001b[39;00m\n\u001b[0;32m     28\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCustomModel 체크포인트-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcheckpoint\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     29\u001b[0m         },\n\u001b[0;32m     30\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../models/checkpoint-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcheckpoint\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     31\u001b[0m     )\n\u001b[0;32m     32\u001b[0m     checkpoint \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\serialization.py:651\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[0;32m    648\u001b[0m _check_save_filelike(f)\n\u001b[0;32m    650\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m--> 651\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m    652\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol, _disable_byteorder_record)\n\u001b[0;32m    653\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\serialization.py:525\u001b[0m, in \u001b[0;36m_open_zipfile_writer\u001b[1;34m(name_or_buffer)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    524\u001b[0m     container \u001b[38;5;241m=\u001b[39m _open_zipfile_writer_buffer\n\u001b[1;32m--> 525\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m container(name_or_buffer)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\serialization.py:496\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__init__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    494\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mPyTorchFileWriter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream))\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 496\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mPyTorchFileWriter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Parent directory ../models does not exist."
     ]
    }
   ],
   "source": [
    "checkpoint = 1 # 1에폭마다 저장\n",
    "for epoch in range(10000):\n",
    "    cost = 0.0\n",
    "\n",
    "    for x, y in train_dataloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        cost += loss\n",
    "\n",
    "    cost = cost / len(train_dataloader)\n",
    "\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        torch.save(\n",
    "            {\n",
    "                \"model\": \"CustomModel\", # 모델의 이름 저장\n",
    "                \"epoch\": epoch, # 에폭 저장\n",
    "                \"model_state_dict\": model.state_dict(), # 모델 상태 저장\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(), # 최적화 상태 저장\n",
    "                \"cost\": cost, # 손실 저장\n",
    "                \"description\": f\"CustomModel 체크포인트-{checkpoint}\",\n",
    "            },\n",
    "            f\"../models/checkpoint-{checkpoint}.pt\",\n",
    "        )\n",
    "        checkpoint += 1 # 다음 에폭으로 넘어간다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12760f09-901e-403d-b06f-2f40fb9a8d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_24036\\127876673.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\"../models/checkpoint-6.pt\")\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../models/checkpoint-6.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 중략.. #\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../models/checkpoint-6.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(checkpoint[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_state_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      5\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mload_state_dict(checkpoint[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer_state_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\serialization.py:1065\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   1063\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m-> 1065\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_like(f, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m   1066\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m   1067\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1068\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1069\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1070\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\serialization.py:468\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 468\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[0;32m    469\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    470\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\serialization.py:449\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mopen\u001b[39m(name, mode))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../models/checkpoint-6.pt'"
     ]
    }
   ],
   "source": [
    "# 중략.. #\n",
    "\n",
    "checkpoint = torch.load(\"../models/checkpoint-6.pt\")\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "checkpoint_epoch = checkpoint[\"epoch\"]\n",
    "checkpoint_description = checkpoint[\"description\"]\n",
    "print(checkpoint_description)\n",
    "\n",
    "for epoch in range(checkpoint_epoch + 1, 10000):\n",
    "    cost = 0.0\n",
    "\n",
    "    for x, y in train_dataloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        cost += loss\n",
    "        if (epoch + 1) % 1000 == 0:\n",
    "            print(f\"Epoch : {epoch+1:4d}, Model : {list(model.parameters())}, Cost : {cost:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad42755a-82f1-4afa-a7d2-02e383fd0efd",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../datasets/binary.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 41\u001b[0m\n\u001b[0;32m     37\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer(x)\n\u001b[0;32m     38\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m---> 41\u001b[0m dataset \u001b[38;5;241m=\u001b[39m CustomDataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../datasets/binary.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     42\u001b[0m dataset_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataset)\n\u001b[0;32m     43\u001b[0m train_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(dataset_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.8\u001b[39m)\n",
      "Cell \u001b[1;32mIn[15], line 9\u001b[0m, in \u001b[0;36mCustomDataset.__init__\u001b[1;34m(self, file_path)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, file_path):\n\u001b[1;32m----> 9\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_path)\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx1 \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx2 \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1706\u001b[0m     f,\n\u001b[0;32m   1707\u001b[0m     mode,\n\u001b[0;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1714\u001b[0m )\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../datasets/binary.csv'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "        self.x1 = df.iloc[:, 0].values\n",
    "        self.x2 = df.iloc[:, 1].values\n",
    "        self.x3 = df.iloc[:, 2].values\n",
    "        self.y = df.iloc[:, 3].values\n",
    "        self.length = len(df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\t\t    # 입력 데이터가 3개\n",
    "        x = torch.FloatTensor([self.x1[index], self.x2[index], self.x3[index]])\n",
    "        # 출력 데이터가 1개\n",
    "        y = torch.FloatTensor([int(self.y[index])])\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Sequential( # 여러 계층을 하나로 묶는 Sequential\n",
    "          nn.Linear(3, 1), # 입력 3개, 출력 1개\n",
    "          # 활성화 함수로 시그모이드를 사용해서 출력값을 범주화\n",
    "          nn.Sigmoid() \n",
    "        )\n",
    "\n",
    "    def forward(self, x): # 순전파 연산\n",
    "        x = self.layer(x)\n",
    "        return x\n",
    "        \n",
    "        \n",
    "dataset = CustomDataset(\"../datasets/binary.csv\")\n",
    "dataset_size = len(dataset)\n",
    "train_size = int(dataset_size * 0.8)\n",
    "validation_size = int(dataset_size * 0.1)\n",
    "test_size = dataset_size - train_size - validation_size\n",
    "\n",
    "train_dataset, validation_dataset, test_dataset = random_split(dataset, [train_size, validation_size, test_size], torch.manual_seed(4))\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, drop_last=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=4, shuffle=True, drop_last=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=True, drop_last=True)\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = CustomModel().to(device)\n",
    "criterion = nn.BCELoss().to(device) # 손실함수는 이진 교차 엔트로피\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0001)\n",
    "\n",
    "\n",
    "for epoch in range(10000):\n",
    "    cost = 0.0\n",
    "\n",
    "    for x, y in train_dataloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        cost += loss\n",
    "\n",
    "    cost = cost / len(train_dataloader)\n",
    "\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f\"Epoch : {epoch+1:4d}, Model : {list(model.parameters())}, Cost : {cost:.3f}\")\n",
    "        \n",
    "        \n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for x, y in validation_dataloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        outputs = model(x)\n",
    "\n",
    "        print(outputs)\n",
    "        print(outputs >= torch.FloatTensor([0.5]).to(device))\n",
    "        print(\"--------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a0a79b8-b5b3-4ea3-903a-a90be8b25cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "\t\t\t\t# 순전파와 역전파를 계산하는 모델은 두 계층으로 구성\n",
    "\t\t\t\n",
    "        self.layer1 = nn.Sequential( # 1계층\n",
    "            nn.Linear(2, 2), # x1, x2 의 입력 / z1, z2의 출력\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.layer2 = nn.Sequential( # 2계층\n",
    "            nn.Linear(2, 1), # o1, o2 의 입력 / z3의 출력\n",
    "            nn.Sigmoid() # 활성화 함수는 시그모이드\n",
    "        )\n",
    "        \n",
    "        self.layer1[0].weight.data = torch.nn.Parameter(\n",
    "            torch.Tensor([[0.4352, 0.3545],\n",
    "                         [0.1951, 0.4835]])\n",
    "        )\n",
    "\n",
    "        self.layer1[0].bias.data = torch.nn.Parameter(\n",
    "            torch.Tensor([-0.1419,  0.0439])\n",
    "        )\n",
    "\n",
    "        self.layer2[0].weight.data = torch.nn.Parameter(\n",
    "            torch.Tensor([[-0.1725,  0.1129]])\n",
    "        )\n",
    "\n",
    "        self.layer2[0].bias.data = torch.nn.Parameter(\n",
    "            torch.Tensor([-0.3043])\n",
    "        )\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = CustomModel().to(device)\n",
    "criterion = nn.BCELoss().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9eb59c3b-b673-4fa1-b8b8-8ec13562bfcb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Module [CustomModel] is missing the required \"forward\" function",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 51\u001b[0m\n\u001b[0;32m     48\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     49\u001b[0m y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 51\u001b[0m output \u001b[38;5;241m=\u001b[39m model(x)\n\u001b[0;32m     52\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, y)\n\u001b[0;32m     54\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:352\u001b[0m, in \u001b[0;36m_forward_unimplemented\u001b[1;34m(self, *input)\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward_unimplemented\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    342\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Define the computation performed at every call.\u001b[39;00m\n\u001b[0;32m    343\u001b[0m \n\u001b[0;32m    344\u001b[0m \u001b[38;5;124;03m    Should be overridden by all subclasses.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    350\u001b[0m \u001b[38;5;124;03m        registered hooks while the latter silently ignores them.\u001b[39;00m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 352\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModule [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] is missing the required \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m function\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Module [CustomModel] is missing the required \"forward\" function"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "\t\t\t\t# 순전파와 역전파를 계산하는 모델은 두 계층으로 구성\n",
    "\t\t\t\n",
    "        self.layer1 = nn.Sequential( # 1계층\n",
    "            nn.Linear(2, 2), # x1, x2 의 입력 / z1, z2의 출력\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.layer2 = nn.Sequential( # 2계층\n",
    "            nn.Linear(2, 1), # o1, o2 의 입력 / z3의 출력\n",
    "            nn.Sigmoid() # 활성화 함수는 시그모이드\n",
    "        )\n",
    "        \n",
    "        self.layer1[0].weight.data = torch.nn.Parameter(\n",
    "            torch.Tensor([[0.4352, 0.3545],\n",
    "                         [0.1951, 0.4835]])\n",
    "        )\n",
    "\n",
    "        self.layer1[0].bias.data = torch.nn.Parameter(\n",
    "            torch.Tensor([-0.1419,  0.0439])\n",
    "        )\n",
    "\n",
    "        self.layer2[0].weight.data = torch.nn.Parameter(\n",
    "            torch.Tensor([[-0.1725,  0.1129]])\n",
    "        )\n",
    "\n",
    "        self.layer2[0].bias.data = torch.nn.Parameter(\n",
    "            torch.Tensor([-0.3043])\n",
    "        )\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = CustomModel().to(device)\n",
    "criterion = nn.BCELoss().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1)\n",
    "\n",
    "\n",
    "for epoch in range(10000):\n",
    "    cost = 0.0\n",
    "\n",
    "    for x, y in train_dataloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        cost += loss\n",
    "\n",
    "    cost = cost / len(train_dataloader)\n",
    "\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f\"Epoch : {epoch+1:4d}, Cost : {cost:.3f}\")\n",
    "        \n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    inputs = torch.FloatTensor([\n",
    "        [0, 0],\n",
    "        [0, 1],\n",
    "        [1, 0],\n",
    "        [1, 1]\n",
    "    ]).to(device)\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    print(\"---------\")\n",
    "    print(outputs)\n",
    "    print(outputs <= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b82f3db-38a4-4b39-8baf-951f3757f964",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
