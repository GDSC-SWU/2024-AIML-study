{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "예제 5.01~5.02 단어 및 글자 토큰화"
      ],
      "metadata": {
        "id": "G9umIHedK1AI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xx9T5yJaKoIR",
        "outputId": "dcfdc39a-6800-409b-ab23-794fee07ea87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['현실과', '구분', '불가능한', 'cg.', '시각적', '즐거음은', '최고!', '더불어', 'ost는', '더더욱', '최고!!']\n"
          ]
        }
      ],
      "source": [
        "review = \" 현실과 구분 불가능한 cg. 시각적 즐거음은 최고! 더불어 ost는 더더욱 최고!!\"\n",
        "tokenized = review.split()\n",
        "print(tokenized)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "review = \"현실과 구분 불가능한 cg. 시각적 즐거음은 최고! 더불어 ost는 더더욱 최고!!\"\n",
        "tokenized = list(review)\n",
        "print(tokenized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MN5Hkv3K4m3",
        "outputId": "748dfe74-8f9f-45d0-89a9-c12dd3c1871c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['현', '실', '과', ' ', '구', '분', ' ', '불', '가', '능', '한', ' ', 'c', 'g', '.', ' ', '시', '각', '적', ' ', '즐', '거', '음', '은', ' ', '최', '고', '!', ' ', '더', '불', '어', ' ', 'o', 's', 't', '는', ' ', '더', '더', '욱', ' ', '최', '고', '!', '!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "예제 5.03 자소 단위 토큰화"
      ],
      "metadata": {
        "id": "JAf8mde5LCA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jamo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FduPTmCKLGBj",
        "outputId": "288e78b9-efdc-4882-a199-62c2d2e08719"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jamo\n",
            "  Downloading jamo-0.4.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Downloading jamo-0.4.1-py3-none-any.whl (9.5 kB)\n",
            "Installing collected packages: jamo\n",
            "Successfully installed jamo-0.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from jamo import h2j, j2hcj\n",
        "\n",
        "review = \"현실과 구분 불가능한 cg. 시각적 즐거음은 최고! 더불어 ost는 더더욱 최고!!\"\n",
        "decomposed = j2hcj(h2j(review))\n",
        "tokenized = list(decomposed)\n",
        "print(tokenized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVJjBKRrK6BZ",
        "outputId": "717a9d54-89f4-4f2f-8b7b-e0ae820bb47a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ㅎ', 'ㅕ', 'ㄴ', 'ㅅ', 'ㅣ', 'ㄹ', 'ㄱ', 'ㅘ', ' ', 'ㄱ', 'ㅜ', 'ㅂ', 'ㅜ', 'ㄴ', ' ', 'ㅂ', 'ㅜ', 'ㄹ', 'ㄱ', 'ㅏ', 'ㄴ', 'ㅡ', 'ㅇ', 'ㅎ', 'ㅏ', 'ㄴ', ' ', 'c', 'g', '.', ' ', 'ㅅ', 'ㅣ', 'ㄱ', 'ㅏ', 'ㄱ', 'ㅈ', 'ㅓ', 'ㄱ', ' ', 'ㅈ', 'ㅡ', 'ㄹ', 'ㄱ', 'ㅓ', 'ㅇ', 'ㅡ', 'ㅁ', 'ㅇ', 'ㅡ', 'ㄴ', ' ', 'ㅊ', 'ㅚ', 'ㄱ', 'ㅗ', '!', ' ', 'ㄷ', 'ㅓ', 'ㅂ', 'ㅜ', 'ㄹ', 'ㅇ', 'ㅓ', ' ', 'o', 's', 't', 'ㄴ', 'ㅡ', 'ㄴ', ' ', 'ㄷ', 'ㅓ', 'ㄷ', 'ㅓ', 'ㅇ', 'ㅜ', 'ㄱ', ' ', 'ㅊ', 'ㅚ', 'ㄱ', 'ㅗ', '!', '!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "예제 5.04~5.05 KoNLPy 토큰화"
      ],
      "metadata": {
        "id": "byWYnSSwLMVF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install konlpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSuoZ2FDLLNV",
        "outputId": "ea068aa8-cac7-42b9-f1c7-21cd395ec920"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting JPype1>=0.7.0 (from konlpy)\n",
            "  Downloading JPype1-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.4)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (24.1)\n",
            "Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading JPype1-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (488 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m488.6/488.6 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.5.0 konlpy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Okt\n",
        "\n",
        "okt = Okt()\n",
        "\n",
        "sentence = \"무엇이든 상상할 수 있는 사람은 무엇이든 만들어 낼 수 있다.\"\n",
        "\n",
        "nouns = okt.nouns(sentence)\n",
        "phrases = okt.phrases(sentence)\n",
        "morphs = okt.morphs(sentence)\n",
        "pos = okt.pos(sentence)\n",
        "\n",
        "print(\"명사 추출 :\", nouns)\n",
        "print(\"구 추출 :\", phrases)\n",
        "print(\"형태소 추출 :\", morphs)\n",
        "print(\"품사 태깅 :\", pos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zlf1z9g5LEon",
        "outputId": "0f3fd99c-f7f6-4101-8ae2-c8e7be6e7731"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "명사 추출 : ['무엇', '상상', '수', '사람', '무엇', '낼', '수']\n",
            "구 추출 : ['무엇', '상상', '상상할 수', '상상할 수 있는 사람', '사람']\n",
            "형태소 추출 : ['무엇', '이든', '상상', '할', '수', '있는', '사람', '은', '무엇', '이든', '만들어', '낼', '수', '있다', '.']\n",
            "품사 태깅 : [('무엇', 'Noun'), ('이든', 'Josa'), ('상상', 'Noun'), ('할', 'Verb'), ('수', 'Noun'), ('있는', 'Adjective'), ('사람', 'Noun'), ('은', 'Josa'), ('무엇', 'Noun'), ('이든', 'Josa'), ('만들어', 'Verb'), ('낼', 'Noun'), ('수', 'Noun'), ('있다', 'Adjective'), ('.', 'Punctuation')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Kkma\n",
        "\n",
        "kkma = Kkma()\n",
        "\n",
        "sentence = \"무엇이든 상상할 수 있는 사람은 무엇이든 만들어 낼 수 있다.\"\n",
        "\n",
        "nouns = kkma.nouns(sentence)\n",
        "sentences = kkma.sentences(sentence)\n",
        "morphs = kkma.morphs(sentence)\n",
        "pos = kkma.pos(sentence)\n",
        "\n",
        "print(\"명사 추출 :\", nouns)\n",
        "print(\"문장 추출 :\", sentences)\n",
        "print(\"형태소 추출 :\", morphs)\n",
        "print(\"품사 태깅 :\", pos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hd5wwhADLQv2",
        "outputId": "f5a29056-3e1c-4d75-8d20-867429ee11d0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "명사 추출 : ['무엇', '상상', '수', '사람', '무엇']\n",
            "문장 추출 : ['무엇이든 상상할 수 있는 사람은 무엇이든 만들어 낼 수 있다.']\n",
            "형태소 추출 : ['무엇', '이', '든', '상상', '하', 'ㄹ', '수', '있', '는', '사람', '은', '무엇', '이', '든', '만들', '어', '내', 'ㄹ', '수', '있', '다', '.']\n",
            "품사 태깅 : [('무엇', 'NNG'), ('이', 'VCP'), ('든', 'ECE'), ('상상', 'NNG'), ('하', 'XSV'), ('ㄹ', 'ETD'), ('수', 'NNB'), ('있', 'VV'), ('는', 'ETD'), ('사람', 'NNG'), ('은', 'JX'), ('무엇', 'NP'), ('이', 'VCP'), ('든', 'ECE'), ('만들', 'VV'), ('어', 'ECD'), ('내', 'VXV'), ('ㄹ', 'ETD'), ('수', 'NNB'), ('있', 'VV'), ('다', 'EFN'), ('.', 'SF')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "예제 5.06~5.08 NLTK 실습"
      ],
      "metadata": {
        "id": "4Wjrq6HyLZ9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"averaged_perceptron_tagger\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCQhBs1KLSwG",
        "outputId": "9deb2382-dffc-412f-c619-b1c65e8eb20e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import tokenize\n",
        "\n",
        "sentence = \"Those who can imagine anything, can create the impossible.\"\n",
        "\n",
        "word_tokens = tokenize.word_tokenize(sentence)\n",
        "sent_tokens = tokenize.sent_tokenize(sentence)\n",
        "\n",
        "print(word_tokens)\n",
        "print(sent_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqZ_Vs3DLcBn",
        "outputId": "faebc1e1-c770-47fb-e0c7-a666bf001bfb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Those', 'who', 'can', 'imagine', 'anything', ',', 'can', 'create', 'the', 'impossible', '.']\n",
            "['Those who can imagine anything, can create the impossible.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import tag\n",
        "from nltk import tokenize\n",
        "\n",
        "sentence = \"Those who can imagine anything, can create the impossible.\"\n",
        "\n",
        "word_tokens = tokenize.word_tokenize(sentence)\n",
        "pos = tag.pos_tag(word_tokens)\n",
        "\n",
        "print(pos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76OmACgbLfHb",
        "outputId": "d572a26b-0bef-4f9f-f306-1501593259e1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Those', 'DT'), ('who', 'WP'), ('can', 'MD'), ('imagine', 'VB'), ('anything', 'NN'), (',', ','), ('can', 'MD'), ('create', 'VB'), ('the', 'DT'), ('impossible', 'JJ'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "예제 5.09 spaCy 품사 태깅"
      ],
      "metadata": {
        "id": "kM4utklfLjYm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spaCy\n",
        "!python -m spacy download en_core_web__sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47BX0KraLhHU",
        "outputId": "b70ef5e2-1384-479b-aaf7-f085b90ccde5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spaCy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spaCy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spaCy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spaCy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spaCy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spaCy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spaCy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spaCy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (0.12.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (4.66.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spaCy) (2.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spaCy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spaCy) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spaCy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spaCy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spaCy) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spaCy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spaCy) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spaCy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spaCy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spaCy) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spaCy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spaCy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spaCy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spaCy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spaCy) (13.9.2)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spaCy) (0.19.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spaCy) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spaCy) (3.0.1)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spaCy) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spaCy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spaCy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spaCy) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spaCy) (0.1.2)\n",
            "\n",
            "\u001b[38;5;1m✘ No compatible package found for 'en_core_web__sm' (spaCy v3.7.5)\u001b[0m\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "sentence = \"Those who can imagine anything, can create the impossible.\"\n",
        "doc = nlp(sentence)\n",
        "\n",
        "for token in doc:\n",
        "    print(f\"[{token.pos_:5} - {token.tag_:3}] : {token.text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6W9-WvlLmME",
        "outputId": "88942b56-003f-4c7a-8fe9-587e56c84c5c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[PRON  - DT ] : Those\n",
            "[PRON  - WP ] : who\n",
            "[AUX   - MD ] : can\n",
            "[VERB  - VB ] : imagine\n",
            "[PRON  - NN ] : anything\n",
            "[PUNCT - ,  ] : ,\n",
            "[AUX   - MD ] : can\n",
            "[VERB  - VB ] : create\n",
            "[DET   - DT ] : the\n",
            "[ADJ   - JJ ] : impossible\n",
            "[PUNCT - .  ] : .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "예제 5.10 청와대 청원 데이터 다운로드"
      ],
      "metadata": {
        "id": "n1Rr-sHoLtLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece Korpora"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paMy29qCLxut",
        "outputId": "bba3c4df-5b33-44b8-e688-2a4df8d2ddd0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: Korpora in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: dataclasses>=0.6 in /usr/local/lib/python3.10/dist-packages (from Korpora) (0.6)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from Korpora) (1.26.4)\n",
            "Requirement already satisfied: tqdm>=4.46.0 in /usr/local/lib/python3.10/dist-packages (from Korpora) (4.66.5)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.10/dist-packages (from Korpora) (2.32.3)\n",
            "Requirement already satisfied: xlrd>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from Korpora) (2.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->Korpora) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->Korpora) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->Korpora) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->Korpora) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from Korpora import Korpora\n",
        "\n",
        "corpus = Korpora.load(\"korean_petitions\")\n",
        "dataset = corpus.train\n",
        "petition = dataset[0]\n",
        "\n",
        "print(\"청원 시작일 :\", petition.begin)\n",
        "print(\"청원 종료일 :\", petition.end)\n",
        "print(\"청원 동의 수 :\", petition.num_agree)\n",
        "print(\"청원 범주 :\", petition.category)\n",
        "print(\"청원 제목 :\", petition.title)\n",
        "print(\"청원 본문 :\", petition.text[:30])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b-mKEs4Lplj",
        "outputId": "267b82d9-de46-4e43-ae79-033c24940a09"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    Korpora 는 다른 분들이 연구 목적으로 공유해주신 말뭉치들을\n",
            "    손쉽게 다운로드, 사용할 수 있는 기능만을 제공합니다.\n",
            "\n",
            "    말뭉치들을 공유해 주신 분들에게 감사드리며, 각 말뭉치 별 설명과 라이센스를 공유 드립니다.\n",
            "    해당 말뭉치에 대해 자세히 알고 싶으신 분은 아래의 description 을 참고,\n",
            "    해당 말뭉치를 연구/상용의 목적으로 이용하실 때에는 아래의 라이센스를 참고해 주시기 바랍니다.\n",
            "\n",
            "    # Description\n",
            "    Author : Hyunjoong Kim lovit@github\n",
            "    Repository : https://github.com/lovit/petitions_archive\n",
            "    References :\n",
            "\n",
            "    청와대 국민청원 게시판의 데이터를 월별로 수집한 것입니다.\n",
            "    청원은 게시판에 글을 올린 뒤, 한달 간 청원이 진행됩니다.\n",
            "    수집되는 데이터는 청원종료가 된 이후의 데이터이며, 청원 내 댓글은 수집되지 않습니다.\n",
            "    단 청원의 동의 개수는 수집됩니다.\n",
            "    자세한 내용은 위의 repository를 참고하세요.\n",
            "\n",
            "    # License\n",
            "    CC0 1.0 Universal (CC0 1.0) Public Domain Dedication\n",
            "    Details in https://creativecommons.org/publicdomain/zero/1.0/\n",
            "\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2017-08\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2017-09\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2017-10\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2017-11\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2017-12\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2018-01\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2018-02\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2018-03\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2018-04\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2018-05\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2018-06\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2018-07\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2018-08\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2018-09\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2018-10\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2018-11\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2018-12\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2019-01\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2019-02\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2019-03\n",
            "청원 시작일 : 2017-08-25\n",
            "청원 종료일 : 2017-09-24\n",
            "청원 동의 수 : 88\n",
            "청원 범주 : 육아/교육\n",
            "청원 제목 : 학교는 인력센터, 취업센터가 아닙니다. 정말 간곡히 부탁드립니다.\n",
            "청원 본문 : 안녕하세요. 현재 사대, 교대 등 교원양성학교들의 예비\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "예제 5.11 학습 데이터세트 생성"
      ],
      "metadata": {
        "id": "PwVIAE9lL947"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from Korpora import Korpora\n",
        "\n",
        "corpus = Korpora.load(\"korean_petitions\")\n",
        "petitions = corpus.get_all_texts()\n",
        "with open(\"corpus.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for petition in petitions:\n",
        "        f.write(petition + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHpvLEydLyet",
        "outputId": "90cfa2f9-c0d0-4c6a-ba4a-677e628ac3df"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    Korpora 는 다른 분들이 연구 목적으로 공유해주신 말뭉치들을\n",
            "    손쉽게 다운로드, 사용할 수 있는 기능만을 제공합니다.\n",
            "\n",
            "    말뭉치들을 공유해 주신 분들에게 감사드리며, 각 말뭉치 별 설명과 라이센스를 공유 드립니다.\n",
            "    해당 말뭉치에 대해 자세히 알고 싶으신 분은 아래의 description 을 참고,\n",
            "    해당 말뭉치를 연구/상용의 목적으로 이용하실 때에는 아래의 라이센스를 참고해 주시기 바랍니다.\n",
            "\n",
            "    # Description\n",
            "    Author : Hyunjoong Kim lovit@github\n",
            "    Repository : https://github.com/lovit/petitions_archive\n",
            "    References :\n",
            "\n",
            "    청와대 국민청원 게시판의 데이터를 월별로 수집한 것입니다.\n",
            "    청원은 게시판에 글을 올린 뒤, 한달 간 청원이 진행됩니다.\n",
            "    수집되는 데이터는 청원종료가 된 이후의 데이터이며, 청원 내 댓글은 수집되지 않습니다.\n",
            "    단 청원의 동의 개수는 수집됩니다.\n",
            "    자세한 내용은 위의 repository를 참고하세요.\n",
            "\n",
            "    # License\n",
            "    CC0 1.0 Universal (CC0 1.0) Public Domain Dedication\n",
            "    Details in https://creativecommons.org/publicdomain/zero/1.0/\n",
            "\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2017-08\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2017-09\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2017-10\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2017-11\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2017-12\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2018-01\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2018-02\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2018-03\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2018-04\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2018-05\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2018-06\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2018-07\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2018-08\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2018-09\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2018-10\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2018-11\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2018-12\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2019-01\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2019-02\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2019-03\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "예제 5.12 토크나이저 모델 학습"
      ],
      "metadata": {
        "id": "t7Dn7jmWMAkf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentencepiece import SentencePieceTrainer\n",
        "\n",
        "SentencePieceTrainer.Train(\n",
        "    \"--input=corpus.txt\\\n",
        "    --model_prefix=petition_bpe\\\n",
        "    --vocab_size=8000 model_type=bpe\"\n",
        ")"
      ],
      "metadata": {
        "id": "_KmmPqL5L-K6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "예제 5.13 바이트 페어 인코딩 토큰화"
      ],
      "metadata": {
        "id": "LEfN21IaN6pB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentencepiece import SentencePieceProcessor\n",
        "\n",
        "tokenizer = SentencePieceProcessor()\n",
        "tokenizer.load(\"petition_bpe.model\")\n",
        "\n",
        "sentence = \"안녕하세요, 토크나이저가 잘 학습되었군요!\"\n",
        "sentences = [\"이렇게 입력값을 리스트로 받아서\", \"쉽게 토크나이저를 사용할 수 있답니다\"]\n",
        "\n",
        "tokenized_sentence = tokenizer.encode_as_pieces(sentence)\n",
        "tokenized_sentences = tokenizer.encode_as_pieces(sentences)\n",
        "print(\"단일 문장 토큰화 :\", tokenized_sentence)\n",
        "print(\"여러 문장 토큰화 :\", tokenized_sentences)\n",
        "\n",
        "encoded_sentence = tokenizer.encode_as_ids(sentence)\n",
        "encoded_sentences = tokenizer.encode_as_ids(sentences)\n",
        "print(\"단일 문장 정수 인코딩 :\", encoded_sentence)\n",
        "print(\"여러 문장 정수 인코딩 :\", encoded_sentences)\n",
        "\n",
        "decode_ids = tokenizer.decode_ids(encoded_sentences)\n",
        "decode_pieces = tokenizer.decode_pieces(encoded_sentences)\n",
        "print(\"정수 인코딩에서 문장 변환 :\", decode_ids)\n",
        "print(\"하위 단어 토큰에서 문장 변환 :\", decode_pieces)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EM5pBmCrMI6p",
        "outputId": "6b30854f-e335-4f6d-ad87-59f6712d4c5d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단일 문장 토큰화 : ['▁안녕하세요', ',', '▁토', '크', '나', '이', '저', '가', '▁잘', '▁학', '습', '되었', '군요', '!']\n",
            "여러 문장 토큰화 : [['▁이렇게', '▁입', '력', '값을', '▁리', '스트', '로', '▁받아서'], ['▁쉽게', '▁토', '크', '나', '이', '저', '를', '▁사용할', '▁수', '▁있', '답니다']]\n",
            "단일 문장 정수 인코딩 : [667, 6553, 994, 6880, 6544, 6513, 6590, 6523, 161, 110, 6554, 872, 787, 6648]\n",
            "여러 문장 정수 인코딩 : [[372, 182, 6677, 4433, 1772, 1613, 6527, 4162], [1681, 994, 6880, 6544, 6513, 6590, 6536, 5852, 19, 5, 2639]]\n",
            "정수 인코딩에서 문장 변환 : ['이렇게 입력값을 리스트로 받아서', '쉽게 토크나이저를 사용할 수 있답니다']\n",
            "하위 단어 토큰에서 문장 변환 : ['이렇게 입력값을 리스트로 받아서', '쉽게 토크나이저를 사용할 수 있답니다']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "예제 5.14 어휘 사전 불러오기"
      ],
      "metadata": {
        "id": "ZfKIiD0ZOAaG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentencepiece import SentencePieceProcessor\n",
        "\n",
        "tokenizer = SentencePieceProcessor()\n",
        "tokenizer.load(\"petition_bpe.model\")\n",
        "\n",
        "vocab = {idx: tokenizer.id_to_piece(idx) for idx in range(tokenizer.get_piece_size())}\n",
        "print(list(vocab.items())[:5])\n",
        "print(\"vocab size :\", len(vocab))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnDjUs5YN-ne",
        "outputId": "5fe85253-fd00-4419-d33b-820df83a026a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, '<unk>'), (1, '<s>'), (2, '</s>'), (3, '니다'), (4, '▁이')]\n",
            "vocab size : 8000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "예제 5.15 워드피스 토크나이저 학습"
      ],
      "metadata": {
        "id": "eYVMN4SFOFgW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import WordPiece\n",
        "from tokenizers.normalizers import Sequence, NFD, Lowercase\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "\n",
        "tokenizer = Tokenizer(WordPiece())\n",
        "tokenizer.normalizer = Sequence([NFD(), Lowercase()])\n",
        "tokenizer.pre_tokenizer = Whitespace()\n",
        "\n",
        "tokenizer.train([\"corpus.txt\"])\n",
        "tokenizer.save(\"petition_wordpiece.json\")"
      ],
      "metadata": {
        "id": "gXQTXGWrODnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "예제 5.16 워드피스 토큰화"
      ],
      "metadata": {
        "id": "FLwry1XcOM2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tokenizers import Tokenizer\n",
        "from tokenizers.decoders import WordPiece as WordPieceDecoder\n",
        "\n",
        "tokenizer = Tokenizer.from_file(\"petition_wordpiece.json\")\n",
        "tokenizer.decoder = WordPieceDecoder()\n",
        "\n",
        "sentence = \"안녕하세요, 토크나이저가 잘 학습되었군요!\"\n",
        "sentences = [\"이렇게 입력값을 리스트로 받아서\", \"쉽게 토크나이저를 사용할 수 있답니다\"]\n",
        "\n",
        "encoded_sentence = tokenizer.encode(sentence)\n",
        "encoded_sentences = tokenizer.encode_batch(sentences)\n",
        "\n",
        "print(\"인코더 형식 :\", type(encoded_sentence))\n",
        "\n",
        "print(\"단일 문장 토큰화 :\", encoded_sentence.tokens)\n",
        "print(\"여러 문장 토큰화 :\", [enc.tokens for enc in encoded_sentences])\n",
        "\n",
        "print(\"단일 문장 정수 인코딩 :\", encoded_sentence.ids)\n",
        "print(\"여러 문장 정수 인코딩 :\", [enc.ids for enc in encoded_sentences])\n",
        "\n",
        "print(\"정수 인코딩에서 문장 변환 :\", tokenizer.decode(encoded_sentence.ids))"
      ],
      "metadata": {
        "id": "I-4PabGiOKpV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}