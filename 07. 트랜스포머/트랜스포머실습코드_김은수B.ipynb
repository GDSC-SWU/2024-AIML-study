{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "374ca708-10e7-47c8-b9f9-c0969277d0c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 07장 트랜스포머/예제 7.01 위치 인코딩.ipynb\n",
    "\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model)\n",
    "        )\n",
    "\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[: x.size(0)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "encoding = PositionalEncoding(d_model=128, max_len=50)\n",
    "\n",
    "plt.pcolormesh(encoding.pe.numpy().squeeze(), cmap=\"RdBu\")\n",
    "plt.xlabel(\"Embedding Dimension\")\n",
    "plt.xlim((0, 128))\n",
    "plt.ylabel(\"Position\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68da87e9-2f2f-49a4-893e-c2925fe2a534",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\anaconda3\\envs\\GDG_env\\python.exe: No module named spacy\n",
      "C:\\Users\\Lenovo\\anaconda3\\envs\\GDG_env\\python.exe: No module named spacy\n"
     ]
    }
   ],
   "source": [
    "# 07장 트랜스포머/예제 7.02~7.08 트랜스포머 모델 번역 결과.ipynb\n",
    "\n",
    "!python -m spacy download de\n",
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc05298e-fc98-447e-94b3-fa011de9cbe6",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 127] 지정된 프로시저를 찾을 수 없습니다",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Multi30k\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_tokenizer\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvocab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_vocab_from_iterator\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torchtext\\__init__.py:18\u001b[0m\n\u001b[0;32m     15\u001b[0m     _WARN \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# the following import has to happen first in order to load the torchtext C++ library\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _extension  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     20\u001b[0m _TEXT_BUCKET \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://download.pytorch.org/models/text/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     22\u001b[0m _CACHE_DIR \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(_get_torch_home(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torchtext\\_extension.py:64\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m# This import is for initializing the methods registered via PyBind11\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;66;03m# This has to happen after the base library is loaded\u001b[39;00m\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _torchtext  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m _init_extension()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torchtext\\_extension.py:58\u001b[0m, in \u001b[0;36m_init_extension\u001b[1;34m()\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _mod_utils\u001b[38;5;241m.\u001b[39mis_module_available(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorchtext._torchtext\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorchtext C++ Extension is not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 58\u001b[0m _load_lib(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibtorchtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# This import is for initializing the methods registered via PyBind11\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# This has to happen after the base library is loaded\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _torchtext\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torchtext\\_extension.py:50\u001b[0m, in \u001b[0;36m_load_lib\u001b[1;34m(lib)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m torch\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mload_library(path)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\_ops.py:1295\u001b[0m, in \u001b[0;36m_Ops.load_library\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m   1290\u001b[0m path \u001b[38;5;241m=\u001b[39m _utils_internal\u001b[38;5;241m.\u001b[39mresolve_library_path(path)\n\u001b[0;32m   1291\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m dl_open_guard():\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;66;03m# Import the shared library into the process, thus running its\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m     \u001b[38;5;66;03m# static (global) initialization code in order to register custom\u001b[39;00m\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;66;03m# operators with the JIT.\u001b[39;00m\n\u001b[1;32m-> 1295\u001b[0m     ctypes\u001b[38;5;241m.\u001b[39mCDLL(path)\n\u001b[0;32m   1296\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloaded_libraries\u001b[38;5;241m.\u001b[39madd(path)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\ctypes\\__init__.py:376\u001b[0m, in \u001b[0;36mCDLL.__init__\u001b[1;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_FuncPtr \u001b[38;5;241m=\u001b[39m _FuncPtr\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 376\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m _dlopen(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, mode)\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    378\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m handle\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 127] 지정된 프로시저를 찾을 수 없습니다"
     ]
    }
   ],
   "source": [
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "\n",
    "def generate_tokens(text_iter, language):\n",
    "    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n",
    "\n",
    "    for text in text_iter:\n",
    "        yield token_transform[language](text[language_index[language]])\n",
    "\n",
    "\n",
    "SRC_LANGUAGE = \"de\"\n",
    "TGT_LANGUAGE = \"en\"\n",
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "special_symbols = [\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"]\n",
    "\n",
    "token_transform = {\n",
    "    SRC_LANGUAGE: get_tokenizer(\"spacy\", language=\"de_core_news_sm\"),\n",
    "    TGT_LANGUAGE: get_tokenizer(\"spacy\", language=\"en_core_web_sm\"),\n",
    "}\n",
    "print(\"Token Transform:\")\n",
    "print(token_transform)\n",
    "\n",
    "vocab_transform = {}\n",
    "for language in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    train_iter = Multi30k(split=\"train\", language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "    vocab_transform[language] = build_vocab_from_iterator(\n",
    "        generate_tokens(train_iter, language),\n",
    "        min_freq=1,\n",
    "        specials=special_symbols,\n",
    "        special_first=True,\n",
    "    )\n",
    "\n",
    "for language in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    vocab_transform[language].set_default_index(UNK_IDX)\n",
    "\n",
    "print(\"Vocab Transform:\")\n",
    "print(vocab_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5a4ef7e-8a03-4b92-b851-b0938c4898ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model)\n",
    "        )\n",
    "\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[: x.size(0)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "    def forward(self, tokens):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
    "\n",
    "\n",
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_encoder_layers,\n",
    "        num_decoder_layers,\n",
    "        emb_size,\n",
    "        max_len,\n",
    "        nhead,\n",
    "        src_vocab_size,\n",
    "        tgt_vocab_size,\n",
    "        dim_feedforward,\n",
    "        dropout=0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
    "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
    "        self.positional_encoding = PositionalEncoding(\n",
    "            d_model=emb_size, max_len=max_len, dropout=dropout\n",
    "        )\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=emb_size,\n",
    "            nhead=nhead,\n",
    "            num_encoder_layers=num_encoder_layers,\n",
    "            num_decoder_layers=num_decoder_layers,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        src,\n",
    "        trg,\n",
    "        src_mask,\n",
    "        tgt_mask,\n",
    "        src_padding_mask,\n",
    "        tgt_padding_mask,\n",
    "        memory_key_padding_mask,\n",
    "    ):\n",
    "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
    "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
    "        outs = self.transformer(\n",
    "            src=src_emb,\n",
    "            tgt=tgt_emb,\n",
    "            src_mask=src_mask,\n",
    "            tgt_mask=tgt_mask,\n",
    "            memory_mask=None,\n",
    "            src_key_padding_mask=src_padding_mask,\n",
    "            tgt_key_padding_mask=tgt_padding_mask,\n",
    "            memory_key_padding_mask=memory_key_padding_mask\n",
    "        )\n",
    "        return self.generator(outs)\n",
    "\n",
    "    def encode(self, src, src_mask):\n",
    "        return self.transformer.encoder(\n",
    "            self.positional_encoding(self.src_tok_emb(src)), src_mask\n",
    "        )\n",
    "\n",
    "    def decode(self, tgt, memory, tgt_mask):\n",
    "        return self.transformer.decoder(\n",
    "            self.positional_encoding(self.tgt_tok_emb(tgt)), memory, tgt_mask\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d122e9f-1bfa-449e-8ece-28958b220d37",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vocab_transform' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 13\u001b[0m\n\u001b[0;32m      4\u001b[0m BATCH_SIZE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m\n\u001b[0;32m      5\u001b[0m DEVICE \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m Seq2SeqTransformer(\n\u001b[0;32m      8\u001b[0m     num_encoder_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m      9\u001b[0m     num_decoder_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m     10\u001b[0m     emb_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m,\n\u001b[0;32m     11\u001b[0m     max_len\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m,\n\u001b[0;32m     12\u001b[0m     nhead\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,\n\u001b[1;32m---> 13\u001b[0m     src_vocab_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(vocab_transform[SRC_LANGUAGE]),\n\u001b[0;32m     14\u001b[0m     tgt_vocab_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(vocab_transform[TGT_LANGUAGE]),\n\u001b[0;32m     15\u001b[0m     dim_feedforward\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m,\n\u001b[0;32m     16\u001b[0m )\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m     17\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(ignore_index\u001b[38;5;241m=\u001b[39mPAD_IDX)\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m     18\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vocab_transform' is not defined"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = Seq2SeqTransformer(\n",
    "    num_encoder_layers=3,\n",
    "    num_decoder_layers=3,\n",
    "    emb_size=512,\n",
    "    max_len=512,\n",
    "    nhead=8,\n",
    "    src_vocab_size=len(vocab_transform[SRC_LANGUAGE]),\n",
    "    tgt_vocab_size=len(vocab_transform[TGT_LANGUAGE]),\n",
    "    dim_feedforward=512,\n",
    ").to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX).to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "for main_name, main_module in model.named_children():\n",
    "    print(main_name)\n",
    "    for sub_name, sub_module in main_module.named_children():\n",
    "        print(\"└\", sub_name)\n",
    "        for ssub_name, ssub_module in sub_module.named_children():\n",
    "            print(\"│  └\", ssub_name)\n",
    "            for sssub_name, sssub_module in ssub_module.named_children():\n",
    "                print(\"│  │  └\", sssub_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66f8c47a-6f93-4590-8596-669f9f99233f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SRC_LANGUAGE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 29\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m src_batch, tgt_batch\n\u001b[0;32m     28\u001b[0m text_transform \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m language \u001b[38;5;129;01min\u001b[39;00m [SRC_LANGUAGE, TGT_LANGUAGE]:\n\u001b[0;32m     30\u001b[0m     text_transform[language] \u001b[38;5;241m=\u001b[39m sequential_transforms(\n\u001b[0;32m     31\u001b[0m         token_transform[language], vocab_transform[language], input_transform\n\u001b[0;32m     32\u001b[0m     )\n\u001b[0;32m     34\u001b[0m data_iter \u001b[38;5;241m=\u001b[39m Multi30k(split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m\"\u001b[39m, language_pair\u001b[38;5;241m=\u001b[39m(SRC_LANGUAGE, TGT_LANGUAGE))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SRC_LANGUAGE' is not defined"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "def sequential_transforms(*transforms):\n",
    "    def func(txt_input):\n",
    "        for transform in transforms:\n",
    "            txt_input = transform(txt_input)\n",
    "        return txt_input\n",
    "    return func\n",
    "\n",
    "def input_transform(token_ids):\n",
    "    return torch.cat(\n",
    "        (torch.tensor([BOS_IDX]), torch.tensor(token_ids), torch.tensor([EOS_IDX]))\n",
    "    )\n",
    "\n",
    "def collator(batch):\n",
    "    src_batch, tgt_batch = [], []\n",
    "    for src_sample, tgt_sample in batch:\n",
    "        src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\")))\n",
    "        tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n",
    "\n",
    "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
    "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
    "    return src_batch, tgt_batch\n",
    "\n",
    "\n",
    "text_transform = {}\n",
    "for language in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    text_transform[language] = sequential_transforms(\n",
    "        token_transform[language], vocab_transform[language], input_transform\n",
    "    )\n",
    "\n",
    "data_iter = Multi30k(split=\"valid\", language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "dataloader = DataLoader(data_iter, batch_size=BATCH_SIZE, collate_fn=collator)\n",
    "source_tensor, target_tensor = next(iter(dataloader))\n",
    "\n",
    "print(\"(source, target):\")\n",
    "print(next(iter(data_iter)))\n",
    "\n",
    "print(\"source_batch:\", source_tensor.shape)\n",
    "print(source_tensor)\n",
    "\n",
    "print(\"target_batch:\", target_tensor.shape)\n",
    "print(target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03d06e98-bef4-414f-be77-980261694756",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'target_tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 23\u001b[0m\n\u001b[0;32m     19\u001b[0m     tgt_padding_mask \u001b[38;5;241m=\u001b[39m (tgt \u001b[38;5;241m==\u001b[39m PAD_IDX)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m src_mask, tgt_mask, src_padding_mask, tgt_padding_mask\n\u001b[1;32m---> 23\u001b[0m target_input \u001b[38;5;241m=\u001b[39m target_tensor[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n\u001b[0;32m     24\u001b[0m target_out \u001b[38;5;241m=\u001b[39m target_tensor[\u001b[38;5;241m1\u001b[39m:, :]\n\u001b[0;32m     26\u001b[0m source_mask, target_mask, source_padding_mask, target_padding_mask \u001b[38;5;241m=\u001b[39m create_mask(\n\u001b[0;32m     27\u001b[0m     source_tensor, target_input\n\u001b[0;32m     28\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'target_tensor' is not defined"
     ]
    }
   ],
   "source": [
    "def generate_square_subsequent_mask(s):\n",
    "    mask = (torch.triu(torch.ones((s, s), device=DEVICE)) == 1).transpose(0, 1)\n",
    "    mask = (\n",
    "        mask.float()\n",
    "        .masked_fill(mask == 0, float(\"-inf\"))\n",
    "        .masked_fill(mask == 1, float(0.0))\n",
    "    )\n",
    "    return mask\n",
    "\n",
    "\n",
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[0]\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len), device=DEVICE).type(torch.bool)\n",
    "\n",
    "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
    "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask\n",
    "\n",
    "\n",
    "target_input = target_tensor[:-1, :]\n",
    "target_out = target_tensor[1:, :]\n",
    "\n",
    "source_mask, target_mask, source_padding_mask, target_padding_mask = create_mask(\n",
    "    source_tensor, target_input\n",
    ")\n",
    "\n",
    "print(\"source_mask:\", source_mask.shape)\n",
    "print(source_mask)\n",
    "print(\"target_mask:\", target_mask.shape)\n",
    "print(target_mask)\n",
    "print(\"source_padding_mask:\", source_padding_mask.shape)\n",
    "print(source_padding_mask)\n",
    "print(\"target_padding_mask:\", target_padding_mask.shape)\n",
    "print(target_padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1902307-4a2a-462a-8034-874f09953efc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 39\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m losses \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mlist\u001b[39m(dataloader))\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m---> 39\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m run(model, optimizer, criterion, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     40\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m run(model, optimizer, criterion, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Val loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "def run(model, optimizer, criterion, split):\n",
    "    model.train() if split == \"train\" else model.eval()\n",
    "    data_iter = Multi30k(split=split, language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "    dataloader = DataLoader(data_iter, batch_size=BATCH_SIZE, collate_fn=collator)\n",
    "    \n",
    "    losses = 0\n",
    "    for source_batch, target_batch in dataloader:\n",
    "        source_batch = source_batch.to(DEVICE)\n",
    "        target_batch = target_batch.to(DEVICE)\n",
    "\n",
    "        target_input = target_batch[:-1, :]\n",
    "        target_output = target_batch[1:, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(\n",
    "            source_batch, target_input\n",
    "        )\n",
    "\n",
    "        logits = model(\n",
    "            src=source_batch,\n",
    "            trg=target_input,\n",
    "            src_mask=src_mask,\n",
    "            tgt_mask=tgt_mask,\n",
    "            src_padding_mask=src_padding_mask,\n",
    "            tgt_padding_mask=tgt_padding_mask,\n",
    "            memory_key_padding_mask=src_padding_mask,\n",
    "        )\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(logits.reshape(-1, logits.shape[-1]), target_output.reshape(-1))\n",
    "        if split == \"train\":\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses / len(list(dataloader))\n",
    "\n",
    "\n",
    "for epoch in range(5):\n",
    "    train_loss = run(model, optimizer, criterion, \"train\")\n",
    "    val_loss = run(model, optimizer, criterion, \"valid\")\n",
    "    print(f\"Epoch: {epoch+1}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2710673d-e12a-48f4-95a6-67c9f50796e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 38\u001b[0m\n\u001b[0;32m     34\u001b[0m     output \u001b[38;5;241m=\u001b[39m vocab_transform[TGT_LANGUAGE]\u001b[38;5;241m.\u001b[39mlookup_tokens(\u001b[38;5;28mlist\u001b[39m(tgt_tokens\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()))[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(output)\n\u001b[1;32m---> 38\u001b[0m output_oov \u001b[38;5;241m=\u001b[39m translate(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEine Gruppe von Menschen steht vor einem Iglu .\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m output \u001b[38;5;241m=\u001b[39m translate(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEine Gruppe von Menschen steht vor einem Gebäude .\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(output_oov)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "def greedy_decode(model, source_tensor, source_mask, max_len, start_symbol):\n",
    "    source_tensor = source_tensor.to(DEVICE)\n",
    "    source_mask = source_mask.to(DEVICE)\n",
    "\n",
    "    memory = model.encode(source_tensor, source_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
    "    for i in range(max_len - 1):\n",
    "        memory = memory.to(DEVICE)\n",
    "        target_mask = generate_square_subsequent_mask(ys.size(0))\n",
    "        target_mask = target_mask.type(torch.bool).to(DEVICE)\n",
    "\n",
    "        out = model.decode(ys, memory, target_mask)\n",
    "        out = out.transpose(0, 1)\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.item()\n",
    "\n",
    "        ys = torch.cat(\n",
    "            [ys, torch.ones(1, 1).type_as(source_tensor.data).fill_(next_word)], dim=0\n",
    "        )\n",
    "        if next_word == EOS_IDX:\n",
    "            break\n",
    "    return ys\n",
    "\n",
    "\n",
    "def translate(model, source_sentence):\n",
    "    model.eval()\n",
    "    source_tensor = text_transform[SRC_LANGUAGE](source_sentence).view(-1, 1)\n",
    "    num_tokens = source_tensor.shape[0]\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    tgt_tokens = greedy_decode(\n",
    "        model, source_tensor, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX\n",
    "    ).flatten()\n",
    "    output = vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))[1:-1]\n",
    "    return \" \".join(output)\n",
    "\n",
    "\n",
    "output_oov = translate(model, \"Eine Gruppe von Menschen steht vor einem Iglu .\")\n",
    "output = translate(model, \"Eine Gruppe von Menschen steht vor einem Gebäude .\")\n",
    "print(output_oov)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9d9306a-b12c-443d-b3b4-fcbb235dfb8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02e3a780604d4dfbbe526cb00c4c5dd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b8b7542c75a4321bf71214e7e95194f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ef95d0b3b0048459d9a08d00ea6cde9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer\n",
      "└ wte\n",
      "└ wpe\n",
      "└ drop\n",
      "└ h\n",
      "│  └ 0\n",
      "│  │  └ ln_1\n",
      "│  │  └ attn\n",
      "│  │  └ ln_2\n",
      "│  │  └ mlp\n",
      "│  └ 1\n",
      "│  │  └ ln_1\n",
      "│  │  └ attn\n",
      "│  │  └ ln_2\n",
      "│  │  └ mlp\n",
      "│  └ 2\n",
      "│  │  └ ln_1\n",
      "│  │  └ attn\n",
      "│  │  └ ln_2\n",
      "│  │  └ mlp\n",
      "│  └ 3\n",
      "│  │  └ ln_1\n",
      "│  │  └ attn\n",
      "│  │  └ ln_2\n",
      "│  │  └ mlp\n",
      "│  └ 4\n",
      "│  │  └ ln_1\n",
      "│  │  └ attn\n",
      "│  │  └ ln_2\n",
      "│  │  └ mlp\n",
      "│  └ 5\n",
      "│  │  └ ln_1\n",
      "│  │  └ attn\n",
      "│  │  └ ln_2\n",
      "│  │  └ mlp\n",
      "│  └ 6\n",
      "│  │  └ ln_1\n",
      "│  │  └ attn\n",
      "│  │  └ ln_2\n",
      "│  │  └ mlp\n",
      "│  └ 7\n",
      "│  │  └ ln_1\n",
      "│  │  └ attn\n",
      "│  │  └ ln_2\n",
      "│  │  └ mlp\n",
      "│  └ 8\n",
      "│  │  └ ln_1\n",
      "│  │  └ attn\n",
      "│  │  └ ln_2\n",
      "│  │  └ mlp\n",
      "│  └ 9\n",
      "│  │  └ ln_1\n",
      "│  │  └ attn\n",
      "│  │  └ ln_2\n",
      "│  │  └ mlp\n",
      "│  └ 10\n",
      "│  │  └ ln_1\n",
      "│  │  └ attn\n",
      "│  │  └ ln_2\n",
      "│  │  └ mlp\n",
      "│  └ 11\n",
      "│  │  └ ln_1\n",
      "│  │  └ attn\n",
      "│  │  └ ln_2\n",
      "│  │  └ mlp\n",
      "└ ln_f\n",
      "lm_head\n"
     ]
    }
   ],
   "source": [
    "# 07장 트랜스포머/예제 7.09 문장 생성을 위한 GPT-2 모델의 구조.ipynb\n",
    "\n",
    "from transformers import GPT2LMHeadModel\n",
    "\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(pretrained_model_name_or_path=\"gpt2\")\n",
    "\n",
    "for main_name, main_module in model.named_children():\n",
    "    print(main_name)\n",
    "    for sub_name, sub_module in main_module.named_children():\n",
    "        print(\"└\", sub_name)\n",
    "        for ssub_name, ssub_module in sub_module.named_children():\n",
    "            print(\"│  └\", ssub_name)\n",
    "            for sssub_name, sssub_module in ssub_module.named_children():\n",
    "                print(\"│  │  └\", sssub_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "953b34ff-c4a2-499a-baa0-a9f783e7ddf5",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.pipelines because of the following error (look up to see its traceback):\noperator torchvision::nms does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1603\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1602\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1603\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   1604\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1147\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:940\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\__init__.py:26\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PreTrainedFeatureExtractor\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_processing_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseImageProcessor\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_auto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoConfig\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\image_processing_utils.py:21\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_processing_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BatchFeature, ImageProcessingMixin\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_transforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m center_crop, normalize, rescale\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChannelDimension\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\image_transforms.py:22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     23\u001b[0m     ChannelDimension,\n\u001b[0;32m     24\u001b[0m     ImageInput,\n\u001b[0;32m     25\u001b[0m     get_channel_dimension_axis,\n\u001b[0;32m     26\u001b[0m     get_image_size,\n\u001b[0;32m     27\u001b[0m     infer_channel_dimension_format,\n\u001b[0;32m     28\u001b[0m )\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExplicitEnum, TensorType, is_jax_tensor, is_tf_tensor, is_torch_tensor\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\image_utils.py:58\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torchvision_available():\n\u001b[1;32m---> 58\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InterpolationMode\n\u001b[0;32m     60\u001b[0m     pil_torch_interpolation_mapping \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     61\u001b[0m         PILImageResampling\u001b[38;5;241m.\u001b[39mNEAREST: InterpolationMode\u001b[38;5;241m.\u001b[39mNEAREST,\n\u001b[0;32m     62\u001b[0m         PILImageResampling\u001b[38;5;241m.\u001b[39mBOX: InterpolationMode\u001b[38;5;241m.\u001b[39mBOX,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m         PILImageResampling\u001b[38;5;241m.\u001b[39mLANCZOS: InterpolationMode\u001b[38;5;241m.\u001b[39mLANCZOS,\n\u001b[0;32m     67\u001b[0m     }\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torchvision\\__init__.py:6\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations, datasets, io, models, ops, transforms, utils\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextension\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _HAS_OPS\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torchvision\\_meta_registrations.py:163\u001b[0m\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m grad\u001b[38;5;241m.\u001b[39mnew_empty((batch_size, channels, height, width))\n\u001b[1;32m--> 163\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39m_custom_ops\u001b[38;5;241m.\u001b[39mimpl_abstract(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorchvision::nms\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmeta_nms\u001b[39m(dets, scores, iou_threshold):\n\u001b[0;32m    165\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_check(dets\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m, \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboxes should be a 2d tensor, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdets\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\library.py:654\u001b[0m, in \u001b[0;36mregister_fake.<locals>.register\u001b[1;34m(func)\u001b[0m\n\u001b[0;32m    653\u001b[0m     use_lib \u001b[38;5;241m=\u001b[39m lib\n\u001b[1;32m--> 654\u001b[0m use_lib\u001b[38;5;241m.\u001b[39m_register_fake(op_name, func, _stacklevel\u001b[38;5;241m=\u001b[39mstacklevel \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    655\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\library.py:154\u001b[0m, in \u001b[0;36mLibrary._register_fake\u001b[1;34m(self, op_name, fn, _stacklevel)\u001b[0m\n\u001b[0;32m    152\u001b[0m     func_to_register \u001b[38;5;241m=\u001b[39m fn\n\u001b[1;32m--> 154\u001b[0m handle \u001b[38;5;241m=\u001b[39m entry\u001b[38;5;241m.\u001b[39mabstract_impl\u001b[38;5;241m.\u001b[39mregister(func_to_register, source)\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registration_handles\u001b[38;5;241m.\u001b[39mappend(handle)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\_library\\abstract_impl.py:31\u001b[0m, in \u001b[0;36mAbstractImplHolder.register\u001b[1;34m(self, func, source)\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregister_fake(...): the operator \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqualname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     28\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malready has an fake impl registered at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     29\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel\u001b[38;5;241m.\u001b[39msource\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     30\u001b[0m     )\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_dispatch_has_kernel_for_dispatch_key(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqualname, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMeta\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregister_fake(...): the operator \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqualname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     34\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malready has an DispatchKey::Meta implementation via a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregister_fake.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     38\u001b[0m     )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: operator torchvision::nms does not exist",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 07장 트랜스포머/예제 7.10 GPT-2를 이용한 문장 생성.ipynb\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[0;32m      6\u001b[0m generator \u001b[38;5;241m=\u001b[39m pipeline(task\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-generation\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m outputs \u001b[38;5;241m=\u001b[39m generator(\n\u001b[0;32m      8\u001b[0m     text_inputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMachine learning is\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      9\u001b[0m     max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[0;32m     10\u001b[0m     num_return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m     11\u001b[0m     pad_token_id\u001b[38;5;241m=\u001b[39mgenerator\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39meos_token_id\n\u001b[0;32m     12\u001b[0m )\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1229\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1593\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1591\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(name)\n\u001b[0;32m   1592\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m-> 1593\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[0;32m   1594\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[0;32m   1595\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1605\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1603\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   1604\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1605\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1606\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1607\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1608\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to import transformers.pipelines because of the following error (look up to see its traceback):\noperator torchvision::nms does not exist"
     ]
    }
   ],
   "source": [
    "# 07장 트랜스포머/예제 7.10 GPT-2를 이용한 문장 생성.ipynb\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "generator = pipeline(task=\"text-generation\", model=\"gpt2\")\n",
    "outputs = generator(\n",
    "    text_inputs=\"Machine learning is\",\n",
    "    max_length=20,\n",
    "    num_return_sequences=3,\n",
    "    pad_token_id=generator.tokenizer.eos_token_id\n",
    ")\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2dcbf4a7-426a-429d-8948-c151f5ba1b21",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 127] 지정된 프로시저를 찾을 수 없습니다",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 07장 트랜스포머/예제 7.11~7.14 GPT-2 모델 실습.ipynb\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CoLA\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torchtext\\__init__.py:18\u001b[0m\n\u001b[0;32m     15\u001b[0m     _WARN \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# the following import has to happen first in order to load the torchtext C++ library\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _extension  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     20\u001b[0m _TEXT_BUCKET \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://download.pytorch.org/models/text/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     22\u001b[0m _CACHE_DIR \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(_get_torch_home(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torchtext\\_extension.py:64\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m# This import is for initializing the methods registered via PyBind11\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;66;03m# This has to happen after the base library is loaded\u001b[39;00m\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _torchtext  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m _init_extension()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torchtext\\_extension.py:58\u001b[0m, in \u001b[0;36m_init_extension\u001b[1;34m()\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _mod_utils\u001b[38;5;241m.\u001b[39mis_module_available(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorchtext._torchtext\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorchtext C++ Extension is not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 58\u001b[0m _load_lib(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibtorchtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# This import is for initializing the methods registered via PyBind11\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# This has to happen after the base library is loaded\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _torchtext\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torchtext\\_extension.py:50\u001b[0m, in \u001b[0;36m_load_lib\u001b[1;34m(lib)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m torch\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mload_library(path)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\_ops.py:1295\u001b[0m, in \u001b[0;36m_Ops.load_library\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m   1290\u001b[0m path \u001b[38;5;241m=\u001b[39m _utils_internal\u001b[38;5;241m.\u001b[39mresolve_library_path(path)\n\u001b[0;32m   1291\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m dl_open_guard():\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;66;03m# Import the shared library into the process, thus running its\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m     \u001b[38;5;66;03m# static (global) initialization code in order to register custom\u001b[39;00m\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;66;03m# operators with the JIT.\u001b[39;00m\n\u001b[1;32m-> 1295\u001b[0m     ctypes\u001b[38;5;241m.\u001b[39mCDLL(path)\n\u001b[0;32m   1296\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloaded_libraries\u001b[38;5;241m.\u001b[39madd(path)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\ctypes\\__init__.py:376\u001b[0m, in \u001b[0;36mCDLL.__init__\u001b[1;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_FuncPtr \u001b[38;5;241m=\u001b[39m _FuncPtr\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 376\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m _dlopen(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, mode)\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    378\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m handle\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 127] 지정된 프로시저를 찾을 수 없습니다"
     ]
    }
   ],
   "source": [
    "# 07장 트랜스포머/예제 7.11~7.14 GPT-2 모델 실습.ipynb\n",
    "\n",
    "import torch\n",
    "from torchtext.datasets import CoLA\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def collator(batch, tokenizer, device):\n",
    "    source, labels, texts = zip(*batch)\n",
    "    tokenized = tokenizer(\n",
    "        texts,\n",
    "        padding=\"longest\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    input_ids = tokenized[\"input_ids\"].to(device)\n",
    "    attention_mask = tokenized[\"attention_mask\"].to(device)\n",
    "    labels = torch.tensor(labels, dtype=torch.long).to(device)\n",
    "    return input_ids, attention_mask, labels\n",
    "\n",
    "\n",
    "train_data = list(CoLA(split=\"train\"))\n",
    "valid_data = list(CoLA(split=\"dev\"))\n",
    "test_data = list(CoLA(split=\"test\"))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "epochs = 3\n",
    "batch_size = 16\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=lambda x: collator(x, tokenizer, device),\n",
    "    shuffle=True,\n",
    ")\n",
    "valid_dataloader = DataLoader(\n",
    "    valid_data, batch_size=batch_size, collate_fn=lambda x: collator(x, tokenizer, device)\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_data, batch_size=batch_size, collate_fn=lambda x: collator(x, tokenizer, device)\n",
    ")\n",
    "\n",
    "print(\"Train Dataset Length :\", len(train_data))\n",
    "print(\"Valid Dataset Length :\", len(valid_data))\n",
    "print(\"Test Dataset Length :\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0028ad1-62d7-403d-9f78-115f1b5a1649",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 8\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optim\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GPT2ForSequenceClassification\n\u001b[0;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m GPT2ForSequenceClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m      6\u001b[0m     pretrained_model_name_or_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt2\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      7\u001b[0m     num_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m----> 8\u001b[0m )\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpad_token_id \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39meos_token_id\n\u001b[0;32m     10\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5e-5\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "from transformers import GPT2ForSequenceClassification\n",
    "\n",
    "\n",
    "model = GPT2ForSequenceClassification.from_pretrained(\n",
    "    pretrained_model_name_or_path=\"gpt2\",\n",
    "    num_labels=2\n",
    ").to(device)\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ded4b9b6-ba77-431f-ba2a-9a20c823be65",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'epochs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 59\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m val_loss, val_accuracy\n\u001b[0;32m     58\u001b[0m best_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10000\u001b[39m\n\u001b[1;32m---> 59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m     60\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m train(model, optimizer, train_dataloader)\n\u001b[0;32m     61\u001b[0m     val_loss, val_accuracy \u001b[38;5;241m=\u001b[39m evaluation(model, valid_dataloader)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'epochs' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "def calc_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "def train(model, optimizer, dataloader):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for input_ids, attention_mask, labels in dataloader:\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "\n",
    "        loss = outputs.loss\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss = train_loss / len(dataloader)\n",
    "    return train_loss\n",
    "\n",
    "def evaluation(model, dataloader):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        val_loss, val_accuracy = 0.0, 0.0\n",
    "        \n",
    "        for input_ids, attention_mask, labels in dataloader:\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "            logits = outputs.logits\n",
    "\n",
    "            loss = criterion(logits, labels)\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            label_ids = labels.to(\"cpu\").numpy()\n",
    "            accuracy = calc_accuracy(logits, label_ids)\n",
    "            \n",
    "            val_loss += loss\n",
    "            val_accuracy += accuracy\n",
    "    \n",
    "    val_loss = val_loss/len(dataloader)\n",
    "    val_accuracy = val_accuracy/len(dataloader)\n",
    "    return val_loss, val_accuracy\n",
    "\n",
    "\n",
    "best_loss = 10000\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train(model, optimizer, train_dataloader)\n",
    "    val_loss, val_accuracy = evaluation(model, valid_dataloader)\n",
    "    print(f\"Epoch {epoch + 1}: Train Loss: {train_loss:.4f} Val Loss: {val_loss:.4f} Val Accuracy {val_accuracy:.4f}\")\n",
    "\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"../models/GPT2ForSequenceClassification.pt\")\n",
    "        print(\"Saved the model weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df818898-e21b-4824-a3cd-a48a8af31b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m GPT2ForSequenceClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m      2\u001b[0m     pretrained_model_name_or_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt2\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m     num_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m----> 4\u001b[0m )\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpad_token_id \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39meos_token_id\n\u001b[0;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../models/GPT2ForSequenceClassification.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "model = GPT2ForSequenceClassification.from_pretrained(\n",
    "    pretrained_model_name_or_path=\"gpt2\",\n",
    "    num_labels=2\n",
    ").to(device)\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "model.load_state_dict(torch.load(\"../models/GPT2ForSequenceClassification.pt\"))\n",
    "\n",
    "test_loss, test_accuracy = evaluation(model, test_dataloader)\n",
    "print(f\"Test Loss : {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy : {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2fdf51b7-06e8-4073-b35a-fe01dcc534e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Korpora'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mKorpora\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Korpora\n\u001b[0;32m      8\u001b[0m corpus \u001b[38;5;241m=\u001b[39m Korpora\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnsmc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(corpus\u001b[38;5;241m.\u001b[39mtest)\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;241m20000\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'Korpora'"
     ]
    }
   ],
   "source": [
    "# 07장 트랜스포머/예제 7.15~7.17 BERT 모델 실습.ipynb\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Korpora import Korpora\n",
    "\n",
    "\n",
    "corpus = Korpora.load(\"nsmc\")\n",
    "df = pd.DataFrame(corpus.test).sample(20000, random_state=42)\n",
    "train, valid, test = np.split(\n",
    "    df.sample(frac=1, random_state=42), [int(0.6 * len(df)), int(0.8 * len(df))]\n",
    ")\n",
    "\n",
    "print(train.head(5).to_markdown())\n",
    "print(f\"Training Data Size : {len(train)}\")\n",
    "print(f\"Validation Data Size : {len(valid)}\")\n",
    "print(f\"Testing Data Size : {len(test)}\")\n",
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data import RandomSampler, SequentialSampler\n",
    "\n",
    "\n",
    "def make_dataset(data, tokenizer, device):\n",
    "    tokenized = tokenizer(\n",
    "        text=data.text.tolist(),\n",
    "        padding=\"longest\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    input_ids = tokenized[\"input_ids\"].to(device)\n",
    "    attention_mask = tokenized[\"attention_mask\"].to(device)\n",
    "    labels = torch.tensor(data.label.values, dtype=torch.long).to(device)\n",
    "    return TensorDataset(input_ids, attention_mask, labels)\n",
    "\n",
    "\n",
    "def get_datalodader(dataset, sampler, batch_size):\n",
    "    data_sampler = sampler(dataset)\n",
    "    dataloader = DataLoader(dataset, sampler=data_sampler, batch_size=batch_size)\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 32\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    pretrained_model_name_or_path=\"bert-base-multilingual-cased\",\n",
    "    do_lower_case=False\n",
    ")\n",
    "\n",
    "train_dataset = make_dataset(train, tokenizer, device)\n",
    "train_dataloader = get_datalodader(train_dataset, RandomSampler, batch_size)\n",
    "\n",
    "valid_dataset = make_dataset(valid, tokenizer, device)\n",
    "valid_dataloader = get_datalodader(valid_dataset, SequentialSampler, batch_size)\n",
    "\n",
    "test_dataset = make_dataset(test, tokenizer, device)\n",
    "test_dataloader = get_datalodader(test_dataset, SequentialSampler, batch_size)\n",
    "\n",
    "print(train_dataset[0])\n",
    "from torch import optim\n",
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    pretrained_model_name_or_path=\"bert-base-multilingual-cased\",\n",
    "    num_labels=2\n",
    ").to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-5, eps=1e-8)\n",
    "for main_name, main_module in model.named_children():\n",
    "    print(main_name)\n",
    "    for sub_name, sub_module in main_module.named_children():\n",
    "        print(\"└\", sub_name)\n",
    "        for ssub_name, ssub_module in sub_module.named_children():\n",
    "            print(\"│  └\", ssub_name)\n",
    "            for sssub_name, sssub_module in ssub_module.named_children():\n",
    "                print(\"│  │  └\", sssub_name)\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "def calc_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "def train(model, optimizer, dataloader):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for input_ids, attention_mask, labels in dataloader:\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "\n",
    "        loss = outputs.loss\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss = train_loss / len(dataloader)\n",
    "    return train_loss\n",
    "\n",
    "def evaluation(model, dataloader):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        val_loss, val_accuracy = 0.0, 0.0\n",
    "        \n",
    "        for input_ids, attention_mask, labels in dataloader:\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            loss = criterion(logits, labels)\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            label_ids = labels.to(\"cpu\").numpy()\n",
    "            accuracy = calc_accuracy(logits, label_ids)\n",
    "            \n",
    "            val_loss += loss\n",
    "            val_accuracy += accuracy\n",
    "    \n",
    "    val_loss = val_loss/len(dataloader)\n",
    "    val_accuracy = val_accuracy/len(dataloader)\n",
    "    return val_loss, val_accuracy\n",
    "\n",
    "\n",
    "best_loss = 10000\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train(model, optimizer, train_dataloader)\n",
    "    val_loss, val_accuracy = evaluation(model, valid_dataloader)\n",
    "    print(f\"Epoch {epoch + 1}: Train Loss: {train_loss:.4f} Val Loss: {val_loss:.4f} Val Accuracy {val_accuracy:.4f}\")\n",
    "\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"../models/BertForSequenceClassification.pt\")\n",
    "        print(\"Saved the model weights\")\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    pretrained_model_name_or_path=\"bert-base-multilingual-cased\",\n",
    "    num_labels=2\n",
    ").to(device)\n",
    "model.load_state_dict(torch.load(\"../models/BertForSequenceClassification.pt\"))\n",
    "\n",
    "test_loss, test_accuracy = evaluation(model, test_dataloader)\n",
    "print(f\"Test Loss : {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy : {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6097d23-3740-4b0d-acf6-57723d419c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\n",
      "  Using cached evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: absl-py in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (2.1.0)\n",
      "Collecting datasets>=2.0.0 (from evaluate)\n",
      "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\lenovo\\anaconda3\\envs\\gdg_env\\lib\\site-packages (from evaluate) (2.0.1)\n",
      "Collecting dill (from evaluate)\n",
      "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\lenovo\\anaconda3\\envs\\gdg_env\\lib\\site-packages (from evaluate) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\lenovo\\anaconda3\\envs\\gdg_env\\lib\\site-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\lenovo\\anaconda3\\envs\\gdg_env\\lib\\site-packages (from evaluate) (4.66.5)\n",
      "Collecting xxhash (from evaluate)\n",
      "  Downloading xxhash-3.5.0-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess (from evaluate)\n",
      "  Downloading multiprocess-0.70.17-py312-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in c:\\users\\lenovo\\anaconda3\\envs\\gdg_env\\lib\\site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in c:\\users\\lenovo\\anaconda3\\envs\\gdg_env\\lib\\site-packages (from evaluate) (0.25.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\lenovo\\anaconda3\\envs\\gdg_env\\lib\\site-packages (from evaluate) (24.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\lenovo\\anaconda3\\envs\\gdg_env\\lib\\site-packages (from rouge_score) (3.9.1)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\lenovo\\anaconda3\\envs\\gdg_env\\lib\\site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\lenovo\\anaconda3\\envs\\gdg_env\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\n",
      "Collecting pyarrow>=15.0.0 (from datasets>=2.0.0->evaluate)\n",
      "  Downloading pyarrow-18.0.0-cp312-cp312-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting dill (from evaluate)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting multiprocess (from evaluate)\n",
      "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting aiohttp (from datasets>=2.0.0->evaluate)\n",
      "  Downloading aiohttp-3.10.10-cp312-cp312-win_amd64.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\lenovo\\anaconda3\\envs\\gdg_env\\lib\\site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\lenovo\\anaconda3\\envs\\gdg_env\\lib\\site-packages (from huggingface-hub>=0.7.0->evaluate) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lenovo\\anaconda3\\envs\\gdg_env\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\anaconda3\\envs\\gdg_env\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\anaconda3\\envs\\gdg_env\\lib\\site-packages (from requests>=2.19.0->evaluate) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\anaconda3\\envs\\gdg_env\\lib\\site-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\anaconda3\\envs\\gdg_env\\lib\\site-packages (from tqdm>=4.62.1->evaluate) (0.4.6)\n",
      "Requirement already satisfied: click in c:\\users\\lenovo\\anaconda3\\envs\\gdg_env\\lib\\site-packages (from nltk->rouge_score) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\lenovo\\anaconda3\\envs\\gdg_env\\lib\\site-packages (from nltk->rouge_score) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\lenovo\\anaconda3\\envs\\gdg_env\\lib\\site-packages (from nltk->rouge_score) (2024.9.11)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lenovo\\anaconda3\\envs\\gdg_env\\lib\\site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lenovo\\anaconda3\\envs\\gdg_env\\lib\\site-packages (from pandas->evaluate) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lenovo\\anaconda3\\envs\\gdg_env\\lib\\site-packages (from pandas->evaluate) (2024.2)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets>=2.0.0->evaluate)\n",
      "  Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets>=2.0.0->evaluate)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->datasets>=2.0.0->evaluate)\n",
      "  Using cached attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets>=2.0.0->evaluate)\n",
      "  Downloading frozenlist-1.5.0-cp312-cp312-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets>=2.0.0->evaluate)\n",
      "  Downloading multidict-6.1.0-cp312-cp312-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting yarl<2.0,>=1.12.0 (from aiohttp->datasets>=2.0.0->evaluate)\n",
      "  Downloading yarl-1.17.1-cp312-cp312-win_amd64.whl.metadata (66 kB)\n",
      "Collecting propcache>=0.2.0 (from yarl<2.0,>=1.12.0->aiohttp->datasets>=2.0.0->evaluate)\n",
      "  Downloading propcache-0.2.0-cp312-cp312-win_amd64.whl.metadata (7.9 kB)\n",
      "Using cached evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Downloading xxhash-3.5.0-cp312-cp312-win_amd64.whl (30 kB)\n",
      "Downloading aiohttp-3.10.10-cp312-cp312-win_amd64.whl (379 kB)\n",
      "Downloading pyarrow-18.0.0-cp312-cp312-win_amd64.whl (25.1 MB)\n",
      "   ---------------------------------------- 0.0/25.1 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 3.9/25.1 MB 19.6 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 8.7/25.1 MB 19.9 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 15.2/25.1 MB 23.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 23.6/25.1 MB 27.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.1/25.1 MB 24.1 MB/s eta 0:00:00\n",
      "Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Downloading frozenlist-1.5.0-cp312-cp312-win_amd64.whl (51 kB)\n",
      "Downloading multidict-6.1.0-cp312-cp312-win_amd64.whl (28 kB)\n",
      "Downloading yarl-1.17.1-cp312-cp312-win_amd64.whl (89 kB)\n",
      "Downloading propcache-0.2.0-cp312-cp312-win_amd64.whl (44 kB)\n",
      "Building wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (setup.py): started\n",
      "  Building wheel for rouge_score (setup.py): finished with status 'done'\n",
      "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24971 sha256=a41ca1c4e79a25084d8f6ee518f22eb0d74c28055da2aad161eeba8460fd2b8f\n",
      "  Stored in directory: c:\\users\\lenovo\\appdata\\local\\pip\\cache\\wheels\\85\\9d\\af\\01feefbe7d55ef5468796f0c68225b6788e85d9d0a281e7a70\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: xxhash, pyarrow, propcache, multidict, frozenlist, dill, attrs, aiohappyeyeballs, yarl, multiprocess, aiosignal, rouge_score, aiohttp, datasets, evaluate\n",
      "Successfully installed aiohappyeyeballs-2.4.3 aiohttp-3.10.10 aiosignal-1.3.1 attrs-24.2.0 datasets-3.1.0 dill-0.3.8 evaluate-0.4.3 frozenlist-1.5.0 multidict-6.1.0 multiprocess-0.70.16 propcache-0.2.0 pyarrow-18.0.0 rouge_score-0.1.2 xxhash-3.5.0 yarl-1.17.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80a55bb78bbe4167916a1e93b5b2878e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/2.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5450f7fc01bd4017bb9b1d32e1bcc7d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.54M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83cd4f36e5fa4dcdb36db45a66fa9d44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/31.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2223cbd9c7904e1caba96080a5cf1b75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a4dd20d81ec480c905464e664cffd22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/20417 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source News : DANANG, Vietnam (Reuters) - Russian President Vladimir Putin said on Saturday he had a normal dialogue with U.S. leader Donald Trump at a summit in Vietnam, and described Trump as civil, well-educated\n",
      "Summarization : Putin says had useful interaction with Trump at Vi\n",
      "Training Data Size : 3000\n",
      "Validation Data Size : 1000\n",
      "Testing Data Size : 1000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b74be507de5f428ab26569bb302e67d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 07장 트랜스포머/예제 7.18~7.23 BART 모델 실습.ipynb\n",
    "\n",
    "!pip install evaluate rouge_score absl-py\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "news = load_dataset(\"argilla/news-summary\", split=\"test\")\n",
    "df = news.to_pandas().sample(5000, random_state=42)[[\"text\", \"prediction\"]]\n",
    "df[\"prediction\"] = df[\"prediction\"].map(lambda x: x[0][\"text\"])\n",
    "train, valid, test = np.split(\n",
    "    df.sample(frac=1, random_state=42), [int(0.6 * len(df)), int(0.8 * len(df))]\n",
    ")\n",
    "\n",
    "print(f\"Source News : {train.text.iloc[0][:200]}\")\n",
    "print(f\"Summarization : {train.prediction.iloc[0][:50]}\")\n",
    "print(f\"Training Data Size : {len(train)}\")\n",
    "print(f\"Validation Data Size : {len(valid)}\")\n",
    "print(f\"Testing Data Size : {len(test)}\")\n",
    "import torch\n",
    "from transformers import BartTokenizer\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data import RandomSampler, SequentialSampler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "def make_dataset(data, tokenizer, device):\n",
    "    tokenized = tokenizer(\n",
    "        text=data.text.tolist(),\n",
    "        padding=\"longest\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "        max_length=1024\n",
    "    )\n",
    "    labels = []\n",
    "    input_ids = tokenized[\"input_ids\"].to(device)\n",
    "    attention_mask = tokenized[\"attention_mask\"].to(device)\n",
    "    for target in data.prediction:\n",
    "        labels.append(tokenizer.encode(target, return_tensors=\"pt\").squeeze())\n",
    "    labels = pad_sequence(labels, batch_first=True, padding_value=-100).to(device)\n",
    "    return TensorDataset(input_ids, attention_mask, labels)\n",
    "\n",
    "\n",
    "\n",
    "def get_datalodader(dataset, sampler, batch_size):\n",
    "    data_sampler = sampler(dataset)\n",
    "    dataloader = DataLoader(dataset, sampler=data_sampler, batch_size=batch_size)\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 8\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "tokenizer = BartTokenizer.from_pretrained(\n",
    "    pretrained_model_name_or_path=\"facebook/bart-base\"\n",
    ")\n",
    "\n",
    "train_dataset = make_dataset(train, tokenizer, device)\n",
    "train_dataloader = get_datalodader(train_dataset, RandomSampler, batch_size)\n",
    "\n",
    "valid_dataset = make_dataset(valid, tokenizer, device)\n",
    "valid_dataloader = get_datalodader(valid_dataset, SequentialSampler, batch_size)\n",
    "\n",
    "test_dataset = make_dataset(test, tokenizer, device)\n",
    "test_dataloader = get_datalodader(test_dataset, SequentialSampler, batch_size)\n",
    "\n",
    "print(train_dataset[0])\n",
    "from torch import optim\n",
    "from transformers import BartForConditionalGeneration\n",
    "\n",
    "\n",
    "model = BartForConditionalGeneration.from_pretrained(\n",
    "    pretrained_model_name_or_path=\"facebook/bart-base\"\n",
    ").to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-5, eps=1e-8)\n",
    "for main_name, main_module in model.named_children():\n",
    "    print(main_name)\n",
    "    for sub_name, sub_module in main_module.named_children():\n",
    "        print(\"└\", sub_name)\n",
    "        for ssub_name, ssub_module in sub_module.named_children():\n",
    "            print(\"│  └\", ssub_name)\n",
    "            for sssub_name, sssub_module in ssub_module.named_children():\n",
    "                print(\"│  │  └\", sssub_name)\n",
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "\n",
    "def calc_rouge(preds, labels):\n",
    "    preds = preds.argmax(axis=-1)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    rouge2 = rouge_score.compute(\n",
    "        predictions=decoded_preds,\n",
    "        references=decoded_labels\n",
    "    )\n",
    "    return rouge2[\"rouge2\"]\n",
    "\n",
    "def train(model, optimizer, dataloader):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for input_ids, attention_mask, labels in dataloader:\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "\n",
    "        loss = outputs.loss\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss = train_loss / len(dataloader)\n",
    "    return train_loss\n",
    "\n",
    "def evaluation(model, dataloader):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        val_loss, val_rouge = 0.0, 0.0\n",
    "\n",
    "        for input_ids, attention_mask, labels in dataloader:\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "            logits = outputs.logits\n",
    "            loss = outputs.loss\n",
    "\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            label_ids = labels.to(\"cpu\").numpy()\n",
    "            rouge = calc_rouge(logits, label_ids)\n",
    "            \n",
    "            val_loss += loss\n",
    "            val_rouge += rouge\n",
    "\n",
    "    val_loss = val_loss / len(dataloader)\n",
    "    val_rouge = val_rouge / len(dataloader)\n",
    "    return val_loss, val_rouge\n",
    "\n",
    "rouge_score = evaluate.load(\"rouge\", tokenizer=tokenizer)\n",
    "best_loss = 10000\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train(model, optimizer, train_dataloader)\n",
    "    val_loss, val_accuracy = evaluation(model, valid_dataloader)\n",
    "    print(f\"Epoch {epoch + 1}: Train Loss: {train_loss:.4f} Val Loss: {val_loss:.4f} Val Rouge {val_accuracy:.4f}\")\n",
    "\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"../models/BartForConditionalGeneration.pt\")\n",
    "        print(\"Saved the model weights\")\n",
    "model = BartForConditionalGeneration.from_pretrained(\n",
    "    pretrained_model_name_or_path=\"facebook/bart-base\"\n",
    ").to(device)\n",
    "model.load_state_dict(torch.load(\"../models/BartForConditionalGeneration.pt\"))\n",
    "\n",
    "test_loss, test_rouge_score = evaluation(model, test_dataloader)\n",
    "print(f\"Test Loss : {test_loss:.4f}\")\n",
    "print(f\"Test ROUGE-2 Score : {test_rouge_score:.4f}\")\n",
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "summarizer = pipeline(\n",
    "    task=\"summarization\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=54,\n",
    "    device=\"cpu\"\n",
    ")\n",
    "\n",
    "for index in range(5):\n",
    "    news_text = test.text.iloc[index]\n",
    "    summarization = test.prediction.iloc[index]\n",
    "    predicted_summarization = summarizer(news_text)[0][\"summary_text\"]\n",
    "    print(f\"정답 요약문 : {summarization}\")\n",
    "    print(f\"모델 요약문 : {predicted_summarization}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cde755-dede-4eef-b5b1-36b8e4829e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 07장 트랜스포머/예제 7.24~7.25 KoELECTRA 모델 실습.ipynb\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Korpora import Korpora\n",
    "\n",
    "\n",
    "corpus = Korpora.load(\"nsmc\")\n",
    "df = pd.DataFrame(corpus.test).sample(20000, random_state=42)\n",
    "train, valid, test = np.split(\n",
    "    df.sample(frac=1, random_state=42), [int(0.6 * len(df)), int(0.8 * len(df))]\n",
    ")\n",
    "\n",
    "print(train.head(5).to_markdown())\n",
    "print(f\"Training Data Size : {len(train)}\")\n",
    "print(f\"Validation Data Size : {len(valid)}\")\n",
    "print(f\"Testing Data Size : {len(test)}\")\n",
    "import torch\n",
    "from transformers import ElectraTokenizer\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data import RandomSampler, SequentialSampler\n",
    "\n",
    "\n",
    "def make_dataset(data, tokenizer, device):\n",
    "    tokenized = tokenizer(\n",
    "        text=data.text.tolist(),\n",
    "        padding=\"longest\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    input_ids = tokenized[\"input_ids\"].to(device)\n",
    "    attention_mask = tokenized[\"attention_mask\"].to(device)\n",
    "    labels = torch.tensor(data.label.values, dtype=torch.long).to(device)\n",
    "    return TensorDataset(input_ids, attention_mask, labels)\n",
    "\n",
    "\n",
    "def get_datalodader(dataset, sampler, batch_size):\n",
    "    data_sampler = sampler(dataset)\n",
    "    dataloader = DataLoader(dataset, sampler=data_sampler, batch_size=batch_size)\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 32\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "tokenizer = ElectraTokenizer.from_pretrained(\n",
    "    pretrained_model_name_or_path=\"monologg/koelectra-base-v3-discriminator\",\n",
    "    do_lower_case=False,\n",
    ")\n",
    "\n",
    "train_dataset = make_dataset(train, tokenizer, device)\n",
    "train_dataloader = get_datalodader(train_dataset, RandomSampler, batch_size)\n",
    "\n",
    "valid_dataset = make_dataset(valid, tokenizer, device)\n",
    "valid_dataloader = get_datalodader(valid_dataset, SequentialSampler, batch_size)\n",
    "\n",
    "test_dataset = make_dataset(test, tokenizer, device)\n",
    "test_dataloader = get_datalodader(test_dataset, SequentialSampler, batch_size)\n",
    "\n",
    "print(train_dataset[0])\n",
    "from torch import optim\n",
    "from transformers import ElectraForSequenceClassification\n",
    "\n",
    "\n",
    "model = ElectraForSequenceClassification.from_pretrained(\n",
    "    pretrained_model_name_or_path=\"monologg/koelectra-base-v3-discriminator\",\n",
    "    num_labels=2\n",
    ").to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-5, eps=1e-8)\n",
    "for main_name, main_module in model.named_children():\n",
    "    print(main_name)\n",
    "    for sub_name, sub_module in main_module.named_children():\n",
    "        print(\"└\", sub_name)\n",
    "        for ssub_name, ssub_module in sub_module.named_children():\n",
    "            print(\"│  └\", ssub_name)\n",
    "            for sssub_name, sssub_module in ssub_module.named_children():\n",
    "                print(\"│  │  └\", sssub_name)\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "def calc_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "def train(model, optimizer, dataloader):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for input_ids, attention_mask, labels in dataloader:\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "\n",
    "        loss = outputs.loss\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss = train_loss / len(dataloader)\n",
    "    return train_loss\n",
    "\n",
    "def evaluation(model, dataloader):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        val_loss, val_accuracy = 0.0, 0.0\n",
    "        \n",
    "        for input_ids, attention_mask, labels in dataloader:\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            loss = criterion(logits, labels)\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            label_ids = labels.to(\"cpu\").numpy()\n",
    "            accuracy = calc_accuracy(logits, label_ids)\n",
    "            \n",
    "            val_loss += loss\n",
    "            val_accuracy += accuracy\n",
    "    \n",
    "    val_loss = val_loss/len(dataloader)\n",
    "    val_accuracy = val_accuracy/len(dataloader)\n",
    "    return val_loss, val_accuracy\n",
    "\n",
    "\n",
    "best_loss = 10000\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train(model, optimizer, train_dataloader)\n",
    "    val_loss, val_accuracy = evaluation(model, valid_dataloader)\n",
    "    print(f\"Epoch {epoch + 1}: Train Loss: {train_loss:.4f} Val Loss: {val_loss:.4f} Val Accuracy {val_accuracy:.4f}\")\n",
    "\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"../models/ElectraForSequenceClassification.pt\")\n",
    "        print(\"Saved the model weights\")\n",
    "model = ElectraForSequenceClassification.from_pretrained(\n",
    "    pretrained_model_name_or_path=\"monologg/koelectra-base-v3-discriminator\",\n",
    "    num_labels=2\n",
    ").to(device)\n",
    "model.load_state_dict(torch.load(\"../models/ElectraForSequenceClassification.pt\"))\n",
    "\n",
    "test_loss, test_accuracy = evaluation(model, test_dataloader)\n",
    "print(f\"Test Loss : {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy : {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60588caa-100f-4d81-9503-a96e7ff93af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 07장 트랜스포머/예제 7.26~7.30 T5 모델 실습.ipynb\n",
    "\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "news = load_dataset(\"argilla/news-summary\", split=\"test\")\n",
    "df = news.to_pandas().sample(5000, random_state=42)[[\"text\", \"prediction\"]]\n",
    "df[\"text\"] = \"summarize: \" + df[\"text\"]\n",
    "df[\"prediction\"] = df[\"prediction\"].map(lambda x: x[0][\"text\"])\n",
    "train, valid, test = np.split(\n",
    "    df.sample(frac=1, random_state=42), [int(0.6 * len(df)), int(0.8 * len(df))]\n",
    ")\n",
    "\n",
    "print(f\"Source News : {train.text.iloc[0][:200]}\")\n",
    "print(f\"Summarization : {train.prediction.iloc[0][:50]}\")\n",
    "print(f\"Training Data Size : {len(train)}\")\n",
    "print(f\"Validation Data Size : {len(valid)}\")\n",
    "print(f\"Testing Data Size : {len(test)}\")\n",
    "import torch\n",
    "from transformers import T5Tokenizer\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data import RandomSampler, SequentialSampler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "def make_dataset(data, tokenizer, device):\n",
    "    source = tokenizer(\n",
    "        text=data.text.tolist(),\n",
    "        padding=\"max_length\",\n",
    "        max_length=128,\n",
    "        pad_to_max_length=True,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    target = tokenizer(\n",
    "        text=data.prediction.tolist(),\n",
    "        padding=\"max_length\", \n",
    "        max_length=128,\n",
    "        pad_to_max_length=True,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    source_ids = source[\"input_ids\"].squeeze().to(device)\n",
    "    source_mask = source[\"attention_mask\"].squeeze().to(device)\n",
    "    target_ids = target[\"input_ids\"].squeeze().to(device)\n",
    "    target_mask = target[\"attention_mask\"].squeeze().to(device)\n",
    "    return TensorDataset(source_ids, source_mask, target_ids, target_mask)\n",
    "\n",
    "def get_datalodader(dataset, sampler, batch_size):\n",
    "    data_sampler = sampler(dataset)\n",
    "    dataloader = DataLoader(dataset, sampler=data_sampler, batch_size=batch_size)\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 8\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(\n",
    "    pretrained_model_name_or_path=\"t5-small\"\n",
    ")\n",
    "\n",
    "train_dataset = make_dataset(train, tokenizer, device)\n",
    "train_dataloader = get_datalodader(train_dataset, RandomSampler, batch_size)\n",
    "\n",
    "valid_dataset = make_dataset(valid, tokenizer, device)\n",
    "valid_dataloader = get_datalodader(valid_dataset, SequentialSampler, batch_size)\n",
    "\n",
    "test_dataset = make_dataset(test, tokenizer, device)\n",
    "test_dataloader = get_datalodader(test_dataset, SequentialSampler, batch_size)\n",
    "\n",
    "print(next(iter(train_dataloader)))\n",
    "print(tokenizer.convert_ids_to_tokens(21603))\n",
    "print(tokenizer.convert_ids_to_tokens(10))\n",
    "from torch import optim\n",
    "from transformers import T5ForConditionalGeneration\n",
    "\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(\n",
    "    pretrained_model_name_or_path=\"t5-small\",\n",
    ").to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-5, eps=1e-8)\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "def calc_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "\n",
    "def train(model, optimizer, dataloader):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for source_ids, source_mask, target_ids, target_mask in dataloader:\n",
    "        decoder_input_ids = target_ids[:, :-1].contiguous()\n",
    "        labels = target_ids[:, 1:].clone().detach()\n",
    "        labels[target_ids[:, 1:] == tokenizer.pad_token_id] = -100\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=source_ids,\n",
    "            attention_mask=source_mask,\n",
    "            decoder_input_ids=decoder_input_ids,\n",
    "            labels=labels,\n",
    "        )\n",
    "\n",
    "        loss = outputs.loss\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss = train_loss / len(dataloader)\n",
    "    return train_loss\n",
    "\n",
    "\n",
    "def evaluation(model, dataloader):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "\n",
    "        for source_ids, source_mask, target_ids, target_mask in dataloader:\n",
    "            decoder_input_ids = target_ids[:, :-1].contiguous()\n",
    "            labels = target_ids[:, 1:].clone().detach()\n",
    "            labels[target_ids[:, 1:] == tokenizer.pad_token_id] = -100\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=source_ids,\n",
    "                attention_mask=source_mask,\n",
    "                decoder_input_ids=decoder_input_ids,\n",
    "                labels=labels,\n",
    "            )\n",
    "\n",
    "            loss = outputs.loss\n",
    "            val_loss += loss\n",
    "\n",
    "    val_loss = val_loss / len(dataloader)\n",
    "    return val_loss\n",
    "\n",
    "\n",
    "best_loss = 10000\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train(model, optimizer, train_dataloader)\n",
    "    val_loss = evaluation(model, valid_dataloader)\n",
    "    print(f\"Epoch {epoch + 1}: Train Loss: {train_loss:.4f} Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"../models/T5ForConditionalGeneration.pt\")\n",
    "        print(\"Saved the model weights\")\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for source_ids, source_mask, target_ids, target_mask in test_dataloader:\n",
    "        generated_ids = model.generate(\n",
    "            input_ids=source_ids,\n",
    "            attention_mask=source_mask,\n",
    "            max_length=128,\n",
    "            num_beams=3,\n",
    "            repetition_penalty=2.5,\n",
    "            length_penalty=1.0,\n",
    "            early_stopping=True,\n",
    "        )\n",
    "\n",
    "        for generated, target in zip(generated_ids, target_ids):\n",
    "            pred = tokenizer.decode(\n",
    "                generated, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "            )\n",
    "            actual = tokenizer.decode(\n",
    "                target, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "            )\n",
    "            print(\"Generated Headline Text:\", pred) \n",
    "            print(\"Actual Headline Text   :\", actual) \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7339da47-4aa0-4753-b59a-122cffeec992",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
