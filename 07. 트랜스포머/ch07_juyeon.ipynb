{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a0569b5493ef41e1b2600e3f0687fdd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b93082b072004993b51510d64fb622eb",
              "IPY_MODEL_fb9f2957abfd4905af046ddc68c72754",
              "IPY_MODEL_344ad04fcde54bcb8fd1d400f9059535"
            ],
            "layout": "IPY_MODEL_e5cd804a1994413d8f01f271ec5bb026"
          }
        },
        "b93082b072004993b51510d64fb622eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55867354bd0d46aa934bad69b4f307b7",
            "placeholder": "​",
            "style": "IPY_MODEL_a02a0632b8484d1aa816f6e03c1f4dde",
            "value": "config.json: 100%"
          }
        },
        "fb9f2957abfd4905af046ddc68c72754": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_874b4743a2fd4300b9227c6b3b252687",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4a09a232d4d04759a18cc5e67c5eebce",
            "value": 665
          }
        },
        "344ad04fcde54bcb8fd1d400f9059535": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e3b9ff90d3c4b95ad87d1a1ab8a2cc2",
            "placeholder": "​",
            "style": "IPY_MODEL_834dba36576548f1ae8202e978e1564c",
            "value": " 665/665 [00:00&lt;00:00, 37.8kB/s]"
          }
        },
        "e5cd804a1994413d8f01f271ec5bb026": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55867354bd0d46aa934bad69b4f307b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a02a0632b8484d1aa816f6e03c1f4dde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "874b4743a2fd4300b9227c6b3b252687": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a09a232d4d04759a18cc5e67c5eebce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1e3b9ff90d3c4b95ad87d1a1ab8a2cc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "834dba36576548f1ae8202e978e1564c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac3c9f7c70b64de0bf07500d478b6960": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9ae36d207d294a7ba7dd3e57f61c1553",
              "IPY_MODEL_42d51cac484940d49adfb9ef67336f43",
              "IPY_MODEL_afac1f17c7f34b6782881d2fbaf409fa"
            ],
            "layout": "IPY_MODEL_596684c017d14d9483f1f1b2c4be3528"
          }
        },
        "9ae36d207d294a7ba7dd3e57f61c1553": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39e1fb93aa344fdfb25527ee69b90119",
            "placeholder": "​",
            "style": "IPY_MODEL_6e44042405d34a2fb9c3c8734598f52c",
            "value": "model.safetensors: 100%"
          }
        },
        "42d51cac484940d49adfb9ef67336f43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01c12063db0540a5bc97219a7dfd9579",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a47193859cfc4006a9f36aaf5d0a4a77",
            "value": 548105171
          }
        },
        "afac1f17c7f34b6782881d2fbaf409fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_488e1a58e75c4aabbd68e3eba0bc33b0",
            "placeholder": "​",
            "style": "IPY_MODEL_6d0b328c907942bdbd3141f15c2c630e",
            "value": " 548M/548M [00:02&lt;00:00, 245MB/s]"
          }
        },
        "596684c017d14d9483f1f1b2c4be3528": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39e1fb93aa344fdfb25527ee69b90119": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e44042405d34a2fb9c3c8734598f52c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01c12063db0540a5bc97219a7dfd9579": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a47193859cfc4006a9f36aaf5d0a4a77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "488e1a58e75c4aabbd68e3eba0bc33b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d0b328c907942bdbd3141f15c2c630e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c627897b892485b8157b871c79be6e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e9239c1474c248c1b99c040eb2535477",
              "IPY_MODEL_2785cf8af95744d583720489eda55181",
              "IPY_MODEL_24ab3136578a40f9b9667e9ab98ca0bf"
            ],
            "layout": "IPY_MODEL_846b60c401b44299b3fa46ab73623a08"
          }
        },
        "e9239c1474c248c1b99c040eb2535477": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83b6ce275af94a4b9df7cb4a18002b92",
            "placeholder": "​",
            "style": "IPY_MODEL_8687929495634695ac005d9c3b4802d5",
            "value": "generation_config.json: 100%"
          }
        },
        "2785cf8af95744d583720489eda55181": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73bbe4aa089945d095f3493e770e516a",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3fb5302b57c74ce297d654fe8d8d5870",
            "value": 124
          }
        },
        "24ab3136578a40f9b9667e9ab98ca0bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bd4cac830a546a8a91ec43b97fb81f5",
            "placeholder": "​",
            "style": "IPY_MODEL_5009798fdb90416e9e9a50755dcaf95e",
            "value": " 124/124 [00:00&lt;00:00, 6.87kB/s]"
          }
        },
        "846b60c401b44299b3fa46ab73623a08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83b6ce275af94a4b9df7cb4a18002b92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8687929495634695ac005d9c3b4802d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73bbe4aa089945d095f3493e770e516a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fb5302b57c74ce297d654fe8d8d5870": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7bd4cac830a546a8a91ec43b97fb81f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5009798fdb90416e9e9a50755dcaf95e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21111788c24a4e969ef78d2fadd2613b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fad2c2b7d54c4ceaa2a5bf7746fe1791",
              "IPY_MODEL_e625668fafcd4248aa07282a5dc2a488",
              "IPY_MODEL_6f5752e3723f4e64bf0c0e48289e0699"
            ],
            "layout": "IPY_MODEL_0a668a5571d344f7b2cc990ebb55ec08"
          }
        },
        "fad2c2b7d54c4ceaa2a5bf7746fe1791": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbd5f529af9a440a964b359bb36939c4",
            "placeholder": "​",
            "style": "IPY_MODEL_e2622f0014c94294acb69e596d1da442",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "e625668fafcd4248aa07282a5dc2a488": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5a96573b56f46ea84ecdc815c91ace2",
            "max": 49,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a63391475d674848804fcd6502dc95a1",
            "value": 49
          }
        },
        "6f5752e3723f4e64bf0c0e48289e0699": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fef1d9dde0ef4b8eabd875030ebfe2da",
            "placeholder": "​",
            "style": "IPY_MODEL_03c46116ebb2491dab2580459967c879",
            "value": " 49.0/49.0 [00:00&lt;00:00, 850B/s]"
          }
        },
        "0a668a5571d344f7b2cc990ebb55ec08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbd5f529af9a440a964b359bb36939c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2622f0014c94294acb69e596d1da442": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5a96573b56f46ea84ecdc815c91ace2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a63391475d674848804fcd6502dc95a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fef1d9dde0ef4b8eabd875030ebfe2da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03c46116ebb2491dab2580459967c879": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d4b0d43f51a4391a22c117b40ecdb95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_97e84a53883d46b09252b8fa30d885b8",
              "IPY_MODEL_7e6ea31fb7df40c691de61a8a802518e",
              "IPY_MODEL_19727e3b763c4c5daa5becb7b7af79ab"
            ],
            "layout": "IPY_MODEL_55705c190e1a4671bff52ec3073386ab"
          }
        },
        "97e84a53883d46b09252b8fa30d885b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c93d9d83b77461c99b45d9f508270c3",
            "placeholder": "​",
            "style": "IPY_MODEL_14d316a683384ed09594dc9fac1d62f8",
            "value": "vocab.txt: 100%"
          }
        },
        "7e6ea31fb7df40c691de61a8a802518e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7fbf603fd5e49da9bf13bee56c533af",
            "max": 995526,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_129cc473f6164f76aa6f7701d33f7bfc",
            "value": 995526
          }
        },
        "19727e3b763c4c5daa5becb7b7af79ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9829dd332cd4f2f9a2ad62d4999a28e",
            "placeholder": "​",
            "style": "IPY_MODEL_946466bd048942f5b969e93e7de6ca64",
            "value": " 996k/996k [00:00&lt;00:00, 5.87MB/s]"
          }
        },
        "55705c190e1a4671bff52ec3073386ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c93d9d83b77461c99b45d9f508270c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14d316a683384ed09594dc9fac1d62f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7fbf603fd5e49da9bf13bee56c533af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "129cc473f6164f76aa6f7701d33f7bfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d9829dd332cd4f2f9a2ad62d4999a28e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "946466bd048942f5b969e93e7de6ca64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98a425648757478cba21bfaecbd038bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_50764927d3d240dc9bcc6da01d299b07",
              "IPY_MODEL_326bef3870f240549024b34c6c7c2fd8",
              "IPY_MODEL_173778f8109f43cc97eb9e14735e902e"
            ],
            "layout": "IPY_MODEL_b511034b56974544990a2c313239a146"
          }
        },
        "50764927d3d240dc9bcc6da01d299b07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f291ecd2ab94657867beb81ce05c74b",
            "placeholder": "​",
            "style": "IPY_MODEL_ea6fa11ce95049adaf6c6cb96b259561",
            "value": "tokenizer.json: 100%"
          }
        },
        "326bef3870f240549024b34c6c7c2fd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5ee31ad1b40462fb44f9771b058268a",
            "max": 1961828,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e7e94bd620eb4fc4bf782a9887d5ae60",
            "value": 1961828
          }
        },
        "173778f8109f43cc97eb9e14735e902e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_035e9365c46543e49b0d1df95950130a",
            "placeholder": "​",
            "style": "IPY_MODEL_bcc0018b3fa940d8a14e5d6cc52ea58d",
            "value": " 1.96M/1.96M [00:00&lt;00:00, 7.52MB/s]"
          }
        },
        "b511034b56974544990a2c313239a146": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f291ecd2ab94657867beb81ce05c74b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea6fa11ce95049adaf6c6cb96b259561": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5ee31ad1b40462fb44f9771b058268a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7e94bd620eb4fc4bf782a9887d5ae60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "035e9365c46543e49b0d1df95950130a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcc0018b3fa940d8a14e5d6cc52ea58d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 위치 인코딩"
      ],
      "metadata": {
        "id": "FxGVuQ134-Ei"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "from torch import nn\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# 위치 인코딩 클래스 정의\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len, dropout=0.1): # d_model: 임베딩 차원, max_len: 최대 시퀀스 길이, dropout: 드롭아웃 비율\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)  # 드롭아웃 계층 설정\n",
        "\n",
        "        # 위치 벡터 생성, 각 위치마다 임베딩 차원을 계산\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "\n",
        "        div_term = torch.exp(\n",
        "            torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model)         # 각 차원마다 다른 주기로 나눌 수 있는 값\n",
        "        )\n",
        "\n",
        "        # 위치 임베딩 초기화함, max_len x 1 x d_model 형태로 0으로 채워진 텐서 생성\n",
        "        pe = torch.zeros(max_len, 1, d_model)\n",
        "\n",
        "        # 위치별로 짝수 인덱스 - 사인 값, 홀수 인덱스 - 코사인 값 적용\n",
        "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        self.register_buffer(\"pe\", pe)\n",
        "\n",
        "    # 순전파 단계 정의\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[: x.size(0)]\n",
        "        return self.dropout(x)\n",
        "\n",
        "# PositionalEncoding 인스턴스 생성\n",
        "encoding = PositionalEncoding(d_model=128, max_len=50)\n",
        "\n",
        "# 위치 인코딩 시각화\n",
        "plt.pcolormesh(encoding.pe.numpy().squeeze(), cmap=\"RdBu\")\n",
        "plt.xlabel(\"Embedding Dimension\")\n",
        "plt.xlim((0, 128))\n",
        "plt.ylabel(\"Position\")\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "WUzbGGVN5CEE",
        "outputId": "967ccc39-bed9-47fb-84a3-b51abe6c44bb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi4AAAG2CAYAAABYlw1sAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAACC1klEQVR4nO3dd3wU1fo/8M/uJrubXkkDQmjSpAkSA6gIkSIqfOUqelEQES5KVEARuUpXEEVAFMEGyBUEsaBYUDoqoUhREAhFkFCSACEJCam78/uDH+fMwE5IdgObZD/v12tfPjk7c+bMJsSTmXmeY1AURQERERFRFWB09wCIiIiIyooTFyIiIqoyOHEhIiKiKoMTFyIiIqoyOHEhIiKiKoMTFyIiIqoyOHEhIiKiKoMTFyIiIqoyOHEhIiKiKoMTFyIiIqoy3DpxmTBhAgwGg+bVuHFj8X5BQQGGDRuGsLAw+Pv7o0+fPkhPT3fjiImIiKqmTZs24b777kNMTAwMBgNWrFhxzX02bNiAW265BRaLBQ0aNMDChQuv2mbOnDmIi4uD1WpFfHw8tm3bVvGDV3H7FZdmzZrh9OnT4vXrr7+K90aMGIGVK1di+fLl2LhxI06dOoUHHnjAjaMlIiKqmvLy8tCyZUvMmTOnTNsfPXoUPXv2xF133YXdu3dj+PDhePLJJ/HTTz+JbZYtW4aRI0di/Pjx2LlzJ1q2bIlu3bohIyPjep0GDO5cZHHChAlYsWIFdu/efdV72dnZqFGjBpYsWYJ//etfAIADBw6gSZMmSE5Oxm233XaDR0tERFQ9GAwGfP311+jdu7fuNqNHj8b333+PvXv3iraHH34YWVlZWLVqFQAgPj4et956K959910AgN1uR+3atfHMM8/gpZdeui5j97ouvZbDoUOHEBMTA6vVioSEBEydOhWxsbHYsWMHiouLkZiYKLZt3LgxYmNjS524FBYWorCwUHxtt9uRmZmJsLAwGAyG634+RERUdSmKggsXLiAmJgZG4/W7KVFQUICioiKX+1EU5ar/t1ksFlgsFpf7Tk5O1vw/GAC6deuG4cOHAwCKioqwY8cOjBkzRrxvNBqRmJiI5ORkl4+vx60Tl/j4eCxcuBCNGjXC6dOnMXHiRNx+++3Yu3cv0tLSYDabERwcrNknMjISaWlpun1OnToVEydOvM4jJyKi6iw1NRW1atW6Ln0XFBTAJyAUKMl3uS9/f3/k5uZq2saPH48JEya43HdaWhoiIyM1bZGRkcjJyUF+fj7Onz8Pm83mcJsDBw64fHw9bp249OjRQ8QtWrRAfHw86tSpg88//xw+Pj5O9TlmzBiMHDlSfJ2dnY3Y2FgMNdWGxWDEbb+tFu/9HN9FxK+e3i7iNc3vFPH//vuOpv+uzeU36LUpS0TcsGN7Eb+8dJyINxzNEnH7zWtE3P+paSI+9fY9Iv6ut5y5LnnlXe253X2TiD+7+XYRrxsq+woK9xXx8HkvinjhGHkeU36fIeIja46JeOZTb8hjLRmrOfaj4fJ4H816VsTBFm8R/9+Tr4v412YnZbtdPpd0z6cTRDzwwG8iXnuL/Mz/Pb6n5tj557JF/PO8zXK7vfJ7Obr2HSJusfYHEWfcc7+IV414S8STvn9NxI/HyvFtve245tjNVthEfHpeHxFHPPGpiP/5WfZb795XRPz9wpdF3OfZeSJ++b//FvGMeetFfEe3lppj79xxWsRh0QEiLiooFnHBxRIR16gptzl+4IyI2yXUFvGmn/4Q8UMPyquWi/+3VnPskUnyZ/LN6Z+LeOrYR0X84tiPRTxn2hARP/W8/LldPGeEiB8eIn++vp0vLyHfN1B+LwBgzafyZ6/LvyeI+Jdlk0R8e1/5b2zL8skiju/zXxFv/3qKiG/9P9m+a8VUEbe6X/4bAYA9K98UcfP7Ron4r+9ke7N7ZfuB72V7456yPeWH6SJudM8LIj70o2xv2EO2l/bekVWyvX532f73T6qfu27PX7P9mOrnNK6rbC/tPfXPdp0ytKeulr9bat898prtzuyj135ijWyvlXjtdr33FFsxbPs+R0BAAK6XoqIioCQfXk0fAkze195Bj60Yufs+R2pqKgIDA0VzRVxtqczcfqtILTg4GDfddBMOHz6Mu+++G0VFRcjKytJcdUlPT0dUVJRuH3qXyCwGIywGI3z95Q+jWfVssvqb7ms0idjbx0/Tj4+f3N/gJY/jZZXb+Znk/haDPIb62AaTWR7bX+5b2rH9A+QYzap+TRY5WVGPQ68vf7O3w230zgHQnqv6PPys3qpt5Dmpj2G0y/Gpx60+H6tBHi/AR/v987LIfn1U26m/Z+rvpfp7ZFV/TjrnZ/S2ymNbtcc2mOTEQP190nz/VONQt/upzk/9+anHZ/SWE3Szj7/m2HrfVxvkxMVkK3a4jdGc57Bf9fEsvup2+RkAgFXzcy7f8/F3/PPvq9Pup2lXfzaO/y0A2p8L9XvlbQ/Qa9f5fpX23vVuB/R/jq53O4/t+L0b8WiBwdt61XHLQ/n/v78DAwM151JRoqKirsrkTU9PR2BgIHx8fGAymWAymRxuU9r/p13l9qwitdzcXBw5cgTR0dFo06YNvL29sXat/EswJSUFx48fR0JCghtHSURE5DqD0eTy63pKSEjQ/D8YAFavXi3+H2w2m9GmTRvNNna7HWvXrr2u/5926xWXF154Affddx/q1KmDU6dOYfz48TCZTHjkkUcQFBSEQYMGYeTIkQgNDUVgYCCeeeYZJCQkMKOIiIiqPJcnH0r59s3NzcXhw4fF10ePHsXu3bsRGhqK2NhYjBkzBidPnsSiRYsAAEOHDsW7776LF198EU888QTWrVuHzz//HN9//73oY+TIkRgwYADatm2Ldu3aYdasWcjLy8PAgQOdP69rcOvE5cSJE3jkkUdw7tw51KhRAx07dsSWLVtQo0YNAMDMmTNhNBrRp08fFBYWolu3bnjvvffcOWQiIqIq6ffff8ddd90lvr78POiAAQOwcOFCnD59GsePy+f86tati++//x4jRozA22+/jVq1auGjjz5Ct27dxDZ9+/bFmTNnMG7cOKSlpaFVq1ZYtWrVVQ/sViS3TlyWLl1a6vtWqxVz5swpc7EcIiKiqsJgcPGKi718+3bq1AmllW5zVBW3U6dO2LVrV6n9JiUlISkpqVxjcUWlejiXiIjIUxhMRhhMrtwqqlSPqd4wHjNxub1WIPyMJkSNHSDanuxRX8RbbpXptOvPyIyMb+8L0XaUkSLCUdlnRfznD9+J+M6PRot45R0yvseSKmLFLtNsD0bKZ3Z+O3dRxC8myvRnAPho6z8ibh0oMzfOto4W8aaf/hTxnmxZiK9X65oirmlpJeJvPt8v4oxUmXYc0TxCc2xLfriId6RmifiJtrLOQUmBrCWQdfS8iP1bymyXIruc7Yf6yH+woWYZ552UnysABMTKS465JXbZl5fjlPnzF2VRJx+T/IddlC8zhCyqz89WKGspePtp+1TsWSI2mB0fr8gmz0n911Ohaqzq9vwi+b03qjJtilTbX9pHZjXYbPI9oyrbQbErDre3q9pNOkW0TEZ1P7Yyv+eIsZwZGKVtX5a+yjKmiswJqUq1K41OjLUKnR6R50xciIiIKhOjiw/nKtc5q6iy4sSFiIjIDVzOKvLQiYtn3iAjIiKiKolXXIiIiNyAV1ycw4kLERGRGxiMRhhcWYH6Oq5eXZl55lkTERFRleQxV1warV+FgIBATA2/WbS9eGaPiBdENBfx4P9rJOI1d8iVfAFAUaWltnvmbRFv/+IrEW+KkJUJe9SWC1/99bJc0Tai2SMi/u93+0QcpUqtvc03S3PsoZtlRcNBCTK9OaqtXP33mw/kitXphTL995G6oSL2C+is2uZ/Is4+dVT2mdBAc2y/A7Ei3vmPTHX+b8eacCTnRI6Ig7r4OtwmRLW2mCYdOu2cZrvwts1ErE6Hzi3Spg9flpEj08DrmWSiZ5Hq8zD7yUUg7SUyfdo7UDtWxS7HYtdLh1anJKtqMhSoxmr0lierTodWb194RTq0SZXKrU57Nno5btdLYdZrN2v60U+HVtOmYjs+hl3V7kxqrh69vqpSqnIVGirdALxV5ByPmbgQERFVJpduFbkycfHMmyacuBAREbmByyX/DZ55xcUzp2tERERUJfGKCxERkTuYTC6tVaSUc5HF6oITFyIiIjdw9eFcl24zVWG8VURERERVhsdccblj8FwYvK048r5Mb272zGci/m3UnSIOeGWuiOcFNtXt87un4kV8t2rl4eHvbxXx1qkPinjWoE/k9vNlWvaPX28R8egAuWpx1mfvao53aq9MrW4yUKZcN4oLEnFxnlzhWZVZjTiDTGEuqdNGxPmqjfLPnRJxUKtWmmOHZAXLcahWkfbKPCZi9ew/85xccblGuON0aFNOmoh9Q2Wq8YXTudrtwuTq1wWq9F91OrQq6xmZeTK9uYUq5bdYlQ5tCZKfsz29WPbjF6w5tjrlV/F2fB7q1aGNqs/gYrEq7bkMq0Or2y/t43h1aLOXl0674/RmvXa9lGcAMOnkGJt0dtFb0Vm/H/1jX+/05hvx15ozaeAVmTpOVQOvuDjHYyYuRERElYnRaNL8sVP+Djxz4sJbRURERFRl8IoLERGRG7hagM6ldY6qME5ciIiI3IDPuDjHM6drREREVCXxigsREZEb8IqLczhxISIicgNOXJzjMRMXS1A4jN4+GO7fQ7Rlpf5PxH+OnSbisa9tEPHcO2I1/aSnnBPxqeH9RLxw8kIRt7zneRHnjZ0l4tT8j0T8SmIDEX/65nsi7tCxloj/+OhXzbHzzM1FbE6cIGLDoV9EbDLLeiihZvlDbf9jrYgPN+sj+1EVjyhS1YDxanqb5thhBzJF/PfedBHbThyU+/j4izitQNYLaRIt68/kqY6nruPiFylrpOSl52mO7RUeJeJ8Vd2SnEJVrRJVv8dzC0Xsr67jUlAgtw+with+UtZ9MfjKsV5J8Za1X9S/MNR1XNTthaqxatpLHLeXqNoBwOQlz8mues/oK9sVVV0bdV0WTb0Wg067enubtoaMUWcfo06xEb36Lnr06r6Upry76J1D6fuU7xiG61105gYdg9zD1UUWDVxkkYiIiKhy85grLkRERJWJwcVFFl3ZtyrjxIWIiMgNWMfFOZ551kRERFQl8YoLERGRGzCryDmcuBAREbkBJy7O8ZiJy453H0ZgYCBCOwwTbTPeGyviAcPnijjvTKqIb/ntR00/xh0rRTy2y39FPP7ueSL2CYkU8fMr94u4S6hMVa65/3sRq9OImw3tJeJpfWdrjm1qIfffnR8g+1r5tYiDajUW8U2H14n49OoNIv41oLOIw1Up0+qU0fzQeppjt6kr4z3rt4u46O9cEZtVqcTni2VfDSPl+R1WpyefOCJi/0g/EWceOq85NgLC5fFU6b9nL8o0ZnU69IU82e6jOj9bYb7cPlQez65O9w0Ihh7FW6ZslykdWpXCbPIyizhf9dmYVJ+HzaZNh1anwdpV561OSVa3W1R9qdObTXopzKXk/uqlN5c3xbgs21/ZbkT50n/Lm8JMRFWbx0xciIiIKhOj0aBbG6lsHXjmrJ0TFyIiIjcwGA0wuDD5cGXfqoxZRURERFRl8IoLERGRGxgMBpeWdPDU5SB4xYWIiMgNDP//GRdnX87eKpozZw7i4uJgtVoRHx+Pbdu26W7bqVMnMcFSv3r27Cm2efzxx696v3v37k6NrSx4xYWIiMgNDAYXn3Fx4orLsmXLMHLkSMybNw/x8fGYNWsWunXrhpSUFERERFy1/VdffYWiIpmpee7cObRs2RIPPvigZrvu3btjwYIF4muLxYLrxWMmLj80uwO+RhPumyY/2Ed2yFWZJ1jCRHxTlwdEfOf0zZp+ku7tKGJ1Cu4PSZ+IuP3ED0W8+uvfRDxtRCcR/zlVbhN763PyAF27ijCtYIbm2CFxN4v4wy3/iPjRlX+IuGZXmU7dMF2mER/fcEjEPzeSqzL38ZdpukZVyu6R83KFZQC4JTZYxPPOy9Whz+8/K2KfkLYizlWlAtcPkWnEp02qdOjTx0TsFyX7zy6Q7QBg85PfG1XmMc7ppEMX5peI2BIo//HYimQ6tCVYpmjbi2U/Rl+ZZn4lu7fVYXuRZhVoeX4XVWnP6jTp/CJVqrLq87BdtTq06rNSrYRtVO2jKNdeHVqdJm3XWx36ypRkzXuqtO6ypElrUrEdb6/XXllVseFWax56d6TCzJgxA4MHD8bAgQMBAPPmzcP333+P+fPn46WXXrpq+9DQUM3XS5cuha+v71UTF4vFgqioqOs3cBX+eyQiInKDy1lFrrwAICcnR/MqLCx0eLyioiLs2LEDiYmJos1oNCIxMRHJycllGvPHH3+Mhx9+GH5+fpr2DRs2ICIiAo0aNcJTTz2Fc+fOOfmpXBsnLkRERG5gNBhcfgFA7dq1ERQUJF5Tp051eLyzZ8/CZrMhMjJS0x4ZGYm0tDSH+6ht27YNe/fuxZNPPqlp7969OxYtWoS1a9di2rRp2LhxI3r06AGb7dpFKp3hMbeKiIiIqqPU1FQEBsrK5dfr+ZKPP/4YzZs3R7t27TTtDz/8sIibN2+OFi1aoH79+tiwYQO6dOlS4ePgFRciIiI3qKhbRYGBgZqX3sQlPDwcJpMJ6enpmvb09PRrPp+Sl5eHpUuXYtCgQdc8r3r16iE8PByHDx8u4ydRPpy4EBERuUFFTVzKymw2o02bNli7dq1os9vtWLt2LRISEkrdd/ny5SgsLMSjjz56zeOcOHEC586dQ3R0dLnGV1acuBAREXmIkSNH4sMPP8Qnn3yC/fv346mnnkJeXp7IMurfvz/GjBlz1X4ff/wxevfujbCwME17bm4uRo0ahS1btuDYsWNYu3YtevXqhQYNGqBbt27X5Rz4jAsREZEbuLrIouLEvn379sWZM2cwbtw4pKWloVWrVli1apV4YPf48eMwGrXXNFJSUvDrr7/i559/vqo/k8mEP//8E5988gmysrIQExODrl27YvLkydftWRuPmbj8c7EEVoMdn1h+Em1jh3wh4m8P/y7ieiGyXkdsp2c0/YxJ6SDiX5Lai3jaW7+I+H/9Wok4+v2PRBy2UNZlWTT1VhE/MbqpiD/bmyHiKKv221O3dSN57OTjIm6dkiniji/VFHEdY2MR/zBbju/IYZmmVqeRnD1brbLuy9YT2Zpjd4wNEXFRnnwv8+ApEfvVkPdI81W1TWoHyR/eULOsZ3LhuLzP6l+zhuyzSPskut03BI6cUdVxsar+oRXlF4vY7O8t4hJVHRdzoKwto9jzRGz0kw+4XalIVURGXZdFXa9FXQsnX6e9qERd30X+4rGri9RAW+Ol0C5r06h/0alrv+jVZSlL+5VMOsUyjDrten3pba/XDujX6TDC8Rt6Pen146ll0itSad8/KjuD8dLLlf2dkZSUhKSkJIfvbdiw4aq2Ro0aaWpGqfn4+OCnn35y+N71wltFREREVGV4zBUXIiKiyoSLLDqHExciIiI3MBrh4jMuFTiYKoQTFyIiIjdwJqX5yv09kYfO14iIiKgq4hUXIiIiNzAYXLziwmdcqreR2xchMMAfz9btJdoSI+TqlmFTBov4zIUCEccmaBeTOp78nYh93psn4pYftRFx0bujRBxY6yYRT9si039PXZQpuzPa1RJx57d+FfGUhtrlxCM71RPxf8ctEPHBXLkS6CO3yHToiHC5RsSRqbJS4pmjJ0Rcs4Ps0+94rIh/PXRGc+x/N48Qsb1EpiFnHpKp2MHN5OepzuyN8JU/ZjUsMo04V5UOHXNHKxFnF8sUXwC4UOL4H2dalvw+RXmpUofzZeqwVZXabiuU6dCW4AARK/YcGXv7ODwWABSqUo+16dCO2/NVad1Gb5kOfVHVrk55Vqc2X+pLlSqtes9Lda7q9Gazl8lhu16qsl6aNKBNdy1LX9frivWV47reKur/Azfifyfl/cw9839xlZt6oURnKB46ceGtIiIiIqoyPOaKCxERUaXi4sO51+1SZyXHiQsREZEbMKvIObxVRERERFUGr7gQERG5gauLLLqyb1XGiQsREZEbsOS/c3iriIiIiKoMj7nikjD3BEwWXyzoKuuWtPp0kYifrdFRxCbVJPbHtLs1/fR+3VvG7ySL+Jv/yu2Wv/aziNtMnS/i+ct2i3iwj+zH/tUbIj68Vdb7aDnkTs2xmzapIeLnzqSKOF9VNKV1iGqHoM4iVNdGyU0/JuLIR2T9mRBbjIgP/n1ec2yf7BNw5NypXBHXiPR3uI0lT9aECQqVdVVyTmSLOLaGrD+TZ9PWM8kuVNURUX1vMi7I+jUNvOQbhfmyRo4l0CJi21lZ98XkJ2vkqGuF2C2OzwEAClSfs8GkruPiuF6Luo6Lur5Lkaomi1FVk8V2xXmbLfKfp121pLxZp46LXl0WvXazSf/vFpPOH3LqmhN29TF0/vLTay/tD0W9q9/l/ePyRvxVVt4r9R56ZZ90GIyXXq7s74k8ZuJCRERUmfAZF+dw4kJEROQGTId2TqW50PT666/DYDBg+PDhoq2goADDhg1DWFgY/P390adPH6Snp+t3QkRERNVapZi4bN++He+//z5atGihaR8xYgRWrlyJ5cuXY+PGjTh16hQeeOABN42SiIio4lzOKnLl5YncPnHJzc1Fv3798OGHHyIkRD5Zmp2djY8//hgzZsxA586d0aZNGyxYsACbN2/Gli1b3DhiIiIi111+xsWVlydy+8Rl2LBh6NmzJxITEzXtO3bsQHFxsaa9cePGiI2NRXJy8pXdCIWFhcjJydG8iIiIqHpw68O5S5cuxc6dO7F9+/ar3ktLS4PZbEZwcLCmPTIyEmlpabp9Tp06FRMnTryq/Z9t62HwMiNn0TLRFj/zdxHPvk2m4546IlOBDZMGacf88ocivvX+0SL2WjdDxHtHrxTxnAfl7a9mHy8UcWKHWiLeNu07EeeYbhZx4INjNcc2psorTSazj4hDzTLVFr/Lvg437S23V03MC7JlerK59SMijjyWJeJj+zI0x7Yf+1PEXlaZMnwyv0TEN9cMksdQ/SVgOi9Tt/0i/ER84bRMpfaKihVx/pXp0AWqFF5Vv8dzZHpzkLcq3Tg/X8TWYPk52dOKRGwMUOeNS4rqcwWuSGNWpUObvGTaszodWr39RVU6tFG1faGq3aRK47aXaM/b6Ov4vbKkN2va1enTNtWYDI77AfSzFfTSpPUYnbiUXe6051LOw/H25R3RjSn05amX/T2ZweDiw7ke+jPjtisuqampeO6557B48WJYrdZr71BGY8aMQXZ2tnilpqZeeyciIqIbzGQ0uPzyRG6buOzYsQMZGRm45ZZb4OXlBS8vL2zcuBGzZ8+Gl5cXIiMjUVRUhKysLM1+6enpiIqK0u3XYrEgMDBQ8yIiIqLqwW23irp06YI9e/Zo2gYOHIjGjRtj9OjRqF27Nry9vbF27Vr06dMHAJCSkoLjx48jISHBHUMmIiKqMEYXr5rYPfSKi9smLgEBAbj55ps1bX5+fggLCxPtgwYNwsiRIxEaGorAwEA888wzSEhIwG233eaOIRMREVUYV2/3cOJSCc2cORNGoxF9+vRBYWEhunXrhvfee8/dwyIiIiI3qVQTlw0bNmi+tlqtmDNnDubMmeOeAREREV0nvOLinEo1cbmePnnvBfj6B6DXwCmirThPrk7ccINc0bn9SZme/UKLgZp+xjWbKmL/qDgRP7Z4t4ifUKX81tr+qYgtAXJF4lZjZL8Te8j0ba9bZKrx5twAzbHrLV0i4pC4tiK++e/1Ij7xzQ8iXm2RK17HWOVq1OqU0ezg+iJOaPiPiP9cqy3yV3DggoitQeEiPlsk06Gbq9Kh96tScIuPHxRxYC15TsfWH5cHCIoQYZFdph0DQEaeXAVanQ59IU+mN/uoUsJL8mWatSVWHs9WrE6HDoYjirev5mt1enNhieKwXZ0OrU6Tzte0O14F2qBZbVl73uqUZPV7Fp30Zr1fgLrtpa7Q7DjFWC+9uSwpyZp+UP5fuDfid7TbC1uR4AmZvpy4OMdjJi5ERESViZcR8HJh8qF46EzbQ0+biIiIqiJecSEiInID3ipyDicuREREbuBqHRebh05ceKuIiIiIqgxecSEiInIDk8EIk9H56wcmg2dee/DMsyYiInIzdy2yOGfOHMTFxcFqtSI+Ph7btm3T3XbhwoWXVrFWva5cGFlRFIwbNw7R0dHw8fFBYmIiDh065NTYysJjrrhETxgCf28v1G4zTLTVa1JDxLc9/52Ie3RvLOLWARZNPwte/ErEw774VsRvvynrtXzx7gARb35pgYib/Os1EZ9pJddbyiwaJ+KIZh1EPG21rH8CAM99vkuOfdCjIm50saaID/8o9/m2/kkRjwiWP2heVlkrZk/GRRHfFifrzMw8d0pz7LN/povYr0ZXEeeWyJokjcNl/Zo0b1nnpOCfIyIOjJX1Ws4W/i1iW0CkjLXlTJChrtdiknPt/Auq9hB5fraifBFbguW5quuImHTquNi8tP8g1fVaClTnavSSdXEKNe2qOi5FquOpxm1Tba+u71JcqK1/YlTtY1fVflH/slKfk7q+i93uuL6LppaKpl32D5Re40Xso6kh43gbvfbSanSUt8aLXl8GTygEcp3p1e2hqmvZsmUYOXIk5s2bh/j4eMyaNQvdunVDSkoKIiIiHO4TGBiIlJQU8fWV/7beeOMNzJ49G5988gnq1q2LsWPHolu3bti3b99Vk5yKwCsuREREbuCOKy4zZszA4MGDMXDgQDRt2hTz5s2Dr68v5s+fr7uPwWBAVFSUeEVGyj80FUXBrFmz8Morr6BXr15o0aIFFi1ahFOnTmHFihXOfCzXxIkLERGRG9zoiUtRURF27NiBxMRE0WY0GpGYmIjk5GTd/XJzc1GnTh3Url0bvXr1wl9//SXeO3r0KNLS0jR9BgUFIT4+vtQ+XcGJCxERURWWk5OjeRUWFjrc7uzZs7DZbJorJgAQGRmJtLQ0h/s0atQI8+fPxzfffINPP/0Udrsd7du3x4kTJwBA7FeePl3FiQsREZEbmAwGl18AULt2bQQFBYnX1KlTr3HksktISED//v3RqlUr3Hnnnfjqq69Qo0YNvP/++xV2jPLymIdziYiIKhNXC9BdfsA+NTUVgYGBot1isTjcPjw8HCaTCenp6Zr29PR0REVFlemY3t7eaN26NQ4fPgwAYr/09HRER0dr+mzVqlWZz6U8eMWFiIjIDSrqGZfAwEDNS2/iYjab0aZNG6xdu1a02e12rF27FgkJCQ73uZLNZsOePXvEJKVu3bqIiorS9JmTk4OtW7eWuc/y8pgrLot+OAyzwYi9J2SqM878I8KABZvktge2iPjt7yZp+nnhjtEintUwV8Svn5cz2GO3vyjiH/bPE/H0R28R8WvrZIrwLapU5fMd64r4t9V7NMfempoj4sc61RNxwwj5w7E66TMRH085K+LaHWuJ2Dc/RsQb/z4n4gG3yLTq4rxszbHP7D0t4qCW4SLOV+Uu1wqUqcA1LDKNOPuwTMsOiJX3QTNV6cKF5gDoOZ1TIGI/VX5twcViEVtV6dDF+fL7Yg2W/Sr2LBEbfIMcHkud8gxo06Fzi0octxfKdm06tLpdjrukWJXarD6fEnk+gDZV2m6Xn7PZSx5bKUPas1nVj2b7UlJd9dJg9f461Nu+LOm06jGVpqISc6tahm95/yCvYqdHN9jIkSMxYMAAtG3bFu3atcOsWbOQl5eHgQMHAgD69++PmjVrittNkyZNwm233YYGDRogKysLb775Jv755x88+eSTAC5lHA0fPhyvvvoqGjZsKNKhY2Ji0Lt37+tyDh4zcSEiIqpMvIwGeN3gtYr69u2LM2fOYNy4cUhLS0OrVq2watUq8XDt8ePHYVRV8z1//jwGDx6MtLQ0hISEoE2bNti8eTOaNm0qtnnxxReRl5eHIUOGICsrCx07dsSqVauuSw0XgBMXIiIit3B1dWhn901KSkJSUpLD9zZs2KD5eubMmZg5c2ap/RkMBkyaNAmTJk0qdbuKwmdciIiIqMrgFRciIiI3cNcVl6qOExciIiI3MBlcnLhUtSfNKwhvFREREVGVwSsuREREblBRBeg8jcdMXMa90xeBPhbMvOk+0WZSfc9f/OJbEc95d4WIX7/YUtNPv85xIt7Q+2kRN+w6TsQDP9gq4vaKrL/R/uJuET/6g6z7MvxBmVbWpstNIu4wR7ta56kCWRdkaGNZS8Uvqo+IU/MXiTjz6D4R1+ndWsTBu+Ux1u2Va0m8dGsI9GQeyhRxWHd/h9uEGuX6GDV8vUWcfUyea40ObUWco6qZcr5Av5bHicx8ETdT1SQpzJd1T3xUdVxsuXJ7S6is16LYZc0au8XP4bHySxTN1waTrJlysViO0egt67Xkqr4v6vaLqjo16notdtV5q+u72GzaGjJ69VfK2673i9Fbp+7LlfvYVe/p/Z4s7yXr0n7fVsar33rj1Ruqh/7/hMqJz7g4h7eKiIiIqMrwmCsuRERElQmvuDiHExciIiI3MBldm3yYPPSeCScuREREbsArLs7x0PkaERERVUW84kJEROQGvOLiHI+ZuIy23gezjz86Wb4UbSfzZRrri5lfiLjehAEifnbUXE0/Y5Z9IuJnIu4Q8awv40V8f//JIn61YaiId704RcTpZxqKuOFnL4pYQaqMr0hR9VHlb4ce+02eR+32Irapsnnzzsi+Ajs9JuKo80UiTjuWJWLjP7tFbDL7aI6dmi1TnZvHyXNS1xHwOndMHq9WgIizjmWL2Ds6TsS5qrTgLFU6tPmKf4wns2V6c3tvx+nQVlU6tD1LthuDwkSs2A/JbSxyfAajTHkuvCIl2ah674IqvdnoJdOe88vQbtJJe/a2yH+C6jRpQJvebC+R3zOz6dppz4pNtnsbHW9fWg0Io05OcnnTnisytVk9Js156G5f/mMYKmMuNlVbrOPiHN4qIiIioirDY664EBERVSYmg8Gl9YY8da0iTlyIiIjcwGgw6N6WLev+noi3ioiIiKjK4BUXIiIiNzBBu2aeM/t7Ik5ciIiI3MBoNLiUGeSpWUUeM3FZPvsDGExmzEv9XbQZtq0Q8biuY0U8frFMaX3OqL2b9sRPGSLuEipThu/IWC/7Va0o3HGaTK2e1ne23KZFYxHvMDcScc1P/ivikLibNcdueexXEZ9a+pmIf+wt94+xqtNrZQptXq1bRNy+6d8iXrhll4gL9uaK2BokV58GtCtT31InWMSHVSm7JUf3ijg4Tq7KfPzXEyI2hNcScb4qLfj0BZlu7XPFnyDnsgtEHKQ6v+I8mWZtjZbHsx2S561Oh1ZTLHKFa3U6dMEVq0Nr0puL1enNsv1CYYmqXfV5qFeTVp2TTZX2bPJSr8KsPbZFvdqzTSftWWd1aDW9v+j00oud2Uc/VdlxR6Xdmq/Ov4uZbk3kOo+ZuBAREVUmzCpyDicuREREbsCsIudw4kJEROQGRoNrD+dW59uqpWE6NBEREVUZvOJCRETkBswqcg4nLkRERG7AZ1ycw1tFREREVGV4zBWX+556At4+/mj4n+WirVM3WSelS4BFxLMf/1DEL//wo6afVyfOF/EHC54S8cYnp4m4xWNviDijQ7yI0wpmiDiq5V0iHvPtXyJ+YcEWETcc+pDm2K0QK+J9n+8W8dLIf+T+4b4i9rLKWiXbT8kaLXc1lDVa5pxJFXH6ttMi9o/srjl2ZpGszXFfZKCIz3nLGij5hw+IOCguUsRnfj4qYltQtIxVZUtOXpC1WnxM2vl0/gVZl8UnxCrikgJV3ZkwOSZ7sdzeFBAMR2xesh91HZe8Im09E6OXt4gvFJWo2lX1XVT7mFRj19Zrke3Fher6LrLdrqprA2jrsqhro6jru9h16rhoaqlo6r6oxlRqLRXVPpoaMo6312vX+4NQr75LafT6Km9tFP61djV3/uXuoRcNAFz6N+hS5VwP/ew8ZuJCRERUmfBWkXP4xwcRERFVGbziQkRE5AYmo0GzhIcz+3siTlyIiIjcgLeKnMNbRURERFRl8IoLERGRGzCryDkeM3F512sNAr2tqJ0uUzs/n/mbiBf88YWIx9W/X8TjbZs1/Uwoyhfxhpv6ivi7FJnqvOjJdiJO+nKPiAdE+InY0qORiJd9uk7Em07kiHh4d7kNANxU724Rf/vDPBEf3SvTmOt3qydi/3Nxcnx/pYv4xU51RVycly3itB0nRRx2R4Tm2EV2mbscFyxTgaOsMpX4/EGZWh3apI6Iz6jSfy96yRRttRPn5eca6KW9EHgxV5UOHe4jx54v06F9I0JEbC+R5wr/MIfHy1elKqvTodUpz4A27Tm3wHE69IWCYlW7HHtJsTyGlyptvCBPbm/SpDar8sMBmIyq90rkZ6CX9mzSpD3Ldm+j4wurpV1m9tb5jai3T1kuWavHVJqK+l1c1a6il/dxhSp2euSAwcVbReUtBVBdeMzEhYiIqDLhw7nO4TMuREREHmTOnDmIi4uD1WpFfHw8tm3bprvthx9+iNtvvx0hISEICQlBYmLiVds//vjjMBgMmlf37t11enQdJy5ERERuYMSlW4ROv5w45rJlyzBy5EiMHz8eO3fuRMuWLdGtWzdkZGQ43H7Dhg145JFHsH79eiQnJ6N27dro2rUrTp48qdmue/fuOH36tHh99tlnToyubDhxISIicgOTweDyq7xmzJiBwYMHY+DAgWjatCnmzZsHX19fzJ8/3+H2ixcvxtNPP41WrVqhcePG+Oijj2C327F27VrNdhaLBVFRUeIVEhLisL+KwIkLERFRFZaTk6N5FRYWOtyuqKgIO3bsQGJiomgzGo1ITExEcnJymY518eJFFBcXIzQ0VNO+YcMGREREoFGjRnjqqadw7tw550/oGjhxISIicoPLBehceQFA7dq1ERQUJF5Tp051eLyzZ8/CZrMhMjJS0x4ZGYm0tLQyjXn06NGIiYnRTH66d++ORYsWYe3atZg2bRo2btyIHj16wGYrWyZheTGriIiIyA1MRv2V1cu6PwCkpqYiMDBQtFssFhdH5tjrr7+OpUuXYsOGDbBaraL94YcfFnHz5s3RokUL1K9fHxs2bECXLl0qfBweM3EZP+RTmA1GbEuTdVV6v75BxLcvkrPNrybIp6HnPzBF00/HKR+L+Knpcv/BVm8Rx6x9W8TJK+VHvOBl2W/HzrLeytxJM0WcWSRnqPfWkT8YAGCo3V/EpwreFfH5v/8QcZ3hnUUcsUke47c/ZK2X8HaOf6gzDmfKc3g02OE2ABBYcFbEUTV85dhT5GcY012O43yxPKez+aq6I6rbs/+cuyji9t7af8kFebKGiW+4PJ4tU9Z+8Q6W41Xsp0RstwY4PIc8VY0Vg0nWWMkt0v6FYPTWqeOias9X7aOu11KiOm+zRf4c2Gzy2D5mub26VgtQ/notZp3fgOrPWVPfxaSuIaM9b71753rterfa9bI1nSk/cSMuD+uOt5zbE91IgYGBmomLnvDwcJhMJqSnp2va09PTERUVVeq+06dPx+uvv441a9agRYsWpW5br149hIeH4/Dhw9dl4sJbRURERG5wKTvIlVtF5Tue2WxGmzZtNA/WXn7QNiEhQXe/N954A5MnT8aqVavQtm3bax7nxIkTOHfuHKKjo8s3wDLymCsuRERElYnRycwg9f7lNXLkSAwYMABt27ZFu3btMGvWLOTl5WHgwIEAgP79+6NmzZriOZlp06Zh3LhxWLJkCeLi4sSzMP7+/vD390dubi4mTpyIPn36ICoqCkeOHMGLL76IBg0aoFu3bk6fW2ncesVl7ty5aNGihbjMlZCQgB9//FG8X1BQgGHDhiEsLAz+/v7o06fPVZe4iIiIqqKKeji3PPr27Yvp06dj3LhxaNWqFXbv3o1Vq1aJB3aPHz+O06flowVz585FUVER/vWvfyE6Olq8pk+fDgAwmUz4888/cf/99+Omm27CoEGD0KZNG/zyyy/X7Vkbt15xqVWrFl5//XU0bNgQiqLgk08+Qa9evbBr1y40a9YMI0aMwPfff4/ly5cjKCgISUlJeOCBB/Dbb79du3MiIiK6SlJSEpKSkhy+t2HDBs3Xx44dK7UvHx8f/PTTTxU0srJx68Tlvvvu03z92muvYe7cudiyZQtq1aqFjz/+GEuWLEHnzpce9FywYAGaNGmCLVu24LbbbnPHkImIiCpERWUVeZpK84yLzWbD8uXLkZeXh4SEBOzYsQPFxcWaXPHGjRsjNjYWycnJuhOXwsJCTfGdnJwch9sRERG5k7O3e9T7eyK3T1z27NmDhIQEFBQUwN/fH19//TWaNm2K3bt3w2w2I1iV5gpcu1DO1KlTMXHixKva+yXWhb+3F/65S6bp7ty2TsQBHZ8T8dGv3xTxwbE/aPr5doBMAwv4UKZG932itYi/e26JiHNqygmW7+D3RGzcuEjE1qAaIq7tI9OqS76X2wPA7+2GithflSqbf15+Hl4JcptGZ+V9ym3r98t+9xwXsSVAVj88fKhYxB0ahmuOfVaVU2s4sU/EIXWDRXz+7ywRe8feJOLcEpn+m6FKbTarHok/nCnToUNVKcIAUJiXK2K/CJnebEsrELEpJEK1hxyfokqHNhhlv/mqMZm8VCnPhTLl+cr3LqjSob3M8t5toSod2uQlz8muOobR13G7XsozoE1v1qQ9q/dRFXhS/xJTb2/UST0wlfI7T+8Xom67TsKwU2nPOuehv335+jfcgF/2N+IYRJ7K7ReaGjVqhN27d2Pr1q146qmnMGDAAOzbt+/aO+oYM2YMsrOzxSs1NbUCR0tERFQxDAbXX57I7VdczGYzGjRoAABo06YNtm/fjrfffht9+/ZFUVERsrKyNFddrlUox2KxXLcnmYmIiCqKEQbdq5Vl3d8Tuf2Ky5XsdjsKCwvRpk0beHt7awrlpKSk4Pjx46UWyiEiIqLqy61XXMaMGYMePXogNjYWFy5cwJIlS7Bhwwb89NNPCAoKwqBBgzBy5EiEhoYiMDAQzzzzDBISEphRREREVZ6rt3t4q8gNMjIy0L9/f5w+fRpBQUFo0aIFfvrpJ9x9990AgJkzZ8JoNKJPnz4oLCxEt27d8N57712jVyIiosrvUsl/1/b3RG6duHz88celvm+1WjFnzhzMmTPnBo2IiIiIKjO3P5x7o2S/sQAl/gFY1TRetBU36yjihGfkis4PvbxCxL8Ml9sAwMEn+4o4NuFJEdeeKtOsp89pJeLgDjeL+JWfD4v4XzM+FXHdhJdEfHv+LyLePUdbjfD9YrnuQ48g+QCyUZWye7AkWMS9W8lHmNZ8+o2Iz/52RsT+kS1FnK5KBb6nTojm2Mlm+aNSdHCXiEMaylTug9tl+rUtpLbc3q6I+Hi2TGFWp3TnZKnaQ7SrYhfnZYvYp64cV0mhXB1amw4t2S066dCq1aGNXjIF/cKVq0PrpEobVanKRap29erQxYWOV41Wrw5tUX0G9mL91aHteunQmtWe1WnE8hjeOqtJa9KObVesDq16+k27MrXj9vK6EX8pVroH+DyYp97SuBbeKnKOx0xciIiIKhNmFTmHExciIiJ3cLUWi2fOW3g1lYiIiKoOXnEhIiJyA2YVOYcTFyIiIjcwwLW7PR46b+GtIiIiIqo6nLrikpeXh9dffx1r165FRkYG7KrUSwD4+++/K2RwRERE1ZXRYNBdcb2s+3sipyYuTz75JDZu3IjHHnsM0dHRVWIJ90eemg6DlwXn100RbS90GiPi9f/nL2KfJVtEnP+WtvjdJ7VbifjjA3eIePhP/4j4lmBZh+R8L1kHZvkXv4s4eNspET/9RjMRt2qUKOL3kj7THHv71hMiHt05TsT++TL+cq+spTLglpryPM6nifjk5qMiDmvZS8S5JXIC2iTcV3Ps4z7yR+Xs7oMiDm0sj51WsFPEBX6yvovascyLIg70krVNLuYUitgvwk+zT5GqjotvhKzjotizRGwMCnd4vIslsoaMuiZLdkGJw/acgmLN/iazj4hzVe95meXYS1Q1YUyqQicFJXJ7k6r2ik31OZtVn8GVdVEsOvVa9Oq4mHT+Her9cjOVcoNcbx+9dnWzplaMzsXs0n5j6P060fs9UwV+/QjOPJNQUafnqf+Tq8wMcLGOS4WNpGpxauLy448/4vvvv0eHDh0qejxEREREupyauISEhCA0NLSix0JEROQxjHDtQVNPfUjVqfOePHkyxo0bh4sXL157YyIiIrqKwWBw+eWJnLri8tZbb+HIkSOIjIxEXFwcvL29Ne/v3LlTZ08iIiIi5zk1cendu3cFD4OIiMizsACdc5yauIwfP76ix0FERORRuDq0c1yqnLtjxw7s378fANCsWTO0bt26QgZ1PdRsdTtMFl903hwo2paN6yrij9o8KuKOEz8Ucc9xP2v6GahKRb31d7ndv5bIj3LSuB5y/14y1bnu2/NEfEqVjju6aZCIDTc9LeJjTyzSHDtj/3YR3/SsHHvkpgYi/mFrqoj/e7PjR5hO7ckQcc3/C3G4TXjxOc3X0WEyLfjMXpmWHdlFpoSfLZJpsGcuyvMzqf5x/X0mT8TxZjm+ixdU6dCR2nRoW2a+iC0RMu3ZXiLPw+4TBEcuqlKVDSaZepxdqBqfRZ5b9kVtOrTRW6ZKX1B9z7y81enQqlRli/w5sNnUac/yXO0lRddsv/I9TTq0yfH31Vv155d6e2/V9nZ1eyl/rumlVuv9otTrqjL+Yi3tr1S9tzz1L1u6vvhwrnOcmrhkZGTg4YcfxoYNGxAcHAwAyMrKwl133YWlS5eiRg3HNTyIiIiIXOHUhO2ZZ57BhQsX8NdffyEzMxOZmZnYu3cvcnJy8Oyzz1b0GImIiKodZhU5x6krLqtWrcKaNWvQpEkT0da0aVPMmTMHXbt2LWVPIiIiAvhwrrOcuuJit9uvSoEGAG9v76vWLSIiIiKqKE5NXDp37oznnnsOp07J9XZOnjyJESNGoEuXLhU2OCIiourM4MLLUzk1cXn33XeRk5ODuLg41K9fH/Xr10fdunWRk5ODd955p6LHSEREVO1cvlXkyssTOfWMS+3atbFz506sWbMGBw4cAAA0adIEiYmJ19iTiIiIyHlO13ExGAy4++67cffdd1fkeK6brSNuQmCAP/zumy7afpk/QcSpU2U9klV9a4nYb8ECTT+DXpK3wj4d+omIs+Pai9j2hLzqFPLzHBH7hsWIuL6frA9y8dPXRfxbpxEiDvLWXhDLP58mYtNdI0V8S+4xEa/7Xi63ULwjRcTWIJminnJQ1gvp1jxKxKdUdUNwbLfm2OGNwkR8NkXWePGuK+vU5JbI55tSs2VdFh9VHZGUjFwR36uqeVKQky1i/2htTZbiU7L2iymsieqdfSKy+8p6NAajrLGSq6rjYvKSn3m2qiaLuj3rijouXmaLiPM1dVzkOZWo6tf4+psdtvuY5ZjsxfLz91HVg1HXXgGuqONik+8ZVZkE6n28dOq7mHT+KtPrp7T3jDoXqMtb36XUYzvepdx/Xd6IjAtPzeqgiuFqZpCn/vyVeeIye/ZsDBkyBFarFbNnzy51W6ZEExERlY5ZRc4p88Rl5syZ6NevH6xWK2bOnKm7ncFg4MSFiIiIrosyP5x79OhRhIWFiVjv9ffff1+3wRIREVUXrmQUuZJZNGfOHMTFxcFqtSI+Ph7btm0rdfvly5ejcePGsFqtaN68OX744QfN+4qiYNy4cYiOjoaPjw8SExNx6NAhJ0d3bU5lFU2aNAkXL168qj0/Px+TJk1yeVBERETVndFgcPlVXsuWLcPIkSMxfvx47Ny5Ey1btkS3bt2QkZHhcPvNmzfjkUcewaBBg7Br1y707t0bvXv3xt69e8U2b7zxBmbPno158+Zh69at8PPzQ7du3VBQUOD0Z1MapyYuEydORG5u7lXtFy9exMSJE10eFBERUXV3eXVoV17lNWPGDAwePBgDBw5E06ZNMW/ePPj6+mL+/PkOt3/77bfRvXt3jBo1Ck2aNMHkyZNxyy234N133wVw6WrLrFmz8Morr6BXr15o0aIFFi1ahFOnTmHFihUufDr6nJq4KIri8GnmP/74A6GhoS4PioiIiMomJydH8yosLHS4XVFREXbs2KEpXWI0GpGYmIjk5GSH+yQnJ19V6qRbt25i+6NHjyItLU2zTVBQEOLj43X7dFW50qFDQkJE+tZNN92kmbzYbDbk5uZi6NChFT7IijDnlodgNZgwceX3ou0/I2Sqctrnz4l4Q6d/ibjNY29o+in5T7yId064WcQ1b71HxI/+b5eIX5j5mYibD50h4kR/eU9x6/SfRPxWoezn+XA/zbHfsfqL+Nczioj/3ba2iL+at1jEp1afFnFQ7e6y/ReZ1jsgTqY5r1OlJ+ft2qI5do2bZYr4ns0nRFwSFifiIrsc05Hz8laivyqt90Jmvmyv4Svi4osyHdq3qRwToE0f9gqPgiMlZvnZGFXpzRcKZaqtyWwVcXZhsardR8S5hfKzAQAvVbpySbGqL9U5FauOYVSlJNttMhXb1+w47dmi6sd+RVqwj84+3qr8ZkW1xIY67VmTwqxOPValVetkT5f6nm7acznvtpf2l2J5Uzyd+uurGnPm9kFF8dDsXKcZFAUGRbn2hqXsD1yqraY2fvx4TJgw4artz549C5vNhsjISE17ZGSkqMl2pbS0NIfbp6Wlifcvt+ltU9HKNXGZNWsWFEXBE088gYkTJyIoSNbbMJvNiIuLQ0JCQoUPkoiIqNpR7JderuwPIDU1FYGBgaLZYrHo7VEtlGviMmDAAABA3bp10b59e4cLLRIREdGNExgYqJm46AkPD4fJZEJ6erqmPT09HVFRjq9mR0VFlbr95f+mp6cjOjpas02rVq3KcxplVuarrDk5OSJu3bo18vPzr7qvdvlFREREpTModpdf5WE2m9GmTRusXbtWtNntdqxdu1b3bklCQoJmewBYvXq12L5u3bqIiorSbJOTk4OtW7detzswZb7iEhISgtOnTyMiIgLBwcEO70NffmjXZrM56IGIiIiECrpVVB4jR47EgAED0LZtW7Rr1w6zZs1CXl4eBg4cCADo378/atasialTpwIAnnvuOdx5551466230LNnTyxduhS///47PvjgAwCXnkkbPnw4Xn31VTRs2BB169bF2LFjERMTg969ezt/bqUo88Rl3bp1ImNo/fr112UwREREdP307dsXZ86cwbhx45CWloZWrVph1apV4uHa48ePw2iUN2Pat2+PJUuW4JVXXsF///tfNGzYECtWrMDNN8vklBdffBF5eXkYMmQIsrKy0LFjR6xatQpWq/Wq41eEMk9c7rzzTocxEREROUFRLr1c2d8JSUlJSEpKcvjehg0brmp78MEH8eCDD+r2ZzAYMGnSpBtWgNap1aFXrVoFf39/dOzYEcCl8sEffvghmjZtijlz5iAkJOQaPdx44RYTfAwmdFr1qmibEdRSxC8rnUV88YBMW97wbFtNP+2n/Srime3kas8JqjTpZ0fNFfEPx7JE/M6/W4u42R1Pi3hxR7nSc0ryXyJu+UQ7zbFDj8rxvv/rUREv6NtCxMV5Mq34n/Vy+YWYf9UUsTptuUm4nBEf9ZMPW6f/rk2Nq93lVhGfzJefQZZBm7J92aF0WaAwSpVSnJslKyn6x8gU5iLVuP1rypWsAcBeclJ+ERTh8Hi5qpWY1atDZ+bLtGd1mnS2ahVok0WmQ2ddlKnXgDYdWp32rG7PvyD3MatSmG0lMrXa7KVaHbpEtb16BejSVodWp0MbddpNjlOrvXWWhy4tbVbvPaNOyrWeisyOrahU2xuRsevM4nfMJPZAbrhVVB04VQJh1KhR4iHcPXv2YOTIkbjnnntw9OhRjBw58hp7ExERETnHqSsuR48eRdOmTQEAX375Je677z5MmTIFO3fuxD333HONvYmIiOhSATrnr5q4UryuKnPqiovZbBaLLK5ZswZdu3YFAISGhjIdmoiIqCwu3ypy5eWBnLri0rFjR4wcORIdOnTAtm3bsGzZMgDAwYMHUatWrWvsTURERHzGxTlOXXF599134eXlhS+++AJz585FzZqXHvz88ccf0b1792vsTUREROQcp664xMbG4rvvvruqfebMmS4PiIiIyCPwiotTnJq4AJdWg16xYgX2798PAGjWrBnuv/9+mEyma+xJREREUOyAnROX8nJq4nL48GHcc889OHnyJBo1agQAmDp1KmrXro3vv/8e9evXr9BBVoQ++zYiMDAQw/2aibY1J2eLuF2v0SJefZusebLtbm2W1N6ipiLusOJ9EXcsOi3i/1zIFLGPqoZG0+NyLYd/GnQVcb5N/vBl/v2HiGNeH6Y5doMVF0S8Y9sJEZubnxGxl1XWRtm3T9ZG6dBSLn5VoioyYT31p4ijG4aKOP0P7XLk9Z+SNWjOFsn6JKdyZT0Us6rf/aflQ9qtrHIym5dzUcSBteSiYCWH80TsHaH9+VHsx0Vs85E1gtT1WnKK5GfoparLkl0ox6qu13IuV9ZSMZlle26B3B4AvFR1WUqKZd0Sq6/ZYbuP2XG9Fh9V3Rd1/RPN9sXaGjL69VrKV5fFpNOu7v9K5a2Zore9ekzqcyjtHnV5a6A4Wn7EmX6c3YeIbiynnnF59tlnUb9+faSmpmLnzp3YuXMnjh8/jrp16+LZZ5+t6DESERFVOzd6kcXqwqkrLhs3bsSWLVvE2kUAEBYWhtdffx0dOnSosMERERFVW3zGxSlOXXGxWCy4cOHCVe25ubkwm80O9iAiIiJynVMTl3vvvRdDhgzB1q1boSgKFEXBli1bMHToUNx///0VPUYiIqLq5/Iii668PJBTE5fZs2ejQYMGaN++PaxWK6xWKzp06IAGDRrg7bffrugxEhERVT+snOuUcj3jYrfb8eabb+Lbb79FUVERevfujQEDBsBgMKBJkyZo0KDB9RonERERUfkmLq+99homTJiAxMRE+Pj44IcffkBQUBDmz59/vcZXYVo9+yWM3j7YNLy9aLs46t8irnXrIBG3e32KiJ8LukXTT1DvPiIetVPmTj749igRN7zrRRH3NMp04+2jZol43tA6Iu4aKtNxP1Yd64BVOxEcdKdMMU5a+ZOI0787J8dXq7mIj/0uiwTe2yxSxMkW+W0v+F2maEe1kWngW5fIcQOAUkumgefb5OXJA2dlGnOQt7yAl54h20PD5PkVZsvU7YCb5ZiK9+SK2CsyFlpbRGT3CxOxOh06t0iVauvlLeLz+TJd20uV9pytblelKheq2gHA2yLfKy6UxwgIke02VTq7r056s9lLfja2Esft6nRhQJv2rKhqPXgbHacYa9ptjtOn1dubVNdbrzy2EY7zgvXTnh23VySnLg9XEL2Ua0/Fj6NicJFF55Trd8GiRYvw3nvv4aeffsKKFSuwcuVKLF68GHZXCugQERF5It4qckq5Ji7Hjx/HPffIgmyJiYkwGAw4depUhQ+MiIioWuPExSnlmriUlJTAarVq2ry9vVFcXKyzBxEREVHFKdczLoqi4PHHH4fFYhFtBQUFGDp0KPz8/ETbV199VXEjJCIiqo5YgM4p5Zq4DBgw4Kq2Rx99tMIGQ0RE5ClcLdvPkv9lsGDBgus1DiIiIqJrcmqtoqooP/MUDF5WrBg6WbQdvKOLiH+/0F3End+V6bfjVCsmA8BNI3uJ+NXXFovY+EuqiN/76DYRt+s+VMQTe0wU8fo6chXoiY/JlZdDT7UU8YyNRzTHfuveRiIedF6u3nxo5X4R1+z5gIhzv5Cz8Vtj5KrRZ/xluvCpX3aJOCrhZhEf/XCH5tg51nA4sveUTNGuYZY/Thcy80WsXgW6ULVydkCsTIe2l8jVtQ2hciXrK6lXgTZ6yeUlzl6Uz1mpV3s+m1soYi8f+RlkXVSlJKvSw9Upz4A2VTr/gmof9arRRfLYPqrPQL06tDpNWp16XGo6tM7qzd4mvfbyrRqt1w5o0121qzrrpEmXoR9te9mOXdmVeyXrCj12FfqgyDG7/dLLlf09kMdMXIiIiCoVV8v2s44LERERUeXGKy5ERETuwKwip7j1isvUqVNx6623IiAgABEREejduzdSUlI02xQUFGDYsGEICwuDv78/+vTpg/T0dDeNmIiIqGJczipy5eWJ3Dpx2bhxI4YNG4YtW7Zg9erVKC4uRteuXZGXJ9e5GTFiBFauXInly5dj48aNOHXqFB544IFSeiUiIqLqyq23ilatWqX5euHChYiIiMCOHTtwxx13IDs7Gx9//DGWLFmCzp07A7iUkt2kSRNs2bIFt912m6NuiYiIKj/eKnJKpXo4Nzs7GwAQGnopBXnHjh0oLi5GYmKi2KZx48aIjY1FcnKywz4KCwuRk5OjeREREVU6iuLiWkWemVVUaR7OtdvtGD58ODp06ICbb75UTyQtLQ1msxnBwcGabSMjI5GWluagl0vPzUycOPGq9nXvD4N/QCBu7jFStG1KrCvine07iXi7SdYz6bxpuaafxExZr+Xl8/JZG7OqoEO7Y9+L+Giz3iLOLh4n4jMHZK2YOlNGi7jJN3KitWHD35pj+9X9R8ReVlmTZO8+WRulc9taIi5QjcnvxE4R124ia7Kc2CLPJ27wkyI+W6QtNngsS1XDRNXvH6lZIn7UKmuV5GbJ233BdUNEXHxAnp+5ZhMRK/YTIrYF1NAc22CU/arruHhZVPVaVHVZTKr2c7mqdlV9lyxVu7dq3MWFJZpj+wbK5S1KimU9Ex9VXRZ1vRYfb5129fbFst3q5bi+C6Cty6J+z1v1+dtV7Saduh569WBKKwOiUypGdx91TRFt3Re97fWPrUev9oteX3qHKO3YpdWXIapwig244t99uff3QJXmisuwYcOwd+9eLF261KV+xowZg+zsbPFKTU299k5ERERUJVSKKy5JSUn47rvvsGnTJtSqJa8YREVFoaioCFlZWZqrLunp6YiKinLYl8Vi0SwCSUREVBkpdjsUF6rfurJvVebWKy6KoiApKQlff/011q1bh7p162reb9OmDby9vbF27VrRlpKSguPHjyMhIeFGD5eIiKji2G2uvzyQW6+4DBs2DEuWLME333yDgIAA8dxKUFAQfHx8EBQUhEGDBmHkyJEIDQ1FYGAgnnnmGSQkJDCjiIiIyAO59YrL3LlzkZ2djU6dOiE6Olq8li1bJraZOXMm7r33XvTp0wd33HEHoqKi8NVXX7lx1ERERBWgEl9xyczMRL9+/RAYGIjg4GAMGjQIubm5pW7/zDPPoFGjRvDx8UFsbCyeffZZkS18mcFguOpV3mdb3XrFRSlDKpfVasWcOXMwZ86cGzAiIiKiG0Ox2aDYnJ98uLLvtfTr1w+nT58WxWEHDhyIIUOGYMmSJQ63P3XqFE6dOoXp06ejadOm+OeffzB06FCcOnUKX3zxhWbbBQsWoHv37uLrKzOHr6VSPJx7I/zToyf8TCbc8tgboi3qP/EinhouU6BrDr5HxD2+OK3p54WZI0TcdugMET8YfUjE6wfPFPG0Z+JE/HxUgIgXqFJzNxbHyP67yoeO//W59srS8SVyLGEN5Df94LaVIh7QqqaI1/l4i/jCLz+KuFb7+nKbD2Radvs6rUScb9NOKv9Il2nMoarU3q1pcgZeI0qmaBecl+nqgW2jRVzyR76IvWPiVEf4TW7jE6o5ttHLLOLz+TJd2WS2ilidDu2tShXPzFOlcVvkj3uRKu3Zy1udDq39RaB+T50OHWCVfanTm33Vac+qv4bU6dCa1GZNyrP2QTt12rMmxVidemzT60uVJq26rqppLyX116iTTKybeqzbXv704kqT6lhJGN2Yos3scM+0f/9+rFq1Ctu3b0fbtm0BAO+88w7uueceTJ8+HTExMVftc/PNN+PLL78UX9evXx+vvfYaHn30UZSUlMDLS/7ODA4O1k2wKQv+jiAiInIHu931F3BV0dXCwkKXhpWcnIzg4GAxaQGAxMREGI1GbN26tcz9ZGdnIzAwUDNpAS493xoeHo527dph/vz5Zbr7ouYxV1yIiIgqFbvdtedU/v/EpXbt2prm8ePHY8KECU53m5aWhoiICE2bl5cXQkNDdYu/Xuns2bOYPHkyhgwZommfNGkSOnfuDF9fX/z88894+umnkZubi2effbbM4+PEhYiIqApLTU1FYGCg+FqvltlLL72EadOmldrX/v37XR5PTk4OevbsiaZNm141gRo7dqyIW7dujby8PLz55pucuBAREVV2it121VIf5d0fAAIDAzUTFz3PP/88Hn/88VK3qVevHqKiopCRkaFpLykpQWZm5jWfTblw4QK6d++OgIAAfP311/D29i51+/j4eEyePBmFhYVlLh7LiQsREZE7KPI5Faf3L4caNWqgRo0a19wuISEBWVlZ2LFjB9q0aQMAWLduHex2O+Lj43X3y8nJQbdu3WCxWPDtt9/CarXqbnvZ7t27ERISUq6K95y4EBERuUFFXXGpaE2aNEH37t0xePBgzJs3D8XFxUhKSsLDDz8sMopOnjyJLl26YNGiRWjXrh1ycnLQtWtXXLx4EZ9++ql4UBi4NGEymUxYuXIl0tPTcdttt8FqtWL16tWYMmUKXnjhhXKNjxMXIiIi0li8eDGSkpLQpUsXGI1G9OnTB7NnzxbvFxcXIyUlBRcvXgQA7Ny5U2QcNWjQQNPX0aNHERcXB29vb8yZMwcjRoyAoiho0KABZsyYgcGDB5drbB4zcVn7dxYsBiM23pUl2uoPl0VxNg5vL+JnXuwq4jb3v6jpp8Hf50W88il5ycz/32+L+KPaPUT8x6oNIr7z9T4irrm1pYgnfvOXiFcPvEnExXnaioMHvtonx/H80yIu+lSmkjUPkDVFMsJlrZhjP+0QcaPH7xfxkZmbRHza5gs924/J826tqmGSdSZPxCH1gkVckH1GxEEN6ojYXiLr3SihckFNtfMF2r8ijN6yjku6qi6LySLP70yOTP/z8pF1XM7lynZvdR0XVT0YdXtejjaN0Ed1riVF8j0fs6qOS0mRqt3ksN3sJSsPqP9KspoctwOAt+o9u07tF832RsfVDUw6xVfUzVceW7cui+PmcnOmPohuDZlybu+M8vbF8idUJq5Wv72OlXNDQ0N1i80BQFxcnCaNuVOnTtdMa+7evbum8JyzPGbiQkREVKnYXXzGhatDExEREVVuvOJCRETkBpV5raLKjBMXIiIid6igyrmehreKiIiIqMrgFRciIiJ3qMRZRZWZx0xcxv8wAYF+vhh75yjRltmul4gPvTJLxI1mPSPi8Jvu0PRz1z8yffjsS4+L+MMHp4i4to8scZybfkzERf/3roj/HXlcxHPeXSHi/OA1Ig6Irq859pb9G0U8+M56It6rTsHdtlLEde6IFfHfa+Q4ms2Q55RZJNet2JMhU5uDvLUX47b8I9Oh7w+SFQ5zz8qy0CGNokVctClHxN6xcoVRxX5AxLZAWTra6CVTnrOuSIf2Msu054w8VXqzVaY9Z1xQt8tqjRdU6dMWH/njXlhQLOLgGn4iLinSHjtAlQ5tL1alPXs7TntWp0Or7z/rpT17lZIObTE5viCqTntW72NU5Rhr2nWSc0tLSdZL/9U/Rjn70T80DM7kSpfD9e6/KuJH4h6K3Q7Fhds9ruxblfFWEREREVUZHnPFhYiIqFLhrSKncOJCRETkDoqLExeFExciIiK6QfiMi3P4jAsRERFVGbziQkRE5A4sQOcUj5m49NwcBi+rH8bFBYu2yKlJIn7kuXkifmLtLyJefOAtTT+3DZKpzhN7TBTx/7J/FfHGIbeKePYpGb/4fYqI37q3kYinvnRQxLvm7hdx3Z4TNMc+8+OHsq9GYSI2qdKTT3z7k4hju8ljf/2FTENOCKorYptqMc8txzJFHGOV5wkA507niji0YaiI88+nyfauchVo25rTIjZGyeOpZdvkj586Hfp0rnaFZi+rTFc+nV0gYm+/IBFn5Mh2i2rsBXky7Vm9CnRBZr7cXtVeXChTmwHAX9WXrUjuo06TtpVhdWiLlypNWvXLxuqlf9FTvQq0OrVad3VonXaDzirQemnSgP7qxrqrRuu8UdXSbN25CrSxqn1Y5Do+nOsU3ioiIiKiKsNjrrgQERFVJlxk0TmcuBAREbmD3e7acyoe+owLbxURERFRlcErLkRERO7Ah3OdwokLERGRGyh221WLq5Z3f0/EW0VERERUZXjMFZddK76AwWRGw80bRdtt30wT8WtGHxHH+craHY2/lLVaAOCb7mNEbDLI99L3bhJxzV/fF/G93x8R8crlstbLO95rRewbFiPi3zbLGjKD3pW1XgDg2FQ5z7TsWiniRrfXFvHhHw+JuO7zL8nxFS4Q8R/peSL2V9URST50VsQj/GVdFQDITpfv1bg5WsSF28+L2NogXsSK/YSIS0Lk+AxGWc8ks0BVm8THX8SnL2jruGjey5L1Wsy+sr5LZo7cx+wjf6wL82Udl8BQ+T0+V1giYn91TZZCWasFAPxVNV7UdVnU+9iLZbuft7peizw/i+pzVvfjrSocYr/irydvo9xH3Zdeu0mnDohJ588TvXZAW1NEW/tFb3v9vhzRq/tSWl96e+huz7ooVMmx5L9zPGbiQkREVJkodgWKzZWJi3LtjaohTlyIiIjcQLHZXZu4uLBvVcZnXIiIiKjK4BUXIiIiN+AzLs7hxIWIiMgNeKvIObxVRERERFWGx1xxGTtlOKx+AWj76EzR9sTaJSJevn+riDsck+nJE3u+qunnf3vaiHjDf24V8cdpMn565WERv9lTpjQvnDpbxL+/cUDE9buOE3Hq2k9FnNQ8UnPsVcFWER//7Au5f68Euc2qxSK+NbyxiItUT5+vU6U9x6jSelcdzxZxjWbhmmPnnTku4vDODURcsum0iE2xTVR7/CyiHMhxm8wyJfmEKoXZyypTm4+fv6g5tjkgVMSns2W6ssUq09bzc2WKscVHtl/IlNtbVe3FhXL7YF+Z+m0r0qZDB6hTpVVpzD5mmfasTm+2eKnToeVfQ1Yvx38jqNOkr1wwzdvkOJ1Xr12d/atNYdbZ3mHr1X1p2699bLXK+JdReVO3gdI/q/Id230p2swOr3x4xcU5HjNxISIiqkwUmw12rg5dbpXxDyIiIiIih3jFhYiIyA0UxcWsIoW3ioiIiOgG4TMuzuGtIiIiIqoyeMWFiIjIDXjFxTm84kJEROQGil0R1XOde12/RRYzMzPRr18/BAYGIjg4GIMGDUJubm6p+3Tq1AkGg0HzGjp0qGab48ePo2fPnvD19UVERARGjRqFkpKSco3NY6649P75DQRYzJgV0kG03Roi64vEzhom4jl9p4o48Ir6G+l7N4k4eNN8EQ/eLOuczHl3hYhn5H0p4oDo+iJevW6jiJ+fd7OI974h64BYfpN1ZgCgeXe5/4Gv9os47qXxIk7NXyji5BMXRBzkLc/jl33pIn4pTNZVOX/ylIgjb4nVHLtgk6z9Ym18p4gV+wkRl4TFidjoJWujZOTJH0pvH38RH1fVZDH7BYn4xHltLRWzr6zxci67QI7DT9ZlKbioqstSQ7X9afkZBPvK7W2F8hj+FvnPQF2TBQD8VXVc7MXyPT9vdb0WmZKorsuiqe9iUrWrtvc2quq42K+o46LznkmnIIdJ588QvXZ1TZErj633F41eDRS97fXqvpRWS0XvLb199I7hqfhxVB12mx12F66auLLvtfTr1w+nT5/G6tWrUVxcjIEDB2LIkCFYsmRJqfsNHjwYkyZNEl/7+vqK2GazoWfPnoiKisLmzZtx+vRp9O/fH97e3pgyZUqZx+YxExciIiK6tv3792PVqlXYvn072rZtCwB45513cM8992D69OmIiYnR3dfX1xdRUVEO3/v555+xb98+rFmzBpGRkWjVqhUmT56M0aNHY8KECTCbzQ73uxJvFREREbnB5WdcXHkBQE5OjuZVWFh4jSOXLjk5GcHBwWLSAgCJiYkwGo3YunVrKXsCixcvRnh4OG6++WaMGTMGFy/KSujJyclo3rw5IiNlVfhu3bohJycHf/31V5nHxysuREREblBRD+fWrl1b0z5+/HhMmDDB6X7T0tIQERGhafPy8kJoaCjS0tJ09/v3v/+NOnXqICYmBn/++SdGjx6NlJQUfPXVV6Jf9aQFgPi6tH6vxIkLERFRFZaamorAwEDxtcVicbjdSy+9hGnTppXa1/79+0t9vzRDhgwRcfPmzREdHY0uXbrgyJEjqF+/fil7lg8nLkRERG5QUZVzAwMDNRMXPc8//zwef/zxUrepV68eoqKikJGRoWkvKSlBZmam7vMrjsTHxwMADh8+jPr16yMqKgrbtm3TbJOefilZpDz9cuJCRETkBje6jkuNGjVQo0aNa26XkJCArKws7NixA23atAEArFu3Dna7XUxGymL37t0AgOjoaNHva6+9hoyMDHEravXq1QgMDETTpk3L3K/HTFxmvv0bzDDicP77os0rp6uIn4nsJOKlBxaI+NT8JzT9LNwsP9z752wR8YYn6ol46omDIt74ipxdtn55nojP/PihiMfWkc9Ih9aSs+b97y3THLvJ0H+J+LPP5eW+ZlZt6vJl3+45LeK2fvJp7RXHskQc3UbOcvPOyJTuiAeaafoq+fmAiI1xLVTvfC+iM0UyRdhkkWnWR7Nk6rG3nzy/v8/kidgcECrif87KdgCw+sqx51+QKcZW1Tllpsv6Ar4+Mu25KF8eO0jVT0mB3F6dJl1SpE3F1qRDq9KbfVXp0PaSYsft6rRnkyr1WLWiq9VL//l4s9e1057Lkiatlx1bWtqsXopxeVNtdVOYndinvJzpp6IyiY3MSaYqrEmTJujevTsGDx6MefPmobi4GElJSXj44YdFRtHJkyfRpUsXLFq0CO3atcORI0ewZMkS3HPPPQgLC8Off/6JESNG4I477kCLFpf+n9G1a1c0bdoUjz32GN544w2kpaXhlVdewbBhw3RvbzniMRMXIiKiyqQyV85dvHgxkpKS0KVLFxiNRvTp0wezZ88W7xcXFyMlJUVkDZnNZqxZswazZs1CXl4eateujT59+uCVV14R+5hMJnz33Xd46qmnkJCQAD8/PwwYMEBT96UsOHEhIiJyA7vdDrsLz7i4su+1hIaGllpsLi4uDooiK/fWrl0bGzdu1N3+sjp16uCHH35waWys40JERERVBq+4EBERuUFlvlVUmXHiQkRE5AaXJi62a29Yyv6eiBMXIiIiN7i8yrMr+3sij5m4DE9KQIDFjC9qtRZtbw+bJeLpbaJFvESV3vplw8c0/SztKFc3vq33SyJO2ZMq4trxMoX6pw/WiXjOQzKNePXLMvUra75MbW75ZHsRr5i2VnPsposfEfGZQrmS5veH5MrNMVaZ2vvVHllC+dGbZLpx5vFDIq7ZSaZ3FyxRrQDdsge0ZDp0flAtEZvMMu35eI5cH8PsK9Oej2TK9GZroKwh8PcZmZLsEyBXdM7J1q6z4RMg05gv5sqU5AhV6nhRvvyehfmr0p7z5THCVOnT6rTnIFU6tHoFaAAIMKvToeUxfHRWh1anN+ulPSt6adJXrNCsuwp0OVdcNhkdH0Ovn9L6Ku8q0BWpMq4C7c6050r4cRDdEB4zcSEiIqpMFLuLz7jwigsRERHdMC4+nAsPfcaF6dBERERUZbh14rJp0ybcd999iImJgcFgwIoVKzTvK4qCcePGITo6Gj4+PkhMTMShQ4ccd0ZERFSF2G12l1+eyK0Tl7y8PLRs2RJz5sxx+P4bb7yB2bNnY968edi6dSv8/PzQrVs3FBQU3OCREhERVazLWUWuvDyRW59x6dGjB3r0uDJ75RJFUTBr1iy88sor6NWrFwBg0aJFiIyMxIoVK/Dwww/fyKESERFRJVBpn3E5evQo0tLSkJiYKNqCgoIQHx+P5ORk3f0KCwuRk5OjeREREVU2lyvnuvLyRJU2qygt7VINksjISE17ZGSkeM+RqVOnYuLEiVe1f9dzDKx+ASia2120/fntMhE33yRrpozYfFzG4z/V9HOkt6wL4lejtoiXfblaxJOT40W8d4Gs91Fn93IRd+51k4i3zZC1XrpvWyr3ffl7zbFXH78o4iBvOedcvvkfEb8U4Svi9w7L84jt1FDEeZtkzZmg2+4UsX2RPF5xzM2aYxu9ZA2U49mynonZL0jEB86q6rUEyXotB05fULWHiPjUOXk+foGyrk1utqyxAgDBNWSNl6wMeYxw1T4H8+QxQv1ku60M9VoCLepaLdo6Lup6Ler3fNXtqtooFpPjei0Wk+O6L95G/b8dVF1p66/o7KKuy6LeXu8IerVaLvXluF2vlopeX3qHKO3Y5a3XUlpfDvsv3+Zux3ot1ZdiU6DYlGtvWMr+nqjSXnFx1pgxY5CdnS1eqamp196JiIiIqoRKe8UlKioKAJCeno7oaFnVNj09Ha1atdLdz2KxwGKx6L5PRERUGdjtrmUG2T304dxKe8Wlbt26iIqKwtq18hZOTk4Otm7dioSEBDeOjIiIyHWKXXH55YncesUlNzcXhw8fFl8fPXoUu3fvRmhoKGJjYzF8+HC8+uqraNiwIerWrYuxY8ciJiYGvXv3dt+giYiIKoDdBtiNzk8+7M4vLF2luXXi8vvvv+Ouu+4SX48cORIAMGDAACxcuBAvvvgi8vLyMGTIEGRlZaFjx45YtWoVrFaru4ZMREREbuTWiUunTp2gKPqzTYPBgEmTJmHSpEk3cFRERETXn2KzQzG6sMgi06GrtwkvzYTBZEZeygrRtmbFeRG3ff4HEacMlPmH08+na/pZOEJuN+Szr0Wc/dNHIu7rc1TEdTvUEnHy6A9EfMf/poj4wyVPijhaqSli8xV5nu//8reIB4T4iHjpX6dEXK9rfRHnHDgo4qiBd4i45OffZKeN5PNCBuMqEafmax9/Uqc978mQqceWoHAR7z0pa+ZYQ6JEfPCUbPcPllfLLmTKVGVfVWpzxvFszbHj6oWK+O88mY5eI0D2VXxR7hOh6qs4X24f4itTutVp0v6adGiZ6g0AAWbHac9WL1Xas022q9Ok1cxejnNavVSbK1dc9zXp5MHqpT3rpTCbdPKFS0uzvd5pz+VNeS6tLz0VmUVsZE4yXQeKTYHiwq0ipkMTERERVXIec8WFiIioMrHbFBcfzvXMKy6cuBAREbkBn3FxDm8VERERUZXBKy5ERERuYFcU2F0oImcvJSu3OuPEhYiIyB1sChSDC5MPD33GhbeKiIiIqMrwmCsuLe/vAy+rH5q/dUS07R0cKGL//60X8f96yvWR+s1bqunn4MOydsvsZkUi/q2tXAhyy5P/FXG7maNEPKb9cBGHh7UVsXrS/MZaWXull6pWCwCs+P2kiJvdI+u1nP/7DxHXefFuERe+vF3Eptay3WDcIuIT9gARq2u1/JEma7UAgDUkUsQ7j2eJ2K9GrIj/TJXtgaG+Is4+d1HE/kHynM6q6rvUrhMs4n/+OqE5dnRwXREX5127Xkuon+N6LUFWx/Va/M2y3VYiv6eAti6LXr0WdS0Vdb0Wdbu3Ua/2in59EP19HG9f3notpR27ouq1OMNT67WwVIznsdvssBtcWGTRQx/O9ZiJCxERUWWiuHiryFML0HHiQkRE5AacuDiHz7gQERFRlcErLkRERG7AZ1ycw4kLERGRGyiKAsWFOi6Kh9Zx4a0iIiIiqjI85orLj3dkI9CvGCGjfhVt7378g4iHfybTnP+4X7bPbaFNC97WqY6IN/3ff0R8x/+miPiFVk+K2Bp1h4htqtnxf1fuE/GAcJk6/PymwyKe9H+NNcc+e0CmMdd9pZeIC0b/JmLjbc+J2GDcKeJ/ECJiS0CoPJ+TMiXZJyxGxL/9nak5tjrtecdR+V6Qauzn02VKcmCYTHvOOC5TmGvVlinXx/fLtOdaITLlecsF7bFrqdLCi1Tp0JGBVhGr055DfLxFrE57DrI4TnsOMDtOeQa0qdLqlGSrt9Fhu9nkOIXZSyfHVy/lGbj+ac+lpR2XN+3ZoHMMvXZn0qcrKluYKc9UWdhtCuzgIovlxSsuREREbqDYlEsLLTr9un4Tl8zMTPTr1w+BgYEIDg7GoEGDkJubq7v9sWPHYDAYHL6WL18utnP0/tKlS3X7dcRjrrgQERFR2fTr1w+nT5/G6tWrUVxcjIEDB2LIkCFYsmSJw+1r166N06dPa9o++OADvPnmm+jRo4emfcGCBejevbv4Ojg4uFxj48SFiIjIDRSbAsWFW0XX64rL/v37sWrVKmzfvh1t216q8v7OO+/gnnvuwfTp0xETE3PVPiaTCVFRUZq2r7/+Gg899BD8/f017cHBwVdtWx68VUREROQGdpvi8ut6SE5ORnBwsJi0AEBiYiKMRiO2bt1apj527NiB3bt3Y9CgQVe9N2zYMISHh6Ndu3aYP39+ubOjeMWFiIioCsvJydF8bbFYYLFYdLa+trS0NERERGjavLy8EBoairS0tDL18fHHH6NJkyZo3769pn3SpEno3LkzfH198fPPP+Ppp59Gbm4unn322TKPj1dciIiI3ECx211+AZeeLwkKChKvqVOnOjzeSy+9pPsA7eXXgQMHXD6v/Px8LFmyxOHVlrFjx6JDhw5o3bo1Ro8ejRdffBFvvvlmufr3mCsur/YYC4vBiC/+TBZt21uvFPHYApkCfXJIGxF/cYdMeQaAB/Z8L+Jnou4S8Rl7ExH7mOR88NnFMiV5XD2Zkjxw7W4Rzx0qZ6RnfpYpz/Xf1X7TC5/8Un7R8WERGr3kKtAHCvzkOFQrOq9VpTf7R8aJePX+DBEHxciU5B2Hz2qOHRop71GeU60cHVxDHu/EoXMibtQwTMRHd/8t4no1Goh4c/YZEddRpVWrU54BIDpIpj2XFOSJONxXpj3bigpEHGJVtavSnjWrQxfrtF+xOrTVq3xpz97lTHvWS3kG9NOeddOky5l6XFpmbnnTnsvbT2mqUtqz3iGY9kxlUVHp0KmpqQgMDBTteldbnn/+eTz++OOl9lmvXj1ERUUhIyND015SUoLMzMwyPZvyxRdf4OLFi+jfv/81t42Pj8fkyZNRWFhY5qtEHjNxISIiqkwUu4sP5/7/qruBgYGaiYueGjVqoEaNGtfcLiEhAVlZWdixYwfatLn0h/y6detgt9sRHx9/zf0//vhj3H///WU61u7duxESElKuW1ucuBAREZHQpEkTdO/eHYMHD8a8efNQXFyMpKQkPPzwwyKj6OTJk+jSpQsWLVqEdu3aiX0PHz6MTZs24Ycffriq35UrVyI9PR233XYbrFYrVq9ejSlTpuCFF14o1/g4cSEiInIHmx2K4sJ9Rfv1W2Rx8eLFSEpKQpcuXWA0GtGnTx/Mnj1bvF9cXIyUlBRcvHhRs9/8+fNRq1YtdO3a9ao+vb29MWfOHIwYMQKKoqBBgwaYMWMGBg8eXK6xceJCRETkBnabArsLCyXaXVig8VpCQ0N1i80BQFxcnMM05ilTpmDKlCkO9gC6d++uKTznLGYVERERUZXBKy5ERERuoNiUchdf0+x/Ha+4VGacuBAREbmBXXHxVpEL+1ZlHjNx6VQ3GH4mE0JHPSraRq98WcQTe74q4idO7Bbxpveba/r5eX2WiNuHyPoiL78vyyB/0esmEc/5eY2Ib5/6bxGffVXWXol8W46j5NvXRHyq7p2aY3v7yb5+PiZrqQTE1Bfx53+cEnFQbFMRf7PrpIjD6sSK+M8UWUslonaQiDNOaCsxNmgi09r+3HJUxO1ayTUrUjbvEXHDSHnsn3POqNplPZhiVb2WmoGOa7UAQISfTJMrKcoXcbivWcQ2VV2WUB9Zx0VdryXAIn/c1bVU9Gq1AIDFy3H9FbNOgRKzTr0WL53tvUop5KJbr6Xc9V0ct5dWY0WvXovePuWtFePM44h6dVncWa+FiG48j5m4EBERVSY2RYHNhasmruxblXHiQkRE5AY25dLLlf09EbOKiIiIqMrgFRciIiI34K0i53DiQkRE5Aa8VeQcTlyIiIjcwO7iFRemQ1dzdVZ9j4CAQMyMlOnNBf1aibi9n0yh7TFBph1/8a8mmn7u/OhLEb/z4ZMifurVlSJu+uO7Is7vIdObz971XxF7zxwr4h8z/UQcFCuP98HWVM2xw2+6VcTzNv0t4qhGMvX4p21yn1o3yeXHj6acFbFeanO37rKflTv2aY59S3eZ4p28cqOIW8e2F/HybJn23ChCpj0XXTgv4tpBPrL9oky51qRDF8qUZwCI9JNpz+r05lBfVdpziTrt2eSw3Ucn7dlSSkqy1aSTDm1y3JdeerO3ztNk3qXkJOulUJc3vVkvtVkvrbrUvnS2L2+2cGkpzNc7vbm07pn2TFT5eczEhYiIqDKxwcVbRRU2kqqFExciIiI3sCkKbODDueXFdGgiIiKqMnjFhYiIyA1simu3e5hVRERERDcMJy7O4a0iIiIiqjJ4xYWIiMgN+HCuczxm4tJ5yBwYvKw49nF/0VbjzfdE/MGuZSJ+qvfbIo7e8IWmn6LuY0S8ucVzIg6I/kDEb/wlL/5FtbxLxCNW/CXiuHadRTzlq70irn9raxF/vfqw5tiN29YR8b7fZb2WLomyxsqPX28R8ROPdxLx+/O+E/HQf90s4l+/WCXi2xvcIeJl505pjt2mdrCIC7NlTZhG4bIGTaGqXku9UF8RF+fnijg2SNZrsanqtdRQ1WqxFWnruARb5Y+pui6Lv7fjWiq+Ou16dVx8dLYHALNO0RS9dr26LOWtyQLo11kpd3s5a7KU9p5ejZXytjtDr6vythNVFnYXbxXZPXPewltFREREVHV4zBUXIiKiyoS3ipzDiQsREZEbMKvIOZy4EBERucGliYsrV1wqcDBVCJ9xISIioiqDV1yIiIjcgLeKnOMxExef0BgYvX0w1NRCtNXtKFN+71yaKeKWvR8WcZfXNmj6SXjkQRH/561NIr7n391E/N5Hcp/+j3YU8UcffC/iMS88IOJXX1ss4pmvDRTxs6Pmao796hPPyH6Xfi3iR0bL1OrP3t4vx9TkIRG/lXZMxHfGhYo4/3y6iNvEBIq48IL8PACgiSrtuSgvW8Rxwar0ZlUac0yA4/TmMB/Hqc0hVpOIr0xJDrI4Tlf2Nzvex8/b8YVEHy/H+bHWUnKSLV6O+yp3mrROu16aNKCfxmzSyfPVa3cmVVnvvYpKSS4tVZlpzOQp+HCuc3iriIiIiKoMj7niQkREVJkoAOwu7u+JOHEhIiJyA94qcg5vFREREVGVwSsuREREbsCsIudw4kJEROQGvFXkHI+ZuOx+50EEBgYisP0w0ZazeY6Iy9IOANt13vtwpqr9Lbnq9PjOj4n4rVdkqvLTbWNE/FL6MRH3bRou4sHn0zTH7lE/WMTqdOWOtfxFXFIgV2K+JVKu0KxOSW4cahGxOiW5XpC3w3YAqB0gf1TUqccxfo7bI3xkqrJamNXx3ckQi/5dy0Cz4/cCvB3nzfrppD37OpMOrTMsvXadIem26wyp1PeMOr/oKqq9tPcMOr8oK6r9RhyDx+axy/IeVV4eM3EhIiKqTHiryDmcuBAREbkBbxU5hxMXIiIiN7C7eMXF7pnzlqqRDj1nzhzExcXBarUiPj4e27Ztc/eQiIiIyA0q/cRl2bJlGDlyJMaPH4+dO3eiZcuW6NatGzIyMtw9NCIiIqfZFMXllyeq9BOXGTNmYPDgwRg4cCCaNm2KefPmwdfXF/Pnz3f30IiIiJxmw/9/QNfZl7tPwE0q9TMuRUVF2LFjB8aMGSPajEYjEhMTkZyc7HCfwsJCFBYWiq+zsy+tZHzhwgUAgGKTab45OTkiLku7M/tUVDuPzWPz2Dw2j339j63Yii/99wZczShyaaUi1/evspRK7OTJkwoAZfPmzZr2UaNGKe3atXO4z/jx4xVcWnuKL7744osvvpx6paamXrf/t+Xn5ytRUVEVMs6oqCglPz//uo21MqrUV1ycMWbMGIwcOVJ8nZWVhTp16uD48eMICgpy48hurJycHNSuXRupqakIDAx093BuGJ43z9sT8Lyv33krioILFy4gJibm2hs7yWq14ujRoygqKrr2xtdgNpthtVorYFRVR6WeuISHh8NkMiE9PV3Tnp6ejqioKIf7WCwWWCyWq9qDgoI86h/4ZYGBgTxvD8Lz9iw87+vjRvyRa7VaPW7CUVEq9cO5ZrMZbdq0wdq1a0Wb3W7H2rVrkZCQ4MaRERERkTtU6isuADBy5EgMGDAAbdu2Rbt27TBr1izk5eVh4MCB7h4aERER3WCVfuLSt29fnDlzBuPGjUNaWhpatWqFVatWITIyskz7WywWjB8/3uHto+qM583z9gQ8b543eR6DonhoBRsiIiKqcir1My5EREREapy4EBERUZXBiQsRERFVGZy4EBERUZVRrScuc+bMQVxcHKxWK+Lj47Ft2zZ3D6lCTZ06FbfeeisCAgIQERGB3r17IyUlRbNNQUEBhg0bhrCwMPj7+6NPnz5XFfSr6l5//XUYDAYMHz5ctFXX8z558iQeffRRhIWFwcfHB82bN8fvv/8u3lcUBePGjUN0dDR8fHyQmJiIQ4cOuXHErrPZbBg7dizq1q0LHx8f1K9fH5MnT9asJVMdznvTpk247777EBMTA4PBgBUrVmjeL8s5ZmZmol+/fggMDERwcDAGDRqE3NzcG3gW5VfaeRcXF2P06NFo3rw5/Pz8EBMTg/79++PUqVOaPqrieZPzqu3EZdmyZRg5ciTGjx+PnTt3omXLlujWrRsyMjLcPbQKs3HjRgwbNgxbtmzB6tWrUVxcjK5duyIvL09sM2LECKxcuRLLly/Hxo0bcerUKTzwwANuHHXF2r59O95//320aNFC014dz/v8+fPo0KEDvL298eOPP2Lfvn146623EBISIrZ54403MHv2bMybNw9bt26Fn58funXrhoKCAjeO3DXTpk3D3Llz8e6772L//v2YNm0a3njjDbzzzjtim+pw3nl5eWjZsiXmzJnj8P2ynGO/fv3w119/YfXq1fjuu++wadMmDBky5EadglNKO++LFy9i586dGDt2LHbu3ImvvvoKKSkpuP/++zXbVcXzJhe4cZ2k66pdu3bKsGHDxNc2m02JiYlRpk6d6sZRXV8ZGRkKAGXjxo2KoihKVlaW4u3trSxfvlxss3//fgWAkpyc7K5hVpgLFy4oDRs2VFavXq3ceeedynPPPacoSvU979GjRysdO3bUfd9utytRUVHKm2++KdqysrIUi8WifPbZZzdiiNdFz549lSeeeELT9sADDyj9+vVTFKV6njcA5euvvxZfl+Uc9+3bpwBQtm/fLrb58ccfFYPBoJw8efKGjd0VV563I9u2bVMAKP/884+iKNXjvKl8quUVl6KiIuzYsQOJiYmizWg0IjExEcnJyW4c2fWVnZ0NAAgNDQUA7NixA8XFxZrPoXHjxoiNja0Wn8OwYcPQs2dPzfkB1fe8v/32W7Rt2xYPPvggIiIi0Lp1a3z44Yfi/aNHjyItLU1z3kFBQYiPj6/S592+fXusXbsWBw8eBAD88ccf+PXXX9GjRw8A1fe81cpyjsnJyQgODkbbtm3FNomJiTAajdi6desNH/P1kp2dDYPBgODgYACec94kVfrKuc44e/YsbDbbVdV1IyMjceDAATeN6vqy2+0YPnw4OnTogJtvvhkAkJaWBrPZLP6BXxYZGYm0tDQ3jLLiLF26FDt37sT27duveq+6nvfff/+NuXPnYuTIkfjvf/+L7du349lnn4XZbMaAAQPEuTn6ua/K5/3SSy8hJycHjRs3hslkgs1mw2uvvYZ+/foBQLU9b7WynGNaWhoiIiI073t5eSE0NLTafA4FBQUYPXo0HnnkEbHIoiecN2lVy4mLJxo2bBj27t2LX3/91d1Due5SU1Px3HPPYfXq1R61uqrdbkfbtm0xZcoUAEDr1q2xd+9ezJs3DwMGDHDz6K6fzz//HIsXL8aSJUvQrFkz7N69G8OHD0dMTEy1Pm/SKi4uxkMPPQRFUTB37lx3D4fcqFreKgoPD4fJZLoqiyQ9PR1RUVFuGtX1k5SUhO+++w7r169HrVq1RHtUVBSKioqQlZWl2b6qfw47duxARkYGbrnlFnh5ecHLywsbN27E7Nmz4eXlhcjIyGp53tHR0WjatKmmrUmTJjh+/DgAiHOrbj/3o0aNwksvvYSHH34YzZs3x2OPPYYRI0Zg6tSpAKrveauV5RyjoqKuSj4oKSlBZmZmlf8cLk9a/vnnH6xevVpcbQGq93mTY9Vy4mI2m9GmTRusXbtWtNntdqxduxYJCQluHFnFUhQFSUlJ+Prrr7Fu3TrUrVtX836bNm3g7e2t+RxSUlJw/PjxKv05dOnSBXv27MHu3bvFq23btujXr5+Iq+N5d+jQ4ap094MHD6JOnToAgLp16yIqKkpz3jk5Odi6dWuVPu+LFy/CaNT+qjKZTLDb7QCq73mrleUcExISkJWVhR07doht1q1bB7vdjvj4+Bs+5opyedJy6NAhrFmzBmFhYZr3q+t5Uync/XTw9bJ06VLFYrEoCxcuVPbt26cMGTJECQ4OVtLS0tw9tArz1FNPKUFBQcqGDRuU06dPi9fFixfFNkOHDlViY2OVdevWKb///ruSkJCgJCQkuHHU14c6q0hRqud5b9u2TfHy8lJee+015dChQ8rixYsVX19f5dNPPxXbvP7660pwcLDyzTffKH/++afSq1cvpW7dukp+fr4bR+6aAQMGKDVr1lS+++475ejRo8pXX32lhIeHKy+++KLYpjqc94ULF5Rdu3Ypu3btUgAoM2bMUHbt2iWyZ8pyjt27d1dat26tbN26Vfn111+Vhg0bKo888oi7TqlMSjvvoqIi5f7771dq1aql7N69W/N7rrCwUPRRFc+bnFdtJy6KoijvvPOOEhsbq5jNZqVdu3bKli1b3D2kCgXA4WvBggVim/z8fOXpp59WQkJCFF9fX+X//u//lNOnT7tv0NfJlROX6nreK1euVG6++WbFYrEojRs3Vj744APN+3a7XRk7dqwSGRmpWCwWpUuXLkpKSoqbRlsxcnJylOeee06JjY1VrFarUq9ePeXll1/W/I+rOpz3+vXrHf57HjBggKIoZTvHc+fOKY888oji7++vBAYGKgMHDlQuXLjghrMpu9LO++jRo7q/59avXy/6qIrnTc4zKIqq/CQRERFRJVYtn3EhIiKi6okTFyIiIqoyOHEhIiKiKoMTFyIiIqoyOHEhIiKiKoMTFyIiIqoyOHEhIiKiKoMTF6JSTJgwAa1atarwfo8dOwaDwYDdu3frbrNhwwYYDAax5tLChQuvWvHa3Tp16oThw4e7exjXZDAYsGLFCncPg4gqACcuVC08/vjjMBgMV726d+/u7qFVmL59++LgwYPX/TgLFy4Un5/JZEJISAji4+MxadIkZGdna7b96quvMHny5Os+JledPn0aPXr0cPcwiKgCeLl7AEQVpXv37liwYIGmzWKxuGk0Fc/Hxwc+Pj435FiBgYFISUmBoijIysrC5s2bMXXqVCxYsAC//fYbYmJiAAChoaE3ZDyu4irBRNUHr7hQtWGxWBAVFaV5hYSEiPcNBgPef/993HvvvfD19UWTJk2QnJyMw4cPo1OnTvDz80P79u1x5MiRq/p+//33Ubt2bfj6+uKhhx666srDRx99hCZNmsBqtaJx48Z47733NO9v27YNrVu3htVqRdu2bbFr166rjvHDDz/gpptugo+PD+666y4cO3ZM8/6Vt4ou38b63//+h7i4OAQFBeHhhx/GhQsXxDYXLlxAv3794Ofnh+joaMycObNMt3cMBgOioqIQHR2NJk2aYNCgQdi8eTNyc3Px4osviu2u7CsuLg6vvvoq+vfvD39/f9SpUwfffvstzpw5g169esHf3x8tWrTA77//rjner7/+ittvvx0+Pj6oXbs2nn32WeTl5Wn6nTJlCp544gkEBAQgNjYWH3zwgXi/qKgISUlJiI6OhtVqRZ06dTB16lTN+ahvFe3ZswedO3eGj48PwsLCMGTIEOTm5or3H3/8cfTu3RvTp09HdHQ0wsLCMGzYMBQXF5f6uRHR9ceJC3mUyZMno3///ti9ezcaN26Mf//73/jPf/6DMWPG4Pfff4eiKEhKStLsc/jwYXz++edYuXIlVq1ahV27duHpp58W7y9evBjjxo3Da6+9hv3792PKlCkYO3YsPvnkEwBAbm4u7r33XjRt2hQ7duzAhAkT8MILL2iOkZqaigceeAD33Xcfdu/ejSeffBIvvfTSNc/nyJEjWLFiBb777jt899132LhxI15//XXx/siRI/Hbb7/h22+/xerVq/HLL79g586dTn12ERER6NevH7799lvYbDbd7WbOnIkOHTpg165d6NmzJx577DH0798fjz76KHbu3In69eujf//+uLxM2pEjR9C9e3f06dMHf/75J5YtW4Zff/31qu/DW2+9JSZ9Tz/9NJ566imkpKQAAGbPno1vv/0Wn3/+OVJSUrB48WLExcU5HF9eXh66deuGkJAQbN++HcuXL8eaNWuuOt769etx5MgRrF+/Hp988gkWLlyIhQsXOvXZEVEFcusSj0QVZMCAAYrJZFL8/Pw0r9dee01sA0B55ZVXxNfJyckKAOXjjz8WbZ999plitVrF1+PHj1dMJpNy4sQJ0fbjjz8qRqNRrDZdv359ZcmSJZrxTJ48WUlISFAURVHef/99JSwsTMnPzxfvz507VwGg7Nq1S1EURRkzZozStGlTTR+jR49WACjnz59XFEVRFixYoAQFBWnG5uvrq+Tk5Ii2UaNGKfHx8YqiXFpV2dvbW1m+fLl4PysrS/H19dWspH2lK4+jdnnc6enpiqJcvSp3nTp1lEcffVR8ffr0aQWAMnbsWNF2+XO//PkNGjRIGTJkiOY4v/zyi2I0GsVndmW/drtdiYiIUObOnasoiqI888wzSufOnRW73e5w3ACUr7/+WlEURfnggw+UkJAQJTc3V7z//fffK0ajUUlLS1MU5dLPU506dZSSkhKxzYMPPqj07dvXYf9EdOPwGReqNu666y7MnTtX03blMxgtWrQQcWRkJACgefPmmraCggLk5OQgMDAQABAbG4uaNWuKbRISEmC325GSkoKAgAAcOXIEgwYNwuDBg8U2JSUlCAoKAgDs378fLVq0gNVq1fShtn//fsTHx2vartzGkbi4OAQEBIivo6OjkZGRAQD4+++/UVxcjHbt2on3g4KC0KhRo2v2q0f5/1dJDAaD7jZl+YwBICMjA1FRUfjjjz/w559/YvHixZrj2O12HD16FE2aNLmq38u3si6f6+OPP467774bjRo1Qvfu3XHvvfeia9euDse3f/9+tGzZEn5+fqKtQ4cO4nt6eXzNmjWDyWQS20RHR2PPnj2lfTxEdANw4kLVhp+fHxo0aFDqNt7e3iK+/D9fR212u71Mx7z8XMSHH3541cRD/T+960U9duDS+Ms6dmfs378fgYGBCAsLK9OYyvIZ5+bm4j//+Q+effbZq/qKjY112O/lfi73ccstt+Do0aP48ccfsWbNGjz00ENITEzEF198Ud5TLNPxiMh9+IwL0TUcP34cp06dEl9v2bIFRqMRjRo1QmRkJGJiYvD333+jQYMGmlfdunUBAE2aNMGff/6JgoICTR9qTZo0wbZt2zRtV25TXvXq1YO3tze2b98u2rKzs51Oqc7IyMCSJUvQu3dvGI0V96vjlltuwb59+676/Bo0aACz2VzmfgIDA9G3b198+OGHWLZsGb788ktkZmZetV2TJk3wxx9/aB7+/e2338T3lIgqN05cqNooLCxEWlqa5nX27FmX+7VarRgwYAD++OMP/PLLL3j22Wfx0EMPiRTbiRMnYurUqZg9ezYOHjyIPXv2YMGCBZgxYwYA4N///jcMBgMGDx6Mffv24YcffsD06dM1xxg6dCgOHTqEUaNGISUlBUuWLHH5QdCAgAAMGDAAo0aNwvr16/HXX39h0KBBMBqNpd7qAS7dqklLS8Pp06exf/9+zJ8/H+3bt0dQUJDm4d+KMHr0aGzevBlJSUnYvXs3Dh06hG+++eaqh2VLM2PGDHz22Wc4cOAADh48iOXLlyMqKsphwb5+/fqJ7+nevXuxfv16PPPMM3jsscfEbSIiqrw4caFqY9WqVYiOjta8Onbs6HK/DRo0wAMPPIB77rkHXbt2RYsWLTTpzk8++SQ++ugjLFiwAM2bN8edd96JhQsXiisu/v7+WLlyJfbs2YPWrVvj5ZdfxrRp0zTHiI2NxZdffokVK1agZcuWmDdvHqZMmeLy2GfMmIGEhATce++9SExMRIcOHUTadmlycnIQHR2NmjVrIiEhAe+//z4GDBiAXbt2ITo62uVxqbVo0QIbN27EwYMHcfvtt6N169YYN26cqBVTFgEBAXjjjTfQtm1b3HrrrTh27Bh++OEHh1eGfH198dNPPyEzMxO33nor/vWvf6FLly549913K/K0iOg6MSiXn7YjomovLy8PNWvWxFtvvYVBgwa5ezhEROXGh3OJqrFdu3bhwIEDaNeuHbKzszFp0iQAQK9evdw8MiIi53DiQlTNTZ8+HSkpKTCbzWjTpg1++eUXhIeHu3tYRERO4a0iIiIiqjL4cC4RERFVGZy4EBERUZXBiQsRERFVGZy4EBERUZXBiQsRERFVGZy4EBERUZXBiQsRERFVGZy4EBERUZXBiQsRERFVGf8PPBFPYzTyCC0AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 트랜스포머 모델 번역"
      ],
      "metadata": {
        "id": "oyctfACs52KD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 언어 모델 및 데이터셋 준비\n",
        "!python -m spacy download de  # 독일어 모델 다운로드\n",
        "!python -m spacy download en  # 영어 모델 다운로드\n",
        "\n",
        "# from torchtext.datasets import multi30k\n",
        "# multi30k.URL[\"train\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/training.tar.gz\"\n",
        "# multi30k.URL[\"valid\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/validation.tar.gz\"\n",
        "# multi30k.URL[\"test\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/mmt16_task1_test.tar.gz\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBU91p_MGNC5",
        "outputId": "37676149-3e27-4741-b66e-839cff504362"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'de' are deprecated. Please use the\n",
            "full pipeline package name 'de_core_news_sm' instead.\u001b[0m\n",
            "Collecting de-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.7.0/de_core_news_sm-3.7.0-py3-none-any.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from de-core-news-sm==3.7.0) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.12.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.66.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (13.9.3)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.2)\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-3.7.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n",
            "full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.12.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.9.3)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torchtext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASAfE92LjtWi",
        "outputId": "b92c4530-3f10-48a7-80e1-4b34667f9deb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchtext\n",
            "  Downloading torchtext-0.18.0-cp310-cp310-manylinux1_x86_64.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext) (4.66.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.32.3)\n",
            "Requirement already satisfied: torch>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.5.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.3.0->torchtext) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.3.0->torchtext) (3.0.2)\n",
            "Downloading torchtext-0.18.0-cp310-cp310-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchtext\n",
            "Successfully installed torchtext-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.datasets import multi30k\n",
        "\n",
        "#대체 url\n",
        "multi30k.URL[\"train\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/training.tar.gz\"\n",
        "multi30k.URL[\"valid\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/validation.tar.gz\"\n",
        "multi30k.URL[\"test\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/mmt16_task1_test.tar.gz\""
      ],
      "metadata": {
        "id": "ZDyYFuFzHMBP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "outputId": "cd6aa82d-cf3f-48b6-e4ca-62e0b8433ea7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "/usr/local/lib/python3.10/dist-packages/torchtext/lib/libtorchtext.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-f762da37ab06>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmulti30k\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#대체 url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmulti30k\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mURL\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/training.tar.gz\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmulti30k\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mURL\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"valid\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/validation.tar.gz\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchtext/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# the following import has to happen first in order to load the torchtext C++ library\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_extension\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0m_TEXT_BUCKET\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://download.pytorch.org/models/text/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchtext/_extension.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m \u001b[0m_init_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchtext/_extension.py\u001b[0m in \u001b[0;36m_init_extension\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"torchtext C++ Extension is not found.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0m_load_lib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"libtorchtext\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;31m# This import is for initializing the methods registered via PyBind11\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m# This has to happen after the base library is loaded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchtext/_extension.py\u001b[0m in \u001b[0;36m_load_lib\u001b[0;34m(lib)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36mload_library\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m   1348\u001b[0m             \u001b[0;31m# static (global) initialization code in order to register custom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m             \u001b[0;31m# operators with the JIT.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m             \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloaded_libraries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: /usr/local/lib/python3.10/dist-packages/torchtext/lib/libtorchtext.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.datasets import Multi30k\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "# 토큰 생성 함수 정의\n",
        "def generate_tokens(text_iter, language):\n",
        "    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}  # 언어 인덱스 매핑\n",
        "    for text in text_iter:\n",
        "        yield token_transform[language](text[language_index[language]])         # 지정 언어에 해당하는 토큰화 적용 후 생성\n",
        "\n",
        "# 소스 및 타겟 언어 설정, 특수 토큰 정의\n",
        "SRC_LANGUAGE = \"de\"  # 소스 언어: 독일어\n",
        "TGT_LANGUAGE = \"en\"  # 타겟 언어: 영어\n",
        "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3  # 특수 토큰 인덱스\n",
        "special_symbols = [\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"]  # 특수 토큰 정의\n",
        "\n",
        "# 언어별 토크나이저 설정\n",
        "token_transform = {\n",
        "    SRC_LANGUAGE: get_tokenizer(\"spacy\", language=\"de_core_news_sm\"),\n",
        "    TGT_LANGUAGE: get_tokenizer(\"spacy\", language=\"en_core_web_sm\"),\n",
        "}\n",
        "print(\"Token Transform:\")\n",
        "print(token_transform)\n",
        "\n",
        "# 언어별로 단어 집합 구축\n",
        "vocab_transform = {}\n",
        "for language in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "    # Multi30k 데이터셋 학습에 사용\n",
        "    train_iter = Multi30k(split=\"train\", language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
        "    vocab_transform[language] = build_vocab_from_iterator(\n",
        "        generate_tokens(train_iter, language),  # 토큰 생성기 사용\n",
        "        min_freq=1,  # 최소 빈도 기준 설정\n",
        "        specials=special_symbols,  # 특수 토큰 추가\n",
        "        special_first=True\n",
        "    )\n",
        "\n",
        "# 각 언어별ㅀ 기본 인덱스를 미지정 토큰으로 설정\n",
        "for language in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "    vocab_transform[language].set_default_index(UNK_IDX)\n",
        "\n",
        "print(\"Vocab Transform:\")\n",
        "print(vocab_transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "Fhw3oa3QGOd8",
        "outputId": "1f5fd393-9919-4efd-ea19-184e3bd5c93a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "/usr/local/lib/python3.10/dist-packages/torchtext/lib/libtorchtext.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-d71745ceaf8a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMulti30k\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_vocab_from_iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 토큰 생성 함수 정의\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchtext/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# the following import has to happen first in order to load the torchtext C++ library\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_extension\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0m_TEXT_BUCKET\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://download.pytorch.org/models/text/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchtext/_extension.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m \u001b[0m_init_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchtext/_extension.py\u001b[0m in \u001b[0;36m_init_extension\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"torchtext C++ Extension is not found.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0m_load_lib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"libtorchtext\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;31m# This import is for initializing the methods registered via PyBind11\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m# This has to happen after the base library is loaded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchtext/_extension.py\u001b[0m in \u001b[0;36m_load_lib\u001b[0;34m(lib)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36mload_library\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m   1348\u001b[0m             \u001b[0;31m# static (global) initialization code in order to register custom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m             \u001b[0;31m# operators with the JIT.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m             \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloaded_libraries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: /usr/local/lib/python3.10/dist-packages/torchtext/lib/libtorchtext.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. 위치 인코딩과 임베딩 클래스 정의\n",
        "\n",
        "import math\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# 위치 인코딩 클래스 정의\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        # 위치와 변환 비율 계산\n",
        "        position = torch.arange(max_len).unsqueeze(1)  # 위치 행렬 생성\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "\n",
        "        # 위치별 sine과 cosine 함수를 적용 -> 위치 인코딩 행렬 생성\n",
        "        pe = torch.zeros(max_len, 1, d_model)\n",
        "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer(\"pe\", pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[: x.size(0)]  # 입력에 위치 인코딩을 추가 후 드롭아웃 적용\n",
        "        return self.dropout(x)\n",
        "\n",
        "# 토큰 임베딩 클래스 정의\n",
        "class TokenEmbedding(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_size):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_size)  # 임베딩 레이어\n",
        "        self.emb_size = emb_size\n",
        "\n",
        "    def forward(self, tokens):\n",
        "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)"
      ],
      "metadata": {
        "id": "GdFrCe9yGRVp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Seq2Seq Transformer 모델 정의\n",
        "\n",
        "class Seq2SeqTransformer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_encoder_layers,\n",
        "        num_decoder_layers,\n",
        "        emb_size,\n",
        "        max_len,\n",
        "        nhead,\n",
        "        src_vocab_size,\n",
        "        tgt_vocab_size,\n",
        "        dim_feedforward,\n",
        "        dropout=0.1,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        # 인코더와 디코더에 토큰 임베딩과 위치 인코딩을 적용\n",
        "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)  # 소스 임베딩\n",
        "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)  # 타겟 임베딩\n",
        "        self.positional_encoding = PositionalEncoding(d_model=emb_size, max_len=max_len, dropout=dropout)\n",
        "\n",
        "        # Transformer 모델 정의\n",
        "        self.transformer = nn.Transformer(\n",
        "            d_model=emb_size,\n",
        "            nhead=nhead,  # 헤드 수\n",
        "            num_encoder_layers=num_encoder_layers,  # 인코더 레이어 수\n",
        "            num_decoder_layers=num_decoder_layers,  # 디코더 레이어 수\n",
        "            dim_feedforward=dim_feedforward,  # 피드포워드 차원\n",
        "            dropout=dropout,\n",
        "        )\n",
        "        self.generator = nn.Linear(emb_size, tgt_vocab_size)  # 출력층 정의\n",
        "\n",
        "    # 모델의 순전파 정의\n",
        "    def forward(\n",
        "        self,\n",
        "        src,\n",
        "        trg,\n",
        "        src_mask,\n",
        "        tgt_mask,\n",
        "        src_padding_mask,\n",
        "        tgt_padding_mask,\n",
        "        memory_key_padding_mask,\n",
        "    ):\n",
        "        # 입력 토큰에 위치 인코딩 추가 후 임베딩\n",
        "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
        "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
        "\n",
        "        # Transformer를 통해 예측값 생성\n",
        "        outs = self.transformer(\n",
        "            src=src_emb,\n",
        "            tgt=tgt_emb,\n",
        "            src_mask=src_mask,\n",
        "            tgt_mask=tgt_mask,\n",
        "            memory_mask=None,\n",
        "            src_key_padding_mask=src_padding_mask,\n",
        "            tgt_key_padding_mask=tgt_padding_mask,\n",
        "            memory_key_padding_mask=memory_key_padding_mask\n",
        "        )\n",
        "        return self.generator(outs)  # 출력층에 통과하여 최종 예측값 반환\n",
        "\n",
        "    # 인코딩 및 디코딩 부분 정의\n",
        "    def encode(self, src, src_mask):\n",
        "        # 인코더를 사용해 소스 시퀀스 인코딩\n",
        "        return self.transformer.encoder(self.positional_encoding(self.src_tok_emb(src)), src_mask)\n",
        "\n",
        "    def decode(self, tgt, memory, tgt_mask):\n",
        "        # 디코더를 사용해 타겟 시퀀스 디코딩\n",
        "        return self.transformer.decoder(self.positional_encoding(self.tgt_tok_emb(tgt)), memory, tgt_mask)"
      ],
      "metadata": {
        "id": "i4AEil_8Gfte"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. 모델 초기화 및 학습 설정\n",
        "\n",
        "from torch import optim\n",
        "\n",
        "# 하이퍼파라미터와 모델 정의\n",
        "BATCH_SIZE = 128  # 배치 크기\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Seq2Seq Transformer 모델 초기화\n",
        "model = Seq2SeqTransformer(\n",
        "    num_encoder_layers=3,\n",
        "    num_decoder_layers=3,\n",
        "    emb_size=512,\n",
        "    max_len=512,\n",
        "    nhead=8,\n",
        "    src_vocab_size=len(vocab_transform[SRC_LANGUAGE]),  # 소스 단어집합 크기\n",
        "    tgt_vocab_size=len(vocab_transform[TGT_LANGUAGE]),  # 타겟 단어집합 크기\n",
        "    dim_feedforward=512,\n",
        ").to(DEVICE)\n",
        "\n",
        "# 손실 함수 및 옵티마이저 설정\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX).to(DEVICE)  # PAD 토큰 무시\n",
        "optimizer = optim.Adam(model.parameters())  # Adam 옵티마이저 설정\n",
        "\n",
        "# 모델 계층 구조 출력\n",
        "for main_name, main_module in model.named_children():\n",
        "    print(main_name)\n",
        "    for sub_name, sub_module in main_module.named_children():\n",
        "        print(\"└\", sub_name)\n",
        "        for ssub_name, ssub_module in sub_module.named_children():\n",
        "            print(\"│  └\", ssub_name)\n",
        "            for sssub_name, sssub_module in ssub_module.named_children():\n",
        "                print(\"│  │  └\", sssub_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "QNUVpKgnGixo",
        "outputId": "3f0914c0-37f0-4b05-af98-b5d2f48625da"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'vocab_transform' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-66e545a7eb9a>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mnhead\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0msrc_vocab_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_transform\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSRC_LANGUAGE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# 소스 단어집합 크기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mtgt_vocab_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_transform\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTGT_LANGUAGE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# 타겟 단어집합 크기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mdim_feedforward\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'vocab_transform' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 문장 생성을 위한 GPT-2 모델의 구조"
      ],
      "metadata": {
        "id": "Vyp0YEGa_dIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel\n",
        "\n",
        "# GPT-2 모델을 사전 학습된 가중치로 불러오기\n",
        "model = GPT2LMHeadModel.from_pretrained(pretrained_model_name_or_path=\"gpt2\")\n",
        "\n",
        "# 모델의 계층 구조를 탐색하며 출력\n",
        "for main_name, main_module in model.named_children():\n",
        "    # 최상위 계층 이름 출력\n",
        "    print(main_name)\n",
        "    for sub_name, sub_module in main_module.named_children():\n",
        "        # 두 번째 계층 이름 출력\n",
        "        print(\"└\", sub_name)\n",
        "        for ssub_name, ssub_module in sub_module.named_children():\n",
        "            # 세 번째 계층 이름 출력\n",
        "            print(\"│  └\", ssub_name)\n",
        "            for sssub_name, sssub_module in ssub_module.named_children():\n",
        "                # 네 번째 계층 이름 출력\n",
        "                print(\"│  │  └\", sssub_name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a0569b5493ef41e1b2600e3f0687fdd7",
            "b93082b072004993b51510d64fb622eb",
            "fb9f2957abfd4905af046ddc68c72754",
            "344ad04fcde54bcb8fd1d400f9059535",
            "e5cd804a1994413d8f01f271ec5bb026",
            "55867354bd0d46aa934bad69b4f307b7",
            "a02a0632b8484d1aa816f6e03c1f4dde",
            "874b4743a2fd4300b9227c6b3b252687",
            "4a09a232d4d04759a18cc5e67c5eebce",
            "1e3b9ff90d3c4b95ad87d1a1ab8a2cc2",
            "834dba36576548f1ae8202e978e1564c",
            "ac3c9f7c70b64de0bf07500d478b6960",
            "9ae36d207d294a7ba7dd3e57f61c1553",
            "42d51cac484940d49adfb9ef67336f43",
            "afac1f17c7f34b6782881d2fbaf409fa",
            "596684c017d14d9483f1f1b2c4be3528",
            "39e1fb93aa344fdfb25527ee69b90119",
            "6e44042405d34a2fb9c3c8734598f52c",
            "01c12063db0540a5bc97219a7dfd9579",
            "a47193859cfc4006a9f36aaf5d0a4a77",
            "488e1a58e75c4aabbd68e3eba0bc33b0",
            "6d0b328c907942bdbd3141f15c2c630e",
            "7c627897b892485b8157b871c79be6e5",
            "e9239c1474c248c1b99c040eb2535477",
            "2785cf8af95744d583720489eda55181",
            "24ab3136578a40f9b9667e9ab98ca0bf",
            "846b60c401b44299b3fa46ab73623a08",
            "83b6ce275af94a4b9df7cb4a18002b92",
            "8687929495634695ac005d9c3b4802d5",
            "73bbe4aa089945d095f3493e770e516a",
            "3fb5302b57c74ce297d654fe8d8d5870",
            "7bd4cac830a546a8a91ec43b97fb81f5",
            "5009798fdb90416e9e9a50755dcaf95e"
          ]
        },
        "id": "gwVJq5LX7x4D",
        "outputId": "b4119dad-eef9-4f08-cac8-b5486b31604b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a0569b5493ef41e1b2600e3f0687fdd7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ac3c9f7c70b64de0bf07500d478b6960"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7c627897b892485b8157b871c79be6e5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "transformer\n",
            "└ wte\n",
            "└ wpe\n",
            "└ drop\n",
            "└ h\n",
            "│  └ 0\n",
            "│  │  └ ln_1\n",
            "│  │  └ attn\n",
            "│  │  └ ln_2\n",
            "│  │  └ mlp\n",
            "│  └ 1\n",
            "│  │  └ ln_1\n",
            "│  │  └ attn\n",
            "│  │  └ ln_2\n",
            "│  │  └ mlp\n",
            "│  └ 2\n",
            "│  │  └ ln_1\n",
            "│  │  └ attn\n",
            "│  │  └ ln_2\n",
            "│  │  └ mlp\n",
            "│  └ 3\n",
            "│  │  └ ln_1\n",
            "│  │  └ attn\n",
            "│  │  └ ln_2\n",
            "│  │  └ mlp\n",
            "│  └ 4\n",
            "│  │  └ ln_1\n",
            "│  │  └ attn\n",
            "│  │  └ ln_2\n",
            "│  │  └ mlp\n",
            "│  └ 5\n",
            "│  │  └ ln_1\n",
            "│  │  └ attn\n",
            "│  │  └ ln_2\n",
            "│  │  └ mlp\n",
            "│  └ 6\n",
            "│  │  └ ln_1\n",
            "│  │  └ attn\n",
            "│  │  └ ln_2\n",
            "│  │  └ mlp\n",
            "│  └ 7\n",
            "│  │  └ ln_1\n",
            "│  │  └ attn\n",
            "│  │  └ ln_2\n",
            "│  │  └ mlp\n",
            "│  └ 8\n",
            "│  │  └ ln_1\n",
            "│  │  └ attn\n",
            "│  │  └ ln_2\n",
            "│  │  └ mlp\n",
            "│  └ 9\n",
            "│  │  └ ln_1\n",
            "│  │  └ attn\n",
            "│  │  └ ln_2\n",
            "│  │  └ mlp\n",
            "│  └ 10\n",
            "│  │  └ ln_1\n",
            "│  │  └ attn\n",
            "│  │  └ ln_2\n",
            "│  │  └ mlp\n",
            "│  └ 11\n",
            "│  │  └ ln_1\n",
            "│  │  └ attn\n",
            "│  │  └ ln_2\n",
            "│  │  └ mlp\n",
            "└ ln_f\n",
            "lm_head\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPT-2를 이용한 문장 생성"
      ],
      "metadata": {
        "id": "_llLTtyf_pDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade torch transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVOg4XumHnxb",
        "outputId": "ac2b202d-82e7-4abe-a6de-182d6870234d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Collecting torch\n",
            "  Downloading torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.46.2-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch)\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.1.0 (from torch)\n",
            "  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Collecting tokenizers<0.21,>=0.20 (from transformers)\n",
            "  Downloading tokenizers-0.20.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Downloading torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl (906.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.4/906.4 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.46.2-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m91.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.20.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, tokenizers, nvidia-cusolver-cu12, transformers, torch\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.3.3\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.3.3:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.3.3\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.5.1.17\n",
            "    Uninstalling nvidia-cudnn-cu12-9.5.1.17:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.5.1.17\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.19.1\n",
            "    Uninstalling tokenizers-0.19.1:\n",
            "      Successfully uninstalled tokenizers-0.19.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.44.2\n",
            "    Uninstalling transformers-4.44.2:\n",
            "      Successfully uninstalled transformers-4.44.2\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.0+cu121\n",
            "    Uninstalling torch-2.5.0+cu121:\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# 텍스트 생성 파이프라인을 'gpt2' 모델로 초기화\n",
        "generator = pipeline(task=\"text-generation\", model=\"gpt2\")\n",
        "\n",
        "# 텍스트 생성 실행: 주어진 문장으로부터 최대 20 토큰까지 생성\n",
        "outputs = generator(\n",
        "    text_inputs=\"Machine learning is\",  # 입력 문장\n",
        "    max_length=20,  # 생성할 최대 토큰 수\n",
        "    num_return_sequences=3,  # 반환할 생성된 문장의 개수\n",
        "    pad_token_id=generator.tokenizer.eos_token_id  # 패딩에 사용될 토큰 ID (모델 종료 토큰 ID)\n",
        ")\n",
        "\n",
        "# 생성된 문장 출력\n",
        "print(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "yATN-p8f_h_z",
        "outputId": "69279568-39d7-4da3-f7b4-4f6a794ca651"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Failed to import transformers.pipelines because of the following error (look up to see its traceback):\ncannot import name 'is_torchvision_v2_available' from 'transformers.utils.import_utils' (/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1602\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0;34m\"tensorflow_text\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_tensorflow_text_available\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTENSORFLOW_TEXT_IMPORT_ERROR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1603\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0;34m\"timm\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_timm_available\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTIMM_IMPORT_ERROR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1604\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0;34m\"torchaudio\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_torchaudio_available\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTORCHAUDIO_IMPORT_ERROR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPreTrainedFeatureExtractor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_processing_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseImageProcessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfiguration_auto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/image_processing_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mimage_processing_base\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatchFeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageProcessingMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mimage_transforms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcenter_crop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrescale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mimage_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChannelDimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/image_transforms.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExplicitEnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensorType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_jax_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_tf_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_torch_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m from .utils.import_utils import (\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mis_flax_available\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'is_torchvision_v2_available' from 'transformers.utils.import_utils' (/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py)",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-11b817121f1b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 텍스트 생성 파이프라인을 'gpt2' 모델로 초기화\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"text-generation\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1591\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0;34m\"librosa\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_librosa_available\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLIBROSA_IMPORT_ERROR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1592\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0;34m\"protobuf\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_protobuf_available\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPROTOBUF_IMPORT_ERROR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1593\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0;34m\"pyctcdecode\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_pyctcdecode_available\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPYCTCDECODE_IMPORT_ERROR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1594\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0;34m\"pytesseract\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_pytesseract_available\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPYTESSERACT_IMPORT_ERROR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1595\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0;34m\"sacremoses\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_sacremoses_available\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSACREMOSES_IMPORT_ERROR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0;34m\"timm\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_timm_available\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTIMM_IMPORT_ERROR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0;34m\"torchaudio\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_torchaudio_available\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTORCHAUDIO_IMPORT_ERROR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1605\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0;34m\"natten\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_natten_available\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNATTEN_IMPORT_ERROR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0;34m\"nltk\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_nltk_available\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNLTK_IMPORT_ERROR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0;34m\"tokenizers\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_tokenizers_available\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTOKENIZERS_IMPORT_ERROR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.pipelines because of the following error (look up to see its traceback):\ncannot import name 'is_torchvision_v2_available' from 'transformers.utils.import_utils' (/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPT-2 모델 실습"
      ],
      "metadata": {
        "id": "PR8YFOf__ySo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y torch torchtext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCJmwtobI6Ii",
        "outputId": "78a58cdd-1b56-47e6-f212-515751536584"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: torchtext 0.18.0\n",
            "Uninstalling torchtext-0.18.0:\n",
            "  Successfully uninstalled torchtext-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchtext"
      ],
      "metadata": {
        "id": "tsKEQm-rKcot",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 866
        },
        "outputId": "5a81fd24-4d84-4ddf-f507-c77b75b64c29"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting torch\n",
            "  Using cached torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Collecting torchtext\n",
            "  Using cached torchtext-0.18.0-cp310-cp310-manylinux1_x86_64.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.10/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.10/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.10/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.10/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext) (4.66.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.32.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext) (1.26.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2024.8.30)\n",
            "Using cached torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl (906.4 MB)\n",
            "Using cached torchtext-0.18.0-cp310-cp310-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: torch, torchtext\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.0+cu121 requires torch==2.5.0, but you have torch 2.5.1 which is incompatible.\n",
            "torchvision 0.20.0+cu121 requires torch==2.5.0, but you have torch 2.5.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-2.5.1 torchtext-0.18.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchgen"
                ]
              },
              "id": "a3bae5ce9b0d452193a6c8c76f2c56f6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchtext.datasets import CoLA\n",
        "from transformers import AutoTokenizer\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# collator 함수 정의(전처리 시 필요)\n",
        "def collator(batch, tokenizer, device):\n",
        "    source, labels, texts = zip(*batch) # 배치 데이터 언패킹해 소스, 라벨, 텍스트로 분리함\n",
        "\n",
        "    # 텍스트 데이터를 토크나이저로 토큰화 및 패딩 처리\n",
        "    tokenized = tokenizer(\n",
        "        texts,\n",
        "        padding=\"longest\",  # 가장 긴 문장에 맞춰 패딩\n",
        "        truncation=True,  # 지정된 최대 길이에 맞게 자르기\n",
        "        return_tensors=\"pt\"  # PyTorch 텐서로 반환\n",
        "    )\n",
        "\n",
        "    # 토큰화 결과 입력: IDs와 어텐션 마스크로 분리하고 디바이스에 올림\n",
        "    input_ids = tokenized[\"input_ids\"].to(device)\n",
        "    attention_mask = tokenized[\"attention_mask\"].to(device)\n",
        "    labels = torch.tensor(labels, dtype=torch.long).to(device)  # 라벨을 텐서로 변환하여 디바이스에 올림\n",
        "    return input_ids, attention_mask, labels  # 입력 IDs, 어텐션 마스크, 라벨 반환\n",
        "\n",
        "# CoLA 데이터셋을 리스트로 변환\n",
        "train_data = list(CoLA(split=\"train\"))  # 학습 데이터\n",
        "valid_data = list(CoLA(split=\"dev\"))    # 검증 데이터\n",
        "test_data = list(CoLA(split=\"test\"))    # 테스트 데이터\n",
        "\n",
        "# 'GPT2' 모델의 토크나이저 불러오고 패딩 토큰 설정\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "tokenizer.pad_token = tokenizer.eos_token  # GPT2에 'pad_token'이 없어서 'eos_token'을 대신 설정\n",
        "\n",
        "# 학습 시 필요한 하이퍼파라미터 설정\n",
        "epochs = 3  # 에폭 수\n",
        "batch_size = 16  # 배치 크기\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # GPU 사용 여부 확인\n",
        "\n",
        "# 데이터 로더 생성\n",
        "train_dataloader = DataLoader(\n",
        "    train_data,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=lambda x: collator(x, tokenizer, device),  # collator 함수로 배치를 전처리\n",
        "    shuffle=True,  # 학습 데이터는 매 에폭마다 셔플\n",
        ")\n",
        "valid_dataloader = DataLoader(\n",
        "    valid_data, batch_size=batch_size, collate_fn=lambda x: collator(x, tokenizer, device)\n",
        ")\n",
        "test_dataloader = DataLoader(\n",
        "    test_data, batch_size=batch_size, collate_fn=lambda x: collator(x, tokenizer, device)\n",
        ")\n",
        "\n",
        "# 데이터셋 크기 출력\n",
        "print(\"Train Dataset Length :\", len(train_data))\n",
        "print(\"Valid Dataset Length :\", len(valid_data))\n",
        "print(\"Test Dataset Length :\", len(test_data))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "5LJisrJT_vzS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "outputId": "e1e29a52-7edd-44e9-9a90-6ff2216a37fa"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "/usr/local/lib/python3.10/dist-packages/torchtext/lib/libtorchtext.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-dd3c74ba60cf>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCoLA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchtext/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# the following import has to happen first in order to load the torchtext C++ library\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_extension\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0m_TEXT_BUCKET\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://download.pytorch.org/models/text/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchtext/_extension.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m \u001b[0m_init_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchtext/_extension.py\u001b[0m in \u001b[0;36m_init_extension\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"torchtext C++ Extension is not found.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0m_load_lib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"libtorchtext\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;31m# This import is for initializing the methods registered via PyBind11\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m# This has to happen after the base library is loaded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchtext/_extension.py\u001b[0m in \u001b[0;36m_load_lib\u001b[0;34m(lib)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36mload_library\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m   1348\u001b[0m             \u001b[0;31m# static (global) initialization code in order to register custom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m             \u001b[0;31m# operators with the JIT.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m             \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloaded_libraries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: /usr/local/lib/python3.10/dist-packages/torchtext/lib/libtorchtext.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import optim\n",
        "from transformers import GPT2ForSequenceClassification\n",
        "\n",
        "\n",
        "# GPT-2 모델: 이진 분류\n",
        "model = GPT2ForSequenceClassification.from_pretrained(\n",
        "    pretrained_model_name_or_path=\"gpt2\",  # 사전 학습된 'GPT 2' 모델 불러오기\n",
        "    num_labels=2  # 분류 클래스 수 설정 (이진 분류)\n",
        ").to(device)  # 모델을 지정한 장치 (GPU 또는 CPU)로 이동\n",
        "\n",
        "# 패딩 토큰 ID를 종료 토큰 ID와 동일하게 설정 (GPT-2는 패딩 토큰 ID가 기본적으로 설정되어 있지 않음)\n",
        "model.config.pad_token_id = model.config.eos_token_id\n",
        "\n",
        "# Adam 옵티마이저 설정 (학습률 5e-5)\n",
        "optimizer = optim.Adam(model.parameters(), lr=5e-5)"
      ],
      "metadata": {
        "id": "e9Wa6x2w_8qc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "outputId": "bf3a3c88-fab6-4246-bf94-143f56ab8265"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'device' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c5ad4d741ff2>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt2\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# 사전 학습된 'GPT 2' 모델 불러오기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mnum_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m  \u001b[0;31m# 분류 클래스 수 설정 (이진 분류)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m ).to(device)  # 모델을 지정한 장치 (GPU 또는 CPU)로 이동\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# 패딩 토큰 ID를 종료 토큰 ID와 동일하게 설정 (GPT-2는 패딩 토큰 ID가 기본적으로 설정되어 있지 않음)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from torch import nn\n",
        "\n",
        "# 정확도 계산 함수 정의\n",
        "def calc_accuracy(preds, labels):\n",
        "    # 예측 결과에서 가장 높은 확률을 가진 클래스 선택\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    # 예측과 실제 라벨이 일치하는 비율을 계산하여 정확도 반환\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "# 학습 함수 정의\n",
        "def train(model, optimizer, dataloader):\n",
        "    model.train()  # 모델을 학습 모드로 설정\n",
        "    train_loss = 0.0  # 학습 손실 초기화\n",
        "\n",
        "    for input_ids, attention_mask, labels in dataloader:\n",
        "        # 모델에 입력 데이터를 전달하여 출력 계산\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            labels=labels\n",
        "        )\n",
        "\n",
        "        # 출력에서 손실 계산\n",
        "        loss = outputs.loss\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        optimizer.zero_grad()  # 옵티마이저의 기울기 초기화\n",
        "        loss.backward()  # 손실에 대한 역전파 수행\n",
        "        optimizer.step()  # 옵티마이저가 가중치를 업데이트\n",
        "\n",
        "    # 에폭별 평균 손실 계산\n",
        "    train_loss = train_loss / len(dataloader)\n",
        "    return train_loss\n",
        "\n",
        "# 평가 함수 정의\n",
        "def evaluation(model, dataloader):\n",
        "    with torch.no_grad():  # 평가 중에는 기울기 계산 비활성화\n",
        "        model.eval()  # 모델을 평가 모드로 설정\n",
        "        criterion = nn.CrossEntropyLoss()  # 손실 함수 정의\n",
        "        val_loss, val_accuracy = 0.0, 0.0  # 검증 손실 및 정확도 초기화\n",
        "\n",
        "        for input_ids, attention_mask, labels in dataloader:\n",
        "            # 모델에 입력 데이터 전달하여 출력 계산\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                labels=labels\n",
        "            )\n",
        "            logits = outputs.logits\n",
        "\n",
        "            # 손실 계산\n",
        "            loss = criterion(logits, labels)\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            label_ids = labels.to(\"cpu\").numpy()\n",
        "\n",
        "            # 정확도 계산\n",
        "            accuracy = calc_accuracy(logits, label_ids)\n",
        "\n",
        "            val_loss += loss\n",
        "            val_accuracy += accuracy\n",
        "\n",
        "    # 에폭별 평균 검증 손실과 정확도 계산\n",
        "    val_loss = val_loss / len(dataloader)\n",
        "    val_accuracy = val_accuracy / len(dataloader)\n",
        "    return val_loss, val_accuracy\n",
        "\n",
        "# 모델 학습 및 평가 루프\n",
        "best_loss = 10000  # 초기 최고 손실 설정\n",
        "for epoch in range(epochs):\n",
        "    # 학습 손실 계산\n",
        "    train_loss = train(model, optimizer, train_dataloader)\n",
        "\n",
        "    # 검증 손실 및 정확도 계산\n",
        "    val_loss, val_accuracy = evaluation(model, valid_dataloader)\n",
        "    print(f\"Epoch {epoch + 1}: Train Loss: {train_loss:.4f} Val Loss: {val_loss:.4f} Val Accuracy {val_accuracy:.4f}\")\n",
        "\n",
        "    # 현재 에폭의 검증 손실이 가장 낮을 경우 모델 가중치 저장\n",
        "    if val_loss < best_loss:\n",
        "        best_loss = val_loss\n",
        "        torch.save(model.state_dict(), \"../models/GPT2ForSequenceClassification.pt\")\n",
        "        print(\"Saved the model weights\")"
      ],
      "metadata": {
        "id": "74FzBWdGAB9N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "9c555052-3f2b-4ddc-e788-00c8a46c6182"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'epochs' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-c9408099b8db>\u001b[0m in \u001b[0;36m<cell line: 71>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;31m# 모델 학습 및 평가 루프\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0mbest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m  \u001b[0;31m# 초기 최고 손실 설정\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0;31m# 학습 손실 계산\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'epochs' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPT-2 이진 분류 모델을 사전 학습된 가중치로 불러와 초기화 후, 저장된 가중치 로드\n",
        "\n",
        "import torch\n",
        "\n",
        "# CUDA가 사용 가능한지 확인하고, 가능하다면 GPU 사용, 그렇지 않다면 CPU 사용\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = GPT2ForSequenceClassification.from_pretrained(\n",
        "    pretrained_model_name_or_path=\"gpt2\",  # 사전 학습된 'gpt2' 모델 사용\n",
        "    num_labels=2  # 분류할 클래스 수 (이진 분류)\n",
        ").to(device)  # 모델을 지정한 장치 (GPU 또는 CPU)로 이동\n",
        "\n",
        "#GPT-2에 기본 패딩 토큰 ID가 없어서 패딩 토큰 ID를 종료 토큰 ID와 동일하게 설정\n",
        "model.config.pad_token_id = model.config.eos_token_id\n",
        "\n",
        "# 저장된 모델 가중치 불러오기\n",
        "model.load_state_dict(torch.load(\"../models/GPT2ForSequenceClassification.pt\"))\n",
        "\n",
        "# 테스트 데이터셋을 사용하여 모델 평가\n",
        "test_loss, test_accuracy = evaluation(model, test_dataloader)\n",
        "\n",
        "# 테스트 손실과 정확도 출력\n",
        "print(f\"Test Loss : {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy : {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "yO-t2Jo9AMFp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "5286d1dc-3862-4739-e10a-6e31cea82c13"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'device' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-395643d86445>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt2\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# 사전 학습된 'gpt2' 모델 사용\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mnum_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m  \u001b[0;31m# 분류할 클래스 수 (이진 분류)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m ).to(device)  # 모델을 지정한 장치 (GPU 또는 CPU)로 이동\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#GPT-2에 기본 패딩 토큰 ID가 없어서 패딩 토큰 ID를 종료 토큰 ID와 동일하게 설정\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BERT 모델 실습"
      ],
      "metadata": {
        "id": "8yzsOoioARj9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Korpora"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "id": "ceOlijpPlkZb",
        "outputId": "668283d1-389a-49cb-8d18-32460e219144"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting Korpora\n",
            "  Downloading Korpora-0.2.0-py3-none-any.whl.metadata (26 kB)\n",
            "Collecting dataclasses>=0.6 (from Korpora)\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from Korpora) (1.26.4)\n",
            "Requirement already satisfied: tqdm>=4.46.0 in /usr/local/lib/python3.10/dist-packages (from Korpora) (4.66.6)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.10/dist-packages (from Korpora) (2.32.3)\n",
            "Requirement already satisfied: xlrd>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from Korpora) (2.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->Korpora) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->Korpora) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->Korpora) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->Korpora) (2024.8.30)\n",
            "Downloading Korpora-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: dataclasses, Korpora\n",
            "Successfully installed Korpora-0.2.0 dataclasses-0.6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dataclasses"
                ]
              },
              "id": "f3bf1ad329504a5b91db3a4ec2dd2368"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from Korpora import Korpora\n",
        "\n",
        "\n",
        "corpus = Korpora.load(\"nsmc\")\n",
        "df = pd.DataFrame(corpus.test).sample(20000, random_state=42)"
      ],
      "metadata": {
        "id": "bHFU3nySAU_h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd02a9e3-34ae-46a4-ff3f-8fb53e95df3d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    Korpora 는 다른 분들이 연구 목적으로 공유해주신 말뭉치들을\n",
            "    손쉽게 다운로드, 사용할 수 있는 기능만을 제공합니다.\n",
            "\n",
            "    말뭉치들을 공유해 주신 분들에게 감사드리며, 각 말뭉치 별 설명과 라이센스를 공유 드립니다.\n",
            "    해당 말뭉치에 대해 자세히 알고 싶으신 분은 아래의 description 을 참고,\n",
            "    해당 말뭉치를 연구/상용의 목적으로 이용하실 때에는 아래의 라이센스를 참고해 주시기 바랍니다.\n",
            "\n",
            "    # Description\n",
            "    Author : e9t@github\n",
            "    Repository : https://github.com/e9t/nsmc\n",
            "    References : www.lucypark.kr/docs/2015-pyconkr/#39\n",
            "\n",
            "    Naver sentiment movie corpus v1.0\n",
            "    This is a movie review dataset in the Korean language.\n",
            "    Reviews were scraped from Naver Movies.\n",
            "\n",
            "    The dataset construction is based on the method noted in\n",
            "    [Large movie review dataset][^1] from Maas et al., 2011.\n",
            "\n",
            "    [^1]: http://ai.stanford.edu/~amaas/data/sentiment/\n",
            "\n",
            "    # License\n",
            "    CC0 1.0 Universal (CC0 1.0) Public Domain Dedication\n",
            "    Details in https://creativecommons.org/publicdomain/zero/1.0/\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nsmc] download ratings_train.txt: 14.6MB [00:00, 85.2MB/s]                            \n",
            "[nsmc] download ratings_test.txt: 4.90MB [00:00, 43.4MB/s]                            \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터프레임을 무작위로 섞어 학습, 검증, 테스트 세트로 분할\n",
        "train, valid, test = np.split(\n",
        "    df.sample(frac=1, random_state=42),  # 데이터를 무작위로 섞음 (random_state로 시드 고정)\n",
        "    [int(0.6 * len(df)), int(0.8 * len(df))]  # 60%, 80% 인덱스 위치를 기준으로 분할\n",
        ")\n",
        "\n",
        "# 학습 데이터의 상위 5개 행을 Markdown 형식으로 출력\n",
        "print(train.head(5).to_markdown())\n",
        "\n",
        "# 각 데이터 세트의 크기 출력\n",
        "print(f\"Training Data Size : {len(train)}\")\n",
        "print(f\"Validation Data Size : {len(valid)}\")\n",
        "print(f\"Testing Data Size : {len(test)}\")"
      ],
      "metadata": {
        "id": "tp7ByWpBAWBb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29979538-38dc-468b-b960-d02bebd2961d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|       | text                                                     |   label |\n",
            "|------:|:---------------------------------------------------------|--------:|\n",
            "| 26891 | 역시 코믹액션은 성룡, 홍금보, 원표 삼인방이 최고지!!     |       1 |\n",
            "| 25024 | 점수 후하게 줘야것네 별 반개~                            |       0 |\n",
            "| 11666 | 오랜만에 느낄수 있는 [감독] 구타욕구.                    |       0 |\n",
            "| 40303 | 본지는 좀 됬지만 극장서 돈주고 본게 아직까지 아까운 영화 |       0 |\n",
            "| 18010 | 징키스칸이란 소재를 가지고 이것밖에 못만드냐             |       0 |\n",
            "Training Data Size : 12000\n",
            "Validation Data Size : 4000\n",
            "Testing Data Size : 4000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
            "  return bound(*args, **kwds)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch.utils.data import RandomSampler, SequentialSampler\n",
        "\n",
        "# 데이터셋 생성 함수 정의\n",
        "def make_dataset(data, tokenizer, device):\n",
        "    # 텍스트 데이터를 토크나이저로 토큰화 및 패딩 처리\n",
        "    tokenized = tokenizer(\n",
        "        text=data.text.tolist(),  # 데이터의 텍스트 열을 리스트로 변환\n",
        "        padding=\"longest\",  # 가장 긴 문장에 맞춰 패딩\n",
        "        truncation=True,  # 지정된 최대 길이에 맞게 자름\n",
        "        return_tensors=\"pt\"  # PyTorch 텐서로 반환\n",
        "    )\n",
        "    # 토큰화 결과를 입력 IDs와 어텐션 마스크로 분리하고, 디바이스에 올림\n",
        "    input_ids = tokenized[\"input_ids\"].to(device)\n",
        "    attention_mask = tokenized[\"attention_mask\"].to(device)\n",
        "\n",
        "    # 라벨 데이터를 텐서로 변환하여 디바이스에 올림\n",
        "    labels = torch.tensor(data.label.values, dtype=torch.long).to(device)\n",
        "\n",
        "    # 입력 IDs, 어텐션 마스크, 라벨을 TensorDataset으로 묶어서 반환\n",
        "    return TensorDataset(input_ids, attention_mask, labels)\n",
        "\n",
        "# 데이터 로더 생성 함수 정의\n",
        "def get_datalodader(dataset, sampler, batch_size):\n",
        "    data_sampler = sampler(dataset)  # 샘플러 설정\n",
        "    # 데이터셋을 주어진 샘플러와 배치 크기로 DataLoader 생성\n",
        "    dataloader = DataLoader(dataset, sampler=data_sampler, batch_size=batch_size)\n",
        "    return dataloader\n",
        "\n",
        "# 학습에 필요한 하이퍼파라미터 설정\n",
        "epochs = 5  # 학습 에폭 수\n",
        "batch_size = 32  # 배치 크기\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# BERT 토크나이저 불러오기\n",
        "tokenizer = BertTokenizer.from_pretrained(\n",
        "    pretrained_model_name_or_path=\"bert-base-multilingual-cased\",\n",
        "    do_lower_case=False  # 대소문자 구분 설정\n",
        ")\n",
        "\n",
        "# 학습, 검증, 테스트 데이터셋 생성 및 데이터로더 초기화\n",
        "train_dataset = make_dataset(train, tokenizer, device)\n",
        "train_dataloader = get_datalodader(train_dataset, RandomSampler, batch_size)  # 학습 데이터는 랜덤 샘플링 사용\n",
        "\n",
        "valid_dataset = make_dataset(valid, tokenizer, device)\n",
        "valid_dataloader = get_datalodader(valid_dataset, SequentialSampler, batch_size)  # 검증 데이터는 순차적 샘플링 사용\n",
        "\n",
        "test_dataset = make_dataset(test, tokenizer, device)\n",
        "test_dataloader = get_datalodader(test_dataset, SequentialSampler, batch_size)  # 테스트 데이터는 순차적 샘플링 사용\n",
        "\n",
        "# 첫 번째 학습 데이터셋 출력\n",
        "print(train_dataset[0])"
      ],
      "metadata": {
        "id": "k6vjf1TwAeW8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459,
          "referenced_widgets": [
            "21111788c24a4e969ef78d2fadd2613b",
            "fad2c2b7d54c4ceaa2a5bf7746fe1791",
            "e625668fafcd4248aa07282a5dc2a488",
            "6f5752e3723f4e64bf0c0e48289e0699",
            "0a668a5571d344f7b2cc990ebb55ec08",
            "fbd5f529af9a440a964b359bb36939c4",
            "e2622f0014c94294acb69e596d1da442",
            "f5a96573b56f46ea84ecdc815c91ace2",
            "a63391475d674848804fcd6502dc95a1",
            "fef1d9dde0ef4b8eabd875030ebfe2da",
            "03c46116ebb2491dab2580459967c879",
            "9d4b0d43f51a4391a22c117b40ecdb95",
            "97e84a53883d46b09252b8fa30d885b8",
            "7e6ea31fb7df40c691de61a8a802518e",
            "19727e3b763c4c5daa5becb7b7af79ab",
            "55705c190e1a4671bff52ec3073386ab",
            "5c93d9d83b77461c99b45d9f508270c3",
            "14d316a683384ed09594dc9fac1d62f8",
            "e7fbf603fd5e49da9bf13bee56c533af",
            "129cc473f6164f76aa6f7701d33f7bfc",
            "d9829dd332cd4f2f9a2ad62d4999a28e",
            "946466bd048942f5b969e93e7de6ca64",
            "98a425648757478cba21bfaecbd038bd",
            "50764927d3d240dc9bcc6da01d299b07",
            "326bef3870f240549024b34c6c7c2fd8",
            "173778f8109f43cc97eb9e14735e902e",
            "b511034b56974544990a2c313239a146",
            "2f291ecd2ab94657867beb81ce05c74b",
            "ea6fa11ce95049adaf6c6cb96b259561",
            "a5ee31ad1b40462fb44f9771b058268a",
            "e7e94bd620eb4fc4bf782a9887d5ae60",
            "035e9365c46543e49b0d1df95950130a",
            "bcc0018b3fa940d8a14e5d6cc52ea58d"
          ]
        },
        "outputId": "817c5b4a-2b2e-4490-e624-2fb3b9651313"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "21111788c24a4e969ef78d2fadd2613b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9d4b0d43f51a4391a22c117b40ecdb95"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "98a425648757478cba21bfaecbd038bd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([   101,  58466,   9812, 118956, 119122,  59095,  10892,   9434, 118888,\n",
            "           117,   9992,  40032,  30005,    117,   9612,  37824,   9410,  12030,\n",
            "         42337,  10739,  83491,  12508,    106,    106,    102,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0]), tensor(1))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import optim\n",
        "from transformers import BertForSequenceClassification\n",
        "import torch\n",
        "\n",
        "# CUDA가 사용 가능한지 확인하고, 가능하다면 GPU 사용, 그렇지 않다면 CPU 사용\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# BERT 이진 분류 모델 초기화 (사전 학습된 가중치 사용)\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    pretrained_model_name_or_path=\"bert-base-multilingual-cased\",  # 멀티언어 사전 학습 BERT 모델 불러오기\n",
        "    num_labels=2  # 분류할 클래스 수 (이진 분류)\n",
        ").to(device)  # 모델을 지정된 장치로 이동\n",
        "\n",
        "# AdamW 옵티마이저 설정 (가중치 감쇠 적용)\n",
        "optimizer = optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=1e-5,  # 학습률\n",
        "    eps=1e-8  # 수치 안정성을 위한 작은 값\n",
        ")"
      ],
      "metadata": {
        "id": "dWaiHQwMAhx5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a12eed16-8736-45c8-96d7-69ee46632c9f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델의 계층 구조를 탐색하며 출력하는 코드\n",
        "for main_name, main_module in model.named_children():\n",
        "    # 최상위 계층 이름 출력\n",
        "    print(main_name)\n",
        "    for sub_name, sub_module in main_module.named_children():\n",
        "        # 두 번째 계층 이름 출력\n",
        "        print(\"└\", sub_name)\n",
        "        for ssub_name, ssub_module in sub_module.named_children():\n",
        "            # 세 번째 계층 이름 출력\n",
        "            print(\"│  └\", ssub_name)\n",
        "            for sssub_name, sssub_module in ssub_module.named_children():\n",
        "                # 네 번째 계층 이름 출력\n",
        "                print(\"│  │  └\", sssub_name)"
      ],
      "metadata": {
        "id": "1W_eI7DUAobA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bf3ab3b-71bc-4463-8275-50686c5465e1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert\n",
            "└ embeddings\n",
            "│  └ word_embeddings\n",
            "│  └ position_embeddings\n",
            "│  └ token_type_embeddings\n",
            "│  └ LayerNorm\n",
            "│  └ dropout\n",
            "└ encoder\n",
            "│  └ layer\n",
            "│  │  └ 0\n",
            "│  │  └ 1\n",
            "│  │  └ 2\n",
            "│  │  └ 3\n",
            "│  │  └ 4\n",
            "│  │  └ 5\n",
            "│  │  └ 6\n",
            "│  │  └ 7\n",
            "│  │  └ 8\n",
            "│  │  └ 9\n",
            "│  │  └ 10\n",
            "│  │  └ 11\n",
            "└ pooler\n",
            "│  └ dense\n",
            "│  └ activation\n",
            "dropout\n",
            "classifier\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from torch import nn\n",
        "\n",
        "# 예측 정확도를 계산하는 함수 정의\n",
        "def calc_accuracy(preds, labels):\n",
        "    # 예측 결과에서 가장 높은 확률을 가진 클래스 선택\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    # 예측과 실제 라벨이 일치하는 비율을 계산하여 정확도 반환\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "# 모델 학습 함수 정의\n",
        "def train(model, optimizer, dataloader):\n",
        "    model.train()  # 모델을 학습 모드로 설정\n",
        "    train_loss = 0.0  # 학습 손실 초기화\n",
        "\n",
        "    # 배치별로 학습 데이터셋을 순회\n",
        "    for input_ids, attention_mask, labels in dataloader:\n",
        "        # 모델에 입력 데이터를 전달하여 출력 계산\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "\n",
        "        # 출력에서 손실 계산\n",
        "        loss = outputs.loss\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        optimizer.zero_grad()  # 옵티마이저의 기울기 초기화\n",
        "        loss.backward()  # 손실에 대한 역전파 수행\n",
        "        optimizer.step()  # 옵티마이저가 가중치 업데이트\n",
        "\n",
        "    # 에폭별 평균 학습 손실 계산\n",
        "    train_loss = train_loss / len(dataloader)\n",
        "    return train_loss\n",
        "\n",
        "# 모델 평가 함수 정의\n",
        "def evaluation(model, dataloader):\n",
        "    with torch.no_grad():  # 평가 중에는 기울기 계산 비활성화\n",
        "        model.eval()  # 모델을 평가 모드로 설정\n",
        "        criterion = nn.CrossEntropyLoss()  # 손실 함수 정의\n",
        "        val_loss, val_accuracy = 0.0, 0.0  # 검증 손실 및 정확도 초기화\n",
        "\n",
        "        # 배치별로 검증 데이터셋을 순회\n",
        "        for input_ids, attention_mask, labels in dataloader:\n",
        "            # 모델에 입력 데이터 전달하여 출력 계산\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            logits = outputs.logits\n",
        "\n",
        "            # 손실 계산\n",
        "            loss = criterion(logits, labels)\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            label_ids = labels.to(\"cpu\").numpy()\n",
        "\n",
        "            # 정확도 계산\n",
        "            accuracy = calc_accuracy(logits, label_ids)\n",
        "\n",
        "            val_loss += loss\n",
        "            val_accuracy += accuracy\n",
        "\n",
        "    # 에폭별 평균 검증 손실과 정확도 계산\n",
        "    val_loss = val_loss / len(dataloader)\n",
        "    val_accuracy = val_accuracy / len(dataloader)\n",
        "    return val_loss, val_accuracy\n",
        "\n",
        "# 모델 학습 및 평가 루프\n",
        "best_loss = 10000  # 초기 최저 검증 손실 설정\n",
        "for epoch in range(epochs):\n",
        "    # 학습 손실 계산\n",
        "    train_loss = train(model, optimizer, train_dataloader)\n",
        "\n",
        "    # 검증 손실 및 정확도 계산\n",
        "    val_loss, val_accuracy = evaluation(model, valid_dataloader)\n",
        "    print(f\"Epoch {epoch + 1}: Train Loss: {train_loss:.4f} Val Loss: {val_loss:.4f} Val Accuracy {val_accuracy:.4f}\")\n",
        "\n",
        "    # 현재 에폭의 검증 손실이 가장 낮을 경우 모델 가중치 저장\n",
        "    if val_loss < best_loss:\n",
        "        best_loss = val_loss\n",
        "        torch.save(model.state_dict(), \"../models/BertForSequenceClassification.pt\")\n",
        "        print(\"Saved the model weights\")"
      ],
      "metadata": {
        "id": "rsSibcCLBCaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "# BERT 이진 분류 모델을 사전 학습된 가중치로 불러와 초기화하고, 저장된 가중치 로드\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    pretrained_model_name_or_path=\"bert-base-multilingual-cased\",  # 멀티언어 사전 학습 BERT 모델 사용\n",
        "    num_labels=2  # 분류할 클래스 수 (이진 분류)\n",
        ").to(device)  # 모델을 지정된 장치(GPU 또는 CPU)로 이동\n",
        "\n",
        "# 저장된 모델 가중치 로드\n",
        "model.load_state_dict(torch.load(\"../models/BertForSequenceClassification.pt\"))\n",
        "\n",
        "# 테스트 데이터셋을 사용하여 모델 평가\n",
        "test_loss, test_accuracy = evaluation(model, test_dataloader)\n",
        "\n",
        "# 테스트 손실과 정확도 출력\n",
        "print(f\"Test Loss : {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy : {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "PDkzkuFsEMhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BART 모델 실습"
      ],
      "metadata": {
        "id": "28FDGgPBEQHe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate rouge_score absl-py"
      ],
      "metadata": {
        "id": "Z7Mf1cC8EM1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news = load_dataset(\"argilla/news-summary\", split=\"test\")\n",
        "# 데이터셋에서 필요한 열 샘플링 후, prediction 열의 텍스트 추출\n",
        "df = news.to_pandas().sample(5000, random_state=42)[[\"text\", \"prediction\"]]\n",
        "df[\"prediction\"] = df[\"prediction\"].map(lambda x: x[0][\"text\"])\n",
        "\n",
        "# 데이터셋을 학습, 검증, 테스트 세트로 60%, 20%, 20% 비율로 분할\n",
        "train, valid, test = np.split(\n",
        "    df.sample(frac=1, random_state=42), [int(0.6 * len(df)), int(0.8 * len(df))]\n",
        ")"
      ],
      "metadata": {
        "id": "_0Upj0GmETSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BartTokenizer\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch.utils.data import RandomSampler, SequentialSampler\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# 데이터셋을 토크나이저로 처리하여 TensorDataset 형식으로 반환\n",
        "def make_dataset(data, tokenizer, device):\n",
        "    # 입력 텍스트 토큰화\n",
        "    tokenized = tokenizer(\n",
        "        text=data.text.tolist(),\n",
        "        padding=\"longest\",\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\",\n",
        "        max_length=1024\n",
        "    )\n",
        "    labels = []\n",
        "    input_ids = tokenized[\"input_ids\"].to(device)\n",
        "    attention_mask = tokenized[\"attention_mask\"].to(device)\n",
        "\n",
        "    # 요약 텍스트 토큰화 후 패딩\n",
        "    for target in data.prediction:\n",
        "        labels.append(tokenizer.encode(target, return_tensors=\"pt\").squeeze())\n",
        "    labels = pad_sequence(labels, batch_first=True, padding_value=-100).to(device)\n",
        "\n",
        "    return TensorDataset(input_ids, attention_mask, labels)\n",
        "\n",
        "# DataLoader 생성 함수 정의\n",
        "def get_datalodader(dataset, sampler, batch_size):\n",
        "    data_sampler = sampler(dataset)\n",
        "    dataloader = DataLoader(dataset, sampler=data_sampler, batch_size=batch_size)\n",
        "    return dataloader\n",
        "\n",
        "# 학습에 필요한 하이퍼파라미터 설정\n",
        "epochs = 5\n",
        "batch_size = 8\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# BART 토크나이저 불러오기\n",
        "tokenizer = BartTokenizer.from_pretrained(\n",
        "    pretrained_model_name_or_path=\"facebook/bart-base\"\n",
        ")\n",
        "\n",
        "# 학습, 검증, 테스트 데이터셋 생성 및 데이터로더 초기화\n",
        "train_dataset = make_dataset(train, tokenizer, device)\n",
        "train_dataloader = get_datalodader(train_dataset, RandomSampler, batch_size)\n",
        "\n",
        "valid_dataset = make_dataset(valid, tokenizer, device)\n",
        "valid_dataloader = get_datalodader(valid_dataset, SequentialSampler, batch_size)\n",
        "\n",
        "test_dataset = make_dataset(test, tokenizer, device)\n",
        "test_dataloader = get_datalodader(test_dataset, SequentialSampler, batch_size)\n",
        "\n",
        "# 첫 번째 학습 데이터셋 출력\n",
        "print(train_dataset[0])"
      ],
      "metadata": {
        "id": "3lmPYD6vEcEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import optim\n",
        "from transformers import BartForConditionalGeneration\n",
        "\n",
        "# BART 모델 불러오기\n",
        "model = BartForConditionalGeneration.from_pretrained(\n",
        "    pretrained_model_name_or_path=\"facebook/bart-base\"\n",
        ").to(device)\n",
        "\n",
        "# AdamW 옵티마이저 설정\n",
        "optimizer = optim.AdamW(model.parameters(), lr=5e-5, eps=1e-8)\n",
        "\n",
        "# 모델 계층 구조 출력\n",
        "for main_name, main_module in model.named_children():\n",
        "    print(main_name)\n",
        "    for sub_name, sub_module in main_module.named_children():\n",
        "        print(\"└\", sub_name)\n",
        "        for ssub_name, ssub_module in sub_module.named_children():\n",
        "            print(\"│  └\", ssub_name)\n",
        "            for sssub_name, sssub_module in ssub_module.named_children():\n",
        "                print(\"│  │  └\", sssub_name)\n"
      ],
      "metadata": {
        "id": "6i6Pd0FpEeBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import evaluate\n",
        "\n",
        "# ROUGE-2 점수 계산 함수 정의\n",
        "def calc_rouge(preds, labels):\n",
        "    preds = preds.argmax(axis=-1)  # 예측 결과에서 argmax 사용하여 토큰 추출\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)  # 패딩 위치는 토크나이저 패딩 토큰으로 변경\n",
        "\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # ROUGE-2 점수 계산\n",
        "    rouge2 = rouge_score.compute(\n",
        "        predictions=decoded_preds,\n",
        "        references=decoded_labels\n",
        "    )\n",
        "    return rouge2[\"rouge2\"]\n",
        "\n",
        "# 학습 함수 정의\n",
        "def train(model, optimizer, dataloader):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "\n",
        "    for input_ids, attention_mask, labels in dataloader:\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            labels=labels\n",
        "        )\n",
        "\n",
        "        loss = outputs.loss\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    train_loss = train_loss / len(dataloader)\n",
        "    return train_loss\n",
        "\n",
        "# 평가 함수 정의\n",
        "def evaluation(model, dataloader):\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        val_loss, val_rouge = 0.0, 0.0\n",
        "\n",
        "        for input_ids, attention_mask, labels in dataloader:\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                labels=labels\n",
        "            )\n",
        "            logits = outputs.logits\n",
        "            loss = outputs.loss\n",
        "\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            label_ids = labels.to(\"cpu\").numpy()\n",
        "            rouge = calc_rouge(logits, label_ids)\n",
        "\n",
        "            val_loss += loss\n",
        "            val_rouge += rouge\n",
        "\n",
        "    val_loss = val_loss / len(dataloader)\n",
        "    val_rouge = val_rouge / len(dataloader)\n",
        "    return val_loss, val_rouge\n",
        "\n",
        "# ROUGE 점수 계산 모듈 불러오기\n",
        "rouge_score = evaluate.load(\"rouge\", tokenizer=tokenizer)\n",
        "\n",
        "# 학습 및 검증 루프\n",
        "best_loss = 10000\n",
        "for epoch in range(epochs):\n",
        "    train_loss = train(model, optimizer, train_dataloader)\n",
        "    val_loss, val_accuracy = evaluation(model, valid_dataloader)\n",
        "    print(f\"Epoch {epoch + 1}: Train Loss: {train_loss:.4f} Val Loss: {val_loss:.4f} Val Rouge {val_accuracy:.4f}\")\n",
        "\n",
        "    # 검증 손실이 최소일 때 모델 저장\n",
        "    if val_loss < best_loss:\n",
        "        best_loss = val_loss\n",
        "        torch.save(model.state_dict(), \"../models/BartForConditionalGeneration.pt\")\n",
        "        print(\"Saved the model weights\")"
      ],
      "metadata": {
        "id": "k7Suv-UDEgUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BART 모델 초기화 및 저장된 가중치 불러오기\n",
        "model = BartForConditionalGeneration.from_pretrained(\n",
        "    pretrained_model_name_or_path=\"facebook/bart-base\"\n",
        ").to(device)\n",
        "model.load_state_dict(torch.load(\"../models/BartForConditionalGeneration.pt\"))\n",
        "\n",
        "# 테스트 데이터셋 평가\n",
        "test_loss, test_rouge_score = evaluation(model, test_dataloader)\n",
        "print(f\"Test Loss : {test_loss:.4f}\")\n",
        "print(f\"Test ROUGE-2 Score : {test_rouge_score:.4f}\")"
      ],
      "metadata": {
        "id": "0d0lTiRBEh8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# 요약 파이프라인 설정\n",
        "summarizer = pipeline(\n",
        "    task=\"summarization\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_length=54,\n",
        "    device=\"cpu\"\n",
        ")\n",
        "\n",
        "# 테스트 데이터셋에서 일부 샘플을 출력\n",
        "for index in range(5):\n",
        "    news_text = test.text.iloc[index]\n",
        "    summarization = test.prediction.iloc[index]\n",
        "    predicted_summarization = summarizer(news_text)[0][\"summary_text\"]\n",
        "    print(f\"정답 요약문 : {summarization}\")\n",
        "    print(f\"모델 요약문 : {predicted_summarization}\\n\")"
      ],
      "metadata": {
        "id": "jWXwxQhVEkYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KoELECTRA 모델 실습"
      ],
      "metadata": {
        "id": "QHElbmBvElPG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from Korpora import Korpora\n",
        "\n",
        "# NSMC 코퍼스를 로드하고, 테스트 데이터셋에서 20000개의 샘플을 추출\n",
        "corpus = Korpora.load(\"nsmc\")\n",
        "df = pd.DataFrame(corpus.test).sample(20000, random_state=42)\n",
        "\n",
        "# 데이터를 학습, 검증, 테스트 세트로 60%, 20%, 20% 비율로 분할\n",
        "train, valid, test = np.split(\n",
        "    df.sample(frac=1, random_state=42), [int(0.6 * len(df)), int(0.8 * len(df))]\n",
        ")\n",
        "\n",
        "# 학습 데이터 일부와 각 데이터셋 크기 출력\n",
        "print(train.head(5).to_markdown())\n",
        "print(f\"Training Data Size : {len(train)}\")\n",
        "print(f\"Validation Data Size : {len(valid)}\")\n",
        "print(f\"Testing Data Size : {len(test)}\")"
      ],
      "metadata": {
        "id": "WPfTKeR_En4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 생성 및 데이터로더 정의\n",
        "\n",
        "import torch\n",
        "from transformers import ElectraTokenizer\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch.utils.data import RandomSampler, SequentialSampler\n",
        "\n",
        "# 데이터셋을 토크나이저로 처리하여 TensorDataset 형식으로 반환\n",
        "def make_dataset(data, tokenizer, device):\n",
        "    # 입력 텍스트 토큰화\n",
        "    tokenized = tokenizer(\n",
        "        text=data.text.tolist(),\n",
        "        padding=\"longest\",\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    input_ids = tokenized[\"input_ids\"].to(device)\n",
        "    attention_mask = tokenized[\"attention_mask\"].to(device)\n",
        "\n",
        "    # 라벨을 텐서로 변환하고 장치로 이동\n",
        "    labels = torch.tensor(data.label.values, dtype=torch.long).to(device)\n",
        "    return TensorDataset(input_ids, attention_mask, labels)\n",
        "\n",
        "# DataLoader 생성 함수 정의\n",
        "def get_datalodader(dataset, sampler, batch_size):\n",
        "    data_sampler = sampler(dataset)\n",
        "    dataloader = DataLoader(dataset, sampler=data_sampler, batch_size=batch_size)\n",
        "    return dataloader\n",
        "\n",
        "# 하이퍼파라미터 설정\n",
        "epochs = 5\n",
        "batch_size = 32\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Electra 토크나이저 초기화\n",
        "tokenizer = ElectraTokenizer.from_pretrained(\n",
        "    pretrained_model_name_or_path=\"monologg/koelectra-base-v3-discriminator\",\n",
        "    do_lower_case=False,\n",
        ")\n",
        "\n",
        "# 학습, 검증, 테스트 데이터셋 및 데이터로더 생성\n",
        "train_dataset = make_dataset(train, tokenizer, device)\n",
        "train_dataloader = get_datalodader(train_dataset, RandomSampler, batch_size)\n",
        "\n",
        "valid_dataset = make_dataset(valid, tokenizer, device)\n",
        "valid_dataloader = get_datalodader(valid_dataset, SequentialSampler, batch_size)\n",
        "\n",
        "test_dataset = make_dataset(test, tokenizer, device)\n",
        "test_dataloader = get_datalodader(test_dataset, SequentialSampler, batch_size)\n",
        "\n",
        "# 첫 번째 학습 데이터셋 출력\n",
        "print(train_dataset[0])"
      ],
      "metadata": {
        "id": "Yrv9NodNExis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 초기화 및 옵티마이저 설정\n",
        "\n",
        "from torch import optim\n",
        "from transformers import ElectraForSequenceClassification\n",
        "\n",
        "# Electra 이진 분류 모델 불러오기\n",
        "model = ElectraForSequenceClassification.from_pretrained(\n",
        "    pretrained_model_name_or_path=\"monologg/koelectra-base-v3-discriminator\",\n",
        "    num_labels=2\n",
        ").to(device)\n",
        "\n",
        "# AdamW 옵티마이저 설정\n",
        "optimizer = optim.AdamW(model.parameters(), lr=1e-5, eps=1e-8)\n",
        "\n",
        "# 모델의 계층 구조 출력\n",
        "for main_name, main_module in model.named_children():\n",
        "    print(main_name)\n",
        "    for sub_name, sub_module in main_module.named_children():\n",
        "        print(\"└\", sub_name)\n",
        "        for ssub_name, ssub_module in sub_module.named_children():\n",
        "            print(\"│  └\", ssub_name)\n",
        "            for sssub_name, sssub_module in ssub_module.named_children():\n",
        "                print(\"│  │  └\", sssub_name)"
      ],
      "metadata": {
        "id": "NEoQN8oqE1Cd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 정확도 계산 함수 및 학습/평가 루프 정의\n",
        "\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "\n",
        "# 예측 정확도 계산 함수 정의\n",
        "def calc_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "# 학습 함수 정의\n",
        "def train(model, optimizer, dataloader):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "\n",
        "    # 데이터셋을 배치 단위로 순회하며 학습\n",
        "    for input_ids, attention_mask, labels in dataloader:\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "\n",
        "        # 손실 계산\n",
        "        loss = outputs.loss\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        optimizer.zero_grad()  # 기울기 초기화\n",
        "        loss.backward()  # 역전파\n",
        "        optimizer.step()  # 가중치 업데이트\n",
        "\n",
        "    # 배치 평균 학습 손실 반환\n",
        "    train_loss = train_loss / len(dataloader)\n",
        "    return train_loss\n",
        "\n",
        "# 평가 함수 정의\n",
        "def evaluation(model, dataloader):\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        val_loss, val_accuracy = 0.0, 0.0\n",
        "\n",
        "        # 데이터셋을 배치 단위로 순회하며 평가\n",
        "        for input_ids, attention_mask, labels in dataloader:\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            logits = outputs.logits\n",
        "\n",
        "            # 손실 및 정확도 계산\n",
        "            loss = criterion(logits, labels)\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            label_ids = labels.to(\"cpu\").numpy()\n",
        "            accuracy = calc_accuracy(logits, label_ids)\n",
        "\n",
        "            val_loss += loss\n",
        "            val_accuracy += accuracy\n",
        "\n",
        "    # 배치 평균 검증 손실 및 정확도 반환\n",
        "    val_loss = val_loss / len(dataloader)\n",
        "    val_accuracy = val_accuracy / len(dataloader)\n",
        "    return val_loss, val_accuracy"
      ],
      "metadata": {
        "id": "FtD1Oy-OE2qE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 학습 및 평가 루프\n",
        "\n",
        "# 초기 최저 손실 설정\n",
        "best_loss = 10000\n",
        "for epoch in range(epochs):\n",
        "    # 학습 손실 계산\n",
        "    train_loss = train(model, optimizer, train_dataloader)\n",
        "\n",
        "    # 검증 손실 및 정확도 계산\n",
        "    val_loss, val_accuracy = evaluation(model, valid_dataloader)\n",
        "    print(f\"Epoch {epoch + 1}: Train Loss: {train_loss:.4f} Val Loss: {val_loss:.4f} Val Accuracy {val_accuracy:.4f}\")\n",
        "\n",
        "    # 검증 손실이 최소일 때 모델 저장\n",
        "    if val_loss < best_loss:\n",
        "        best_loss = val_loss\n",
        "        torch.save(model.state_dict(), \"../models/ElectraForSequenceClassification.pt\")\n",
        "        print(\"Saved the model weights\")"
      ],
      "metadata": {
        "id": "Be4UAf7dE5iy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#테스트 평가 및 결과 출력\n",
        "from transformers import ElectraForSequenceClassification\n",
        "\n",
        "# 저장된 모델 불러오기 및 가중치 로드\n",
        "model = ElectraForSequenceClassification.from_pretrained(\n",
        "    pretrained_model_name_or_path=\"monologg/koelectra-base-v3-discriminator\",\n",
        "    num_labels=2\n",
        ").to(device)\n",
        "model.load_state_dict(torch.load(\"../models/ElectraForSequenceClassification.pt\"))\n",
        "\n",
        "# 테스트 데이터셋 평가\n",
        "test_loss, test_accuracy = evaluation(model, test_dataloader)\n",
        "\n",
        "# 테스트 손실과 정확도 출력\n",
        "print(f\"Test Loss : {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy : {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "ZA6M2cqvE7R_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## T5 모델 실습"
      ],
      "metadata": {
        "id": "fK9EJzBYFcLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터셋 로드 및 분할\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "\n",
        "# 데이터셋 불러와 무작위로 5000개의 샘플을 추출하여 텍스트와 요약문으로 구성된 DataFrame 생성\n",
        "news = load_dataset(\"argilla/news-summary\", split=\"test\")\n",
        "df = news.to_pandas().sample(5000, random_state=42)[[\"text\", \"prediction\"]]\n",
        "\n",
        "# 입력 텍스트 앞에 'summarize:'라는 프롬프트를 추가해 T5 모델이 요약 작업을 수행하도록 설정\n",
        "df[\"text\"] = \"summarize: \" + df[\"text\"]\n",
        "\n",
        "# 요약문 데이터에서 텍스트만 추출\n",
        "df[\"prediction\"] = df[\"prediction\"].map(lambda x: x[0][\"text\"])\n",
        "\n",
        "# 데이터를 60%, 20%, 20% 비율로 학습, 검증, 테스트 세트로 분할\n",
        "train, valid, test = np.split(\n",
        "    df.sample(frac=1, random_state=42), [int(0.6 * len(df)), int(0.8 * len(df))]\n",
        ")\n",
        "\n",
        "# 데이터 일부 출력\n",
        "print(f\"Source News : {train.text.iloc[0][:200]}\")\n",
        "print(f\"Summarization : {train.prediction.iloc[0][:50]}\")\n",
        "print(f\"Training Data Size : {len(train)}\")\n",
        "print(f\"Validation Data Size : {len(valid)}\")\n",
        "print(f\"Testing Data Size : {len(test)}\")"
      ],
      "metadata": {
        "id": "vxGKUgwIFeQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 전처리 및 데이터로더 정의\n",
        "import torch\n",
        "from transformers import T5Tokenizer\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch.utils.data import RandomSampler, SequentialSampler\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# 입력 및 레이블 데이터를 토큰화하고 TensorDataset 형식으로 반환하는 함수\n",
        "def make_dataset(data, tokenizer, device):\n",
        "    # 입력 텍스트를 토큰화하고 최대 길이로 패딩\n",
        "    source = tokenizer(\n",
        "        text=data.text.tolist(),\n",
        "        padding=\"max_length\",\n",
        "        max_length=128,\n",
        "        pad_to_max_length=True,\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    # 요약문(타겟 텍스트)을 토큰화하고 최대 길이로 패딩\n",
        "    target = tokenizer(\n",
        "        text=data.prediction.tolist(),\n",
        "        padding=\"max_length\",\n",
        "        max_length=128,\n",
        "        pad_to_max_length=True,\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    # 토큰화된 입력 IDs와 어텐션 마스크, 레이블 IDs 및 레이블 마스크 생성\n",
        "    source_ids = source[\"input_ids\"].squeeze().to(device)\n",
        "    source_mask = source[\"attention_mask\"].squeeze().to(device)\n",
        "    target_ids = target[\"input_ids\"].squeeze().to(device)\n",
        "    target_mask = target[\"attention_mask\"].squeeze().to(device)\n",
        "    return TensorDataset(source_ids, source_mask, target_ids, target_mask)\n",
        "\n",
        "# DataLoader 생성 함수 정의\n",
        "def get_datalodader(dataset, sampler, batch_size):\n",
        "    data_sampler = sampler(dataset)\n",
        "    dataloader = DataLoader(dataset, sampler=data_sampler, batch_size=batch_size)\n",
        "    return dataloader\n",
        "\n",
        "# 하이퍼파라미터 설정\n",
        "epochs = 5\n",
        "batch_size = 8\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# T5 모델 토크나이저 불러오기\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
        "\n",
        "# 학습, 검증, 테스트 데이터셋 및 데이터로더 생성\n",
        "train_dataset = make_dataset(train, tokenizer, device)\n",
        "train_dataloader = get_datalodader(train_dataset, RandomSampler, batch_size)\n",
        "\n",
        "valid_dataset = make_dataset(valid, tokenizer, device)\n",
        "valid_dataloader = get_datalodader(valid_dataset, SequentialSampler, batch_size)\n",
        "\n",
        "test_dataset = make_dataset(test, tokenizer, device)\n",
        "test_dataloader = get_datalodader(test_dataset, SequentialSampler, batch_size)\n",
        "\n",
        "# 첫 번째 학습 데이터셋 출력 및 토큰 예시 출력\n",
        "print(next(iter(train_dataloader)))\n",
        "print(tokenizer.convert_ids_to_tokens(21603))\n",
        "print(tokenizer.convert_ids_to_tokens(10))"
      ],
      "metadata": {
        "id": "yooRn8twFqGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 초기화 및 옵티마이저 설정\n",
        "from torch import optim\n",
        "from transformers import T5ForConditionalGeneration\n",
        "\n",
        "# T5 모델 불러오기 (요약문 생성을 위한 조건부 생성 모델)\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\").to(device)\n",
        "\n",
        "# AdamW 옵티마이저 설정 (가중치 감쇠 적용)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=1e-5, eps=1e-8)"
      ],
      "metadata": {
        "id": "n9OjKROwFreG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 및 평가 함수 정의\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "\n",
        "# 학습 함수 정의\n",
        "def train(model, optimizer, dataloader):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "\n",
        "    # 데이터셋을 배치 단위로 순회하며 학습\n",
        "    for source_ids, source_mask, target_ids, target_mask in dataloader:\n",
        "        # 디코더 입력 및 레이블 생성\n",
        "        decoder_input_ids = target_ids[:, :-1].contiguous()\n",
        "        labels = target_ids[:, 1:].clone().detach()\n",
        "        labels[target_ids[:, 1:] == tokenizer.pad_token_id] = -100  # 패딩 토큰 위치를 -100으로 설정하여 무시\n",
        "\n",
        "        # 모델에 입력 데이터를 전달하고 손실 계산\n",
        "        outputs = model(\n",
        "            input_ids=source_ids,\n",
        "            attention_mask=source_mask,\n",
        "            decoder_input_ids=decoder_input_ids,\n",
        "            labels=labels,\n",
        "        )\n",
        "\n",
        "        loss = outputs.loss\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        optimizer.zero_grad()  # 기울기 초기화\n",
        "        loss.backward()  # 역전파\n",
        "        optimizer.step()  # 가중치 업데이트\n",
        "\n",
        "    # 배치 평균 학습 손실 반환\n",
        "    train_loss = train_loss / len(dataloader)\n",
        "    return train_loss\n",
        "\n",
        "# 평가 함수 정의\n",
        "def evaluation(model, dataloader):\n",
        "    with torch.no_grad():  # 평가 중에는 기울기 계산 비활성화\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "\n",
        "        # 데이터셋을 배치 단위로 순회하며 평가\n",
        "        for source_ids, source_mask, target_ids, target_mask in dataloader:\n",
        "            # 디코더 입력 및 레이블 생성\n",
        "            decoder_input_ids = target_ids[:, :-1].contiguous()\n",
        "            labels = target_ids[:, 1:].clone().detach()\n",
        "            labels[target_ids[:, 1:] == tokenizer.pad_token_id] = -100  # 패딩 토큰 위치를 -100으로 설정하여 무시\n",
        "\n",
        "            # 모델에 입력 데이터를 전달하고 손실 계산\n",
        "            outputs = model(\n",
        "                input_ids=source_ids,\n",
        "                attention_mask=source_mask,\n",
        "                decoder_input_ids=decoder_input_ids,\n",
        "                labels=labels,\n",
        "            )\n",
        "\n",
        "            loss = outputs.loss\n",
        "            val_loss += loss\n",
        "\n",
        "    # 배치 평균 검증 손실 반환\n",
        "    val_loss = val_loss / len(dataloader)\n",
        "    return val_loss"
      ],
      "metadata": {
        "id": "GJra7VGKFtFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 학습 및 평가 루프\n",
        "best_loss = 10000  # 초기 최저 손실 설정\n",
        "for epoch in range(epochs):\n",
        "    # 학습 손실 계산\n",
        "    train_loss = train(model, optimizer, train_dataloader)\n",
        "\n",
        "    # 검증 손실 계산\n",
        "    val_loss = evaluation(model, valid_dataloader)\n",
        "    print(f\"Epoch {epoch + 1}: Train Loss: {train_loss:.4f} Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "    # 검증 손실이 최소일 때 모델 저장\n",
        "    if val_loss < best_loss:\n",
        "        best_loss = val_loss\n",
        "        torch.save(model.state_dict(), \"../models/T5ForConditionalGeneration.pt\")\n",
        "        print(\"Saved the model weights\")"
      ],
      "metadata": {
        "id": "ASIPaIZtFvK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 평가 및 요약 생성 예시\n",
        "model.eval()  # 모델을 평가 모드로 설정\n",
        "with torch.no_grad():  # 기울기 계산 비활성화\n",
        "    for source_ids, source_mask, target_ids, target_mask in test_dataloader:\n",
        "        # 테스트 데이터셋에서 요약문 생성\n",
        "        generated_ids = model.generate(\n",
        "            input_ids=source_ids,\n",
        "            attention_mask=source_mask,\n",
        "            max_length=128,  # 생성할 최대 토큰 길이\n",
        "            num_beams=3,  # 빔 탐색 개수\n",
        "            repetition_penalty=2.5,  # 반복 억제 설정\n",
        "            length_penalty=1.0,  # 길이 패널티 설정\n",
        "            early_stopping=True,  # 조기 종료 설정\n",
        "        )\n",
        "\n",
        "        # 생성된 요약문과 실제 요약문을 디코딩하여 비교\n",
        "        for generated, target in zip(generated_ids, target_ids):\n",
        "            pred = tokenizer.decode(\n",
        "                generated, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
        "            )\n",
        "            actual = tokenizer.decode(\n",
        "                target, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
        "            )\n",
        "            print(\"Generated Headline Text:\", pred)\n",
        "            print(\"Actual Headline Text   :\", actual)\n",
        "        break  # 첫 배치만 출력"
      ],
      "metadata": {
        "id": "A5eng1xtFwnu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}